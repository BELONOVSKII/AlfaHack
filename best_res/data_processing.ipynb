{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23681369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33fb4b8",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "**Steps**\n",
    "1. Concat train/test data files.\n",
    "2. Extract categorical features from data.\n",
    "3. Scale numeric features and ordinal encode categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812a9010",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb09e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd4ab0",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "**Concat train/test data files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8815b5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список файлов в репозитории train: ['train_1.csv', 'train_10.csv', 'train_2.csv', 'train_3.csv', 'train_4.csv', 'train_5.csv', 'train_6.csv', 'train_7.csv', 'train_8.csv', 'train_9.csv']\n",
      "Список файлов в репозитории test: ['test_1.csv', 'test_10.csv', 'test_2.csv', 'test_3.csv', 'test_4.csv', 'test_5.csv', 'test_6.csv', 'test_7.csv', 'test_8.csv', 'test_9.csv']\n",
      "Размерность полных тренировочных данных составляет: 413194 строки и 189 столбцов\n"
     ]
    }
   ],
   "source": [
    "path_train = '../data/train'\n",
    "path_test = '../data/test'\n",
    "print(*[f'Список файлов в репозитории {x.split(\"/\")[-1]}: {sorted(os.listdir(x))}' for x in [path_train, path_test]], sep='\\n')\n",
    "# Получим список путей к файлам в папке train\n",
    "filenames_train = glob.glob(path_train + \"/*.csv\")\n",
    "# Создадим список для записи считанных файлов train\n",
    "data_files_train = []\n",
    "# Считаем все файлы train и добавим их в список\n",
    "for filename in filenames_train:\n",
    "    data_files_train.append(pl.read_csv(filename))\n",
    "# Объединим тренировочные данные в единый датасет\n",
    "data_train = pl.concat(data_files_train)\n",
    "# Выведем информацию о размерности полученных тренировочных данных\n",
    "print('Размерность полных тренировочных данных составляет: {} строки и {} столбцов'.format(*data_train.shape))\n",
    "\n",
    "# Получим список путей к файлам в папке train\n",
    "filenames_test = glob.glob(path_test + \"/*.csv\")\n",
    "# Создадим список для записи считанных файлов train\n",
    "data_files_test = []\n",
    "# Считаем все файлы train и добавим их в список\n",
    "for filename in filenames_test:\n",
    "    data_files_test.append(pl.read_csv(filename))\n",
    "# Объединим тренировочные данные в единый датасет\n",
    "data_test = pl.concat(data_files_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65c755",
   "metadata": {},
   "source": [
    "## Step 2 \n",
    "**Extract categorical features from data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef223cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical columns: 12\n",
      "Number of numeric columns: 174\n"
     ]
    }
   ],
   "source": [
    "cat_unique_thresh = 150\n",
    "cat_condition = data_train.select(pl.col(\"*\").n_unique() < cat_unique_thresh).to_numpy()[0]\n",
    "cat_columns = data_train[:, cat_condition].drop(\"target\", \"smpl\", \"id\", strict=False).columns\n",
    "num_columns = data_train.drop(\"target\", \"smpl\", \"id\", *cat_columns).columns\n",
    "\n",
    "# convert cat_columns to str \n",
    "# and num_columns columns to float32 to reduce memory consumption\n",
    "data_train = data_train.with_columns(\"target\", \"smpl\", \"id\", pl.col(cat_columns).cast(pl.Int16), pl.col(num_columns).cast(pl.Float32))\n",
    "data_test = data_test.with_columns(\"smpl\", \"id\", pl.col(cat_columns).cast(pl.Int16), pl.col(num_columns).cast(pl.Float32))\n",
    "print(f\"Number of categorical columns: {len(cat_columns)}\")\n",
    "print(f\"Number of numeric columns: {len(num_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e67a6b",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "**Scale numeric features and ordinal encode categorical features.**\n",
    "\n",
    "\n",
    "Apply basic preprocessing, since data is already in good condition (no missing values, no outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "194ab34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing\n",
    "oe = OrdinalEncoder(dtype=np.int32, handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "ss = StandardScaler()\n",
    "\n",
    "data_train[cat_columns] = oe.fit_transform(data_train[cat_columns])\n",
    "data_train[num_columns] = ss.fit_transform(data_train[num_columns])\n",
    "\n",
    "data_test[cat_columns] = oe.transform(data_test[cat_columns])\n",
    "data_test[num_columns] = ss.transform(data_test[num_columns])\n",
    "\n",
    "data_train.write_parquet(DATA_PATH / \"train_preproc_2.parquet\")\n",
    "data_test.write_parquet(DATA_PATH / \"test_preproc_2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7112f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_kernel",
   "language": "python",
   "name": "base_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
