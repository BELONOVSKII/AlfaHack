{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa3af6a-d478-4c0e-a715-21f3f6707c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../../automl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe599f1-83eb-4e6b-8115-f05eb659ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "[2024-11-05 17:42:47]\n",
      "/home/peter/venvs/base_venv/lib/python3.10/site-packages/lightautoml/ml_algo/dl_model.py:42: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/home/peter/venvs/base_venv/lib/python3.10/site-packages/lightautoml/text/embed.py:22: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/home/peter/venvs/base_venv/lib/python3.10/site-packages/lightautoml/text/dl_transformers.py:25: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.automl.loggers import configure_root_logger\n",
    "from src.automl.constants import create_ml_data_dir\n",
    "from src.automl.model.lama import TabularLamaUtilized\n",
    "from src.automl.model.metrics import RocAuc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4701a7-04a9-42cd-b472-d9ca1dce955d",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9446b478-3af7-4d89-8d52-0d16996734e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 77\n",
    "DATA_PATH = Path(\"../../data/\")\n",
    "CONFIG_PATH = Path(\"../../configs/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5494d0ab-4d12-47b3-bbaa-31fd51961cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CONFIG_PATH.open() as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a983d1-64cf-4a80-b72c-023c6528fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ml_data_dir()\n",
    "configure_root_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1cf46-0712-400d-b190-15de4b596d15",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7208e0bf-13a0-4f7a-9f2e-307f386ef935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(DATA_PATH / \"train_preproc.parquet\")\n",
    "df_train, df_test = df_train.sort_values(by=\"id\").iloc[:300_000], df_train.sort_values(by=\"id\").iloc[300_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a4bbaca-2b74-4177-88e4-4897ff07498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = df_train.columns[df_train.columns.str.startswith(\"OneHotEncoder\")].values.tolist()\n",
    "oe_cols = df_train.columns[df_train.columns.str.startswith(\"OrdinalEncoder\")].values.tolist()\n",
    "te_cols = df_train.columns[df_train.columns.str.startswith(\"MeanTargetEncoder\")].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979b253b-f611-498c-919d-11993f85a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take ordinal encoded columns\n",
    "X_train, y_train = df_train[cfg[\"selected_features\"] + oe_cols + ohe_cols + te_cols], df_train[\"target\"]\n",
    "X_test, y_test = df_test[cfg[\"selected_features\"] + oe_cols + ohe_cols + te_cols], df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f28cd79-395e-4e5d-9fa6-015a640955d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940853\n",
       "1    0.059147\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.941322\n",
       "1    0.058678\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train.value_counts(normalize=True))\n",
    "display(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b00734-0a36-4487-93ed-c78e6833ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ohe_cols + oe_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48abfc9d-95b1-4eda-9665-251676ed3d8f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e9b58f-d170-4930-9bd9-e67ac8828af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularLamaUtilized(timeout=60 * 60, task=\"classification\", n_jobs=16, metric=RocAuc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55d6a590-bf4d-4d9d-bbe7-f59f4015d553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-05 17:43:46,352] - [   START    ] - Fitting TabularLamaUtilized\n",
      "[17:43:46] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[17:43:46] - time: 7200.00 seconds\n",
      "[17:43:46] - CPU: 16 cores\n",
      "[17:43:46] - memory: 16 GB\n",
      "\n",
      "[17:43:46] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[17:43:46] ==================================================\n",
      "[17:43:46] Start 0 automl preset configuration:\n",
      "[17:43:46] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[17:43:46] Stdout logging level is INFO.\n",
      "[17:43:46] Task: binary\n",
      "\n",
      "[17:43:46] Start automl preset with listed constraints:\n",
      "[17:43:46] - time: 7200.00 seconds\n",
      "[17:43:46] - CPU: 16 cores\n",
      "[17:43:46] - memory: 16 GB\n",
      "\n",
      "[17:43:46] \u001b[1mTrain data shape: (300000, 77)\u001b[0m\n",
      "\n",
      "[17:43:58] Layer \u001b[1m1\u001b[0m train process start. Time left 7188.11 secs\n",
      "[17:44:07] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[17:44:53] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7861847660826955\u001b[0m\n",
      "[17:44:53] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[17:44:53] Time left 7133.11 secs\n",
      "\n",
      "[17:45:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[17:45:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8019902842006865\u001b[0m\n",
      "[17:45:39] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:45:39] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:45:39] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[17:50:41] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[17:50:41] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:51:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8046907611535709\u001b[0m\n",
      "[17:51:27] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:51:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[17:52:05] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8006805971995175\u001b[0m\n",
      "[17:52:05] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:52:05] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:57:08] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[17:57:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:58:14] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8010790172011413\u001b[0m\n",
      "[17:58:14] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:58:14] Time left 6332.45 secs\n",
      "\n",
      "[17:58:14] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:58:14] Blending: optimization starts with equal weights and score \u001b[1m0.8029871171970764\u001b[0m\n",
      "[17:58:18] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8050453362802048\u001b[0m, weights = \u001b[1m[0.         0.15608239 0.7615264  0.08239119 0.        ]\u001b[0m\n",
      "[17:58:21] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8050732737220843\u001b[0m, weights = \u001b[1m[0.         0.21669145 0.656168   0.12714058 0.        ]\u001b[0m\n",
      "[17:58:25] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8050738941858522\u001b[0m, weights = \u001b[1m[0.         0.2061703  0.67345524 0.12037446 0.        ]\u001b[0m\n",
      "[17:58:29] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.805073927829664\u001b[0m, weights = \u001b[1m[0.         0.20647536 0.672972   0.12055257 0.        ]\u001b[0m\n",
      "[17:58:33] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8050740783782337\u001b[0m, weights = \u001b[1m[0.         0.20805173 0.66786873 0.12407953 0.        ]\u001b[0m\n",
      "[17:58:33] \u001b[1mAutoml preset training completed in 887.07 seconds\u001b[0m\n",
      "\n",
      "[17:58:33] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.20805 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.66787 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.12408 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n",
      "[17:58:33] ==================================================\n",
      "[17:58:33] Start 1 automl preset configuration:\n",
      "[17:58:33] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n",
      "[17:58:33] Stdout logging level is INFO.\n",
      "[17:58:33] Task: binary\n",
      "\n",
      "[17:58:33] Start automl preset with listed constraints:\n",
      "[17:58:33] - time: 6312.91 seconds\n",
      "[17:58:33] - CPU: 16 cores\n",
      "[17:58:33] - memory: 16 GB\n",
      "\n",
      "[17:58:33] \u001b[1mTrain data shape: (300000, 77)\u001b[0m\n",
      "\n",
      "[17:58:44] Layer \u001b[1m1\u001b[0m train process start. Time left 6301.71 secs\n",
      "[17:58:53] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[17:59:41] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7862294739164642\u001b[0m\n",
      "[17:59:41] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[17:59:41] Time left 6245.32 secs\n",
      "\n",
      "[17:59:48] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:59:56] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[18:00:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8027937025175401\u001b[0m\n",
      "[18:00:35] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:00:35] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:05:39] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[18:05:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[18:06:14] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8047269215623326\u001b[0m\n",
      "[18:06:14] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:06:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[18:06:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8006710392621598\u001b[0m\n",
      "[18:06:50] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:06:50] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:11:54] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[18:11:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[18:12:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8015520810406291\u001b[0m\n",
      "[18:12:53] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:12:53] Time left 5453.29 secs\n",
      "\n",
      "[18:12:53] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[18:12:53] Blending: optimization starts with equal weights and score \u001b[1m0.8034019850292968\u001b[0m\n",
      "[18:12:57] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8054475652205476\u001b[0m, weights = \u001b[1m[0.         0.20521922 0.6201432  0.         0.17463763]\u001b[0m\n",
      "[18:13:00] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8054615689330482\u001b[0m, weights = \u001b[1m[0.         0.25891384 0.57388324 0.         0.16720292]\u001b[0m\n",
      "[18:13:04] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8054616734584811\u001b[0m, weights = \u001b[1m[0.         0.25858212 0.57442915 0.         0.1669887 ]\u001b[0m\n",
      "[18:13:08] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8054616769526455\u001b[0m, weights = \u001b[1m[0.         0.25858292 0.5744279  0.         0.16698919]\u001b[0m\n",
      "[18:13:12] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8054616855383067\u001b[0m, weights = \u001b[1m[0.         0.2585879  0.57441974 0.         0.1669924 ]\u001b[0m\n",
      "[18:13:12] \u001b[1mAutoml preset training completed in 878.73 seconds\u001b[0m\n",
      "\n",
      "[18:13:12] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.25859 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.57442 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.16699 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[18:13:12] ==================================================\n",
      "[18:13:12] Start 2 automl preset configuration:\n",
      "[18:13:12] \u001b[1mconf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'nn_params': {'random_state': 44}, 'general_params': {'return_all_predictions': False}}\n",
      "[18:13:12] Stdout logging level is INFO.\n",
      "[18:13:12] Task: binary\n",
      "\n",
      "[18:13:12] Start automl preset with listed constraints:\n",
      "[18:13:12] - time: 5434.15 seconds\n",
      "[18:13:12] - CPU: 16 cores\n",
      "[18:13:12] - memory: 16 GB\n",
      "\n",
      "[18:13:12] \u001b[1mTrain data shape: (300000, 77)\u001b[0m\n",
      "\n",
      "[18:13:12] Layer \u001b[1m1\u001b[0m train process start. Time left 5433.48 secs\n",
      "[18:13:21] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[18:14:08] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7861063777984048\u001b[0m\n",
      "[18:14:08] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[18:14:08] Time left 5377.93 secs\n",
      "\n",
      "[18:14:15] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:14:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[18:14:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.801677295420994\u001b[0m\n",
      "[18:14:59] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:14:59] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:20:05] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[18:20:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[18:20:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8048039214653488\u001b[0m\n",
      "[18:20:42] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:20:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[18:21:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8003978080835839\u001b[0m\n",
      "[18:21:15] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:21:15] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:26:23] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[18:26:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[18:27:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8010966703187966\u001b[0m\n",
      "[18:27:27] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:27:27] Time left 4579.00 secs\n",
      "\n",
      "[18:27:27] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[18:27:27] Blending: optimization starts with equal weights and score \u001b[1m0.8029087556681016\u001b[0m\n",
      "[18:27:31] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8051310054048166\u001b[0m, weights = \u001b[1m[0.         0.10300357 0.7284069  0.06817882 0.10041067]\u001b[0m\n",
      "[18:27:35] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8051377442503194\u001b[0m, weights = \u001b[1m[0.         0.13496354 0.69535553 0.05904629 0.11063457]\u001b[0m\n",
      "[18:27:38] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8051379019868846\u001b[0m, weights = \u001b[1m[0.         0.12945844 0.6997808  0.05942207 0.11133867]\u001b[0m\n",
      "[18:27:42] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8051379019868846\u001b[0m, weights = \u001b[1m[0.         0.12945844 0.6997808  0.05942207 0.11133867]\u001b[0m\n",
      "[18:27:42] Blending: no score update. Terminated\n",
      "\n",
      "[18:27:42] \u001b[1mAutoml preset training completed in 870.45 seconds\u001b[0m\n",
      "\n",
      "[18:27:42] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.12946 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.69978 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.05942 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.11134 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[18:27:42] ==================================================\n",
      "[18:27:42] Start 3 automl preset configuration:\n",
      "[18:27:42] \u001b[1mconf_3_sel_type_1_no_inter_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'nn_params': {'random_state': 45}, 'general_params': {'return_all_predictions': False}}\n",
      "[18:27:42] Stdout logging level is INFO.\n",
      "[18:27:42] Task: binary\n",
      "\n",
      "[18:27:42] Start automl preset with listed constraints:\n",
      "[18:27:42] - time: 4563.67 seconds\n",
      "[18:27:42] - CPU: 16 cores\n",
      "[18:27:42] - memory: 16 GB\n",
      "\n",
      "[18:27:42] \u001b[1mTrain data shape: (300000, 77)\u001b[0m\n",
      "\n",
      "[18:27:53] Layer \u001b[1m1\u001b[0m train process start. Time left 4552.49 secs\n",
      "[18:28:02] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[18:28:53] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7861484812816805\u001b[0m\n",
      "[18:28:53] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[18:28:53] Time left 4493.26 secs\n",
      "\n",
      "[18:29:00] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:29:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[18:29:34] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.802124078851204\u001b[0m\n",
      "[18:29:34] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:29:34] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:34:34] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[18:34:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[18:35:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8041125912509626\u001b[0m\n",
      "[18:35:07] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:35:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[18:35:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8001935165693709\u001b[0m\n",
      "[18:35:37] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:35:37] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:40:40] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[18:40:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[18:41:45] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8010022775634577\u001b[0m\n",
      "[18:41:45] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:41:45] Time left 3721.45 secs\n",
      "\n",
      "[18:41:45] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[18:41:45] Blending: optimization starts with equal weights and score \u001b[1m0.8026903522221243\u001b[0m\n",
      "[18:41:49] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8046389315138791\u001b[0m, weights = \u001b[1m[0.         0.19288893 0.65488005 0.         0.15223104]\u001b[0m\n",
      "[18:41:52] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8046531213155934\u001b[0m, weights = \u001b[1m[0.         0.24600567 0.6078687  0.         0.14612566]\u001b[0m\n",
      "[18:41:56] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8046531364902502\u001b[0m, weights = \u001b[1m[0.         0.24604012 0.6078137  0.         0.14614613]\u001b[0m\n",
      "[18:42:00] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8046531403837477\u001b[0m, weights = \u001b[1m[0.         0.24601975 0.6078462  0.         0.14613405]\u001b[0m\n",
      "[18:42:04] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8046531403837477\u001b[0m, weights = \u001b[1m[0.         0.24601975 0.6078462  0.         0.14613405]\u001b[0m\n",
      "[18:42:04] Blending: no score update. Terminated\n",
      "\n",
      "[18:42:04] \u001b[1mAutoml preset training completed in 861.60 seconds\u001b[0m\n",
      "\n",
      "[18:42:04] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.24602 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.60785 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.14613 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[18:42:04] ==================================================\n",
      "[18:42:04] Start 4 automl preset configuration:\n",
      "[18:42:04] \u001b[1mconf_4_sel_type_0_no_int.yml\u001b[0m, random state: {'reader_params': {'random_state': 46}, 'nn_params': {'random_state': 46}, 'general_params': {'return_all_predictions': False}}\n",
      "[18:42:04] Stdout logging level is INFO.\n",
      "[18:42:04] Task: binary\n",
      "\n",
      "[18:42:04] Start automl preset with listed constraints:\n",
      "[18:42:04] - time: 3702.04 seconds\n",
      "[18:42:04] - CPU: 16 cores\n",
      "[18:42:04] - memory: 16 GB\n",
      "\n",
      "[18:42:04] \u001b[1mTrain data shape: (300000, 77)\u001b[0m\n",
      "\n",
      "[18:42:15] Layer \u001b[1m1\u001b[0m train process start. Time left 3690.76 secs\n",
      "[18:42:17] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[18:42:59] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7862122175362207\u001b[0m\n",
      "[18:42:59] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[18:42:59] Time left 3646.73 secs\n",
      "\n",
      "[18:43:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[18:43:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8023801447973111\u001b[0m\n",
      "[18:43:36] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:43:36] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:48:44] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[18:48:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[18:49:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8048972644738626\u001b[0m\n",
      "[18:49:21] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:49:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[18:49:57] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8005658935652311\u001b[0m\n",
      "[18:49:57] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:49:57] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:54:57] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[18:54:57] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[18:56:01] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8007368694196876\u001b[0m\n",
      "[18:56:01] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:56:01] Time left 2864.97 secs\n",
      "\n",
      "[18:56:01] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[18:56:01] Blending: optimization starts with equal weights and score \u001b[1m0.8031155979223422\u001b[0m\n",
      "[18:56:05] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.80531177889631\u001b[0m, weights = \u001b[1m[0.         0.149172   0.7101214  0.06440853 0.07629807]\u001b[0m\n",
      "[18:56:09] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8053386648941987\u001b[0m, weights = \u001b[1m[0.         0.2182111  0.660374   0.05989641 0.06151848]\u001b[0m\n",
      "[18:56:13] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8053388785373946\u001b[0m, weights = \u001b[1m[0.         0.21752581 0.66248715 0.0597083  0.06027871]\u001b[0m\n",
      "[18:56:17] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.805338930949861\u001b[0m, weights = \u001b[1m[0.         0.21798421 0.66177595 0.05983413 0.06040574]\u001b[0m\n",
      "[18:56:20] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8053396816960452\u001b[0m, weights = \u001b[1m[0.         0.2233547  0.66637075 0.06024957 0.05002498]\u001b[0m\n",
      "[18:56:20] \u001b[1mAutoml preset training completed in 856.47 seconds\u001b[0m\n",
      "\n",
      "[18:56:20] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.22335 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.66637 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.06025 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.05002 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[18:56:20] ==================================================\n",
      "[18:56:20] Start 5 automl preset configuration:\n",
      "[18:56:20] \u001b[1mconf_5_sel_type_1_tuning_full.yml\u001b[0m, random state: {'reader_params': {'random_state': 47}, 'nn_params': {'random_state': 47}, 'general_params': {'return_all_predictions': False}}\n",
      "[18:56:20] Stdout logging level is INFO.\n",
      "[18:56:20] Task: binary\n",
      "\n",
      "[18:56:20] Start automl preset with listed constraints:\n",
      "[18:56:20] - time: 2845.54 seconds\n",
      "[18:56:20] - CPU: 16 cores\n",
      "[18:56:20] - memory: 16 GB\n",
      "\n",
      "[18:56:20] \u001b[1mTrain data shape: (300000, 77)\u001b[0m\n",
      "\n",
      "[18:56:32] Layer \u001b[1m1\u001b[0m train process start. Time left 2834.28 secs\n",
      "[18:56:41] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[18:57:29] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7863066788770156\u001b[0m\n",
      "[18:57:29] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[18:57:29] Time left 2777.37 secs\n",
      "\n",
      "[18:57:37] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:57:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[18:58:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8018802167235874\u001b[0m\n",
      "[18:58:20] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:58:20] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:58:20] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[18:58:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8007740328533046\u001b[0m\n",
      "[18:58:59] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:58:59] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[18:59:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8035811403233303\u001b[0m\n",
      "[18:59:50] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:59:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:00:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8015023895300631\u001b[0m\n",
      "[19:00:19] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:00:19] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:00:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8018808928943196\u001b[0m\n",
      "[19:00:56] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:00:56] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:01:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7988818204236596\u001b[0m\n",
      "[19:01:25] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:01:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:02:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8033417798774873\u001b[0m\n",
      "[19:02:03] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:02:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:02:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8033034144513095\u001b[0m\n",
      "[19:02:40] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:02:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:03:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7979028580816183\u001b[0m\n",
      "[19:03:17] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:03:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:03:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8049583979752422\u001b[0m\n",
      "[19:03:59] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:03:59] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[19:03:59] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:04:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8048282886698561\u001b[0m\n",
      "[19:04:31] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:04:31] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[19:05:05] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8004843468558034\u001b[0m\n",
      "[19:05:05] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:05:05] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[19:05:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:05:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8010000295179024\u001b[0m\n",
      "[19:05:51] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:05:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:06:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7997624670620496\u001b[0m\n",
      "[19:06:22] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:06:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:07:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8006607081161323\u001b[0m\n",
      "[19:07:15] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:07:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:07:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7988230671470837\u001b[0m\n",
      "[19:07:39] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:07:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:07:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7973415578051687\u001b[0m\n",
      "[19:07:58] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:07:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:08:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8006615359336005\u001b[0m\n",
      "[19:08:43] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:08:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:09:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.799746265919461\u001b[0m\n",
      "[19:09:12] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:09:13] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:10:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8008147559419675\u001b[0m\n",
      "[19:10:04] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:10:04] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:10:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8007382437244711\u001b[0m\n",
      "[19:10:42] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:10:42] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[19:10:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:11:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8010563942835132\u001b[0m\n",
      "[19:11:48] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:11:48] Time left 1918.02 secs\n",
      "\n",
      "[19:11:48] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:11:48] Blending: optimization starts with equal weights and score \u001b[1m0.802896593679751\u001b[0m\n",
      "[19:11:52] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8051067442232414\u001b[0m, weights = \u001b[1m[0.         0.1074714  0.7452136  0.06278474 0.08453024]\u001b[0m\n",
      "[19:11:56] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8051121533894318\u001b[0m, weights = \u001b[1m[0.         0.13654782 0.7222284  0.0598671  0.08135667]\u001b[0m\n",
      "[19:12:00] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8051121533894318\u001b[0m, weights = \u001b[1m[0.         0.13654782 0.7222284  0.0598671  0.08135667]\u001b[0m\n",
      "[19:12:00] Blending: no score update. Terminated\n",
      "\n",
      "[19:12:00] \u001b[1mAutoml preset training completed in 939.44 seconds\u001b[0m\n",
      "\n",
      "[19:12:00] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.13655 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.72223 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.05987 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.08136 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[19:12:00] ==================================================\n",
      "[19:12:00] Start 6 automl preset configuration:\n",
      "[19:12:00] \u001b[1mconf_6_sel_type_1_tuning_full_no_int_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 48}, 'nn_params': {'random_state': 48}, 'general_params': {'return_all_predictions': False}}\n",
      "[19:12:00] Stdout logging level is INFO.\n",
      "[19:12:00] Task: binary\n",
      "\n",
      "[19:12:00] Start automl preset with listed constraints:\n",
      "[19:12:00] - time: 1906.07 seconds\n",
      "[19:12:00] - CPU: 16 cores\n",
      "[19:12:00] - memory: 16 GB\n",
      "\n",
      "[19:12:00] \u001b[1mTrain data shape: (300000, 77)\u001b[0m\n",
      "\n",
      "[19:12:11] Layer \u001b[1m1\u001b[0m train process start. Time left 1894.69 secs\n",
      "[19:12:20] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[19:13:09] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7862984420333089\u001b[0m\n",
      "[19:13:09] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[19:13:09] Time left 1836.60 secs\n",
      "\n",
      "[19:13:17] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:13:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[19:13:52] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8020639865109886\u001b[0m\n",
      "[19:13:52] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:13:52] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 287.19 secs\n",
      "[19:18:40] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[19:18:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:19:14] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8048355371641979\u001b[0m\n",
      "[19:19:14] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:19:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[19:19:45] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7999808639190309\u001b[0m\n",
      "[19:19:45] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:19:45] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[19:24:46] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[19:24:46] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:25:55] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8014905558933345\u001b[0m\n",
      "[19:25:55] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:25:55] Time left 1070.94 secs\n",
      "\n",
      "[19:25:55] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:25:55] Blending: optimization starts with equal weights and score \u001b[1m0.8028090099527028\u001b[0m\n",
      "[19:25:59] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8050897096725218\u001b[0m, weights = \u001b[1m[0.         0.11257305 0.7648155  0.         0.12261145]\u001b[0m\n",
      "[19:26:03] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8051074771991037\u001b[0m, weights = \u001b[1m[0.         0.17221417 0.7104012  0.         0.11738466]\u001b[0m\n",
      "[19:26:06] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8051074771991037\u001b[0m, weights = \u001b[1m[0.         0.17221417 0.7104012  0.         0.11738466]\u001b[0m\n",
      "[19:26:06] Blending: no score update. Terminated\n",
      "\n",
      "[19:26:06] \u001b[1mAutoml preset training completed in 846.55 seconds\u001b[0m\n",
      "\n",
      "[19:26:06] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.17221 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.71040 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.11738 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[19:26:06] ==================================================\n",
      "[19:26:06] ==================================================\n",
      "[19:26:06] Start 0 automl preset configuration:\n",
      "[19:26:06] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 49}, 'nn_params': {'random_state': 49}, 'general_params': {'return_all_predictions': False}}\n",
      "[19:26:06] Stdout logging level is INFO.\n",
      "[19:26:06] Task: binary\n",
      "\n",
      "[19:26:06] Start automl preset with listed constraints:\n",
      "[19:26:06] - time: 1059.49 seconds\n",
      "[19:26:06] - CPU: 16 cores\n",
      "[19:26:06] - memory: 16 GB\n",
      "\n",
      "[19:26:06] \u001b[1mTrain data shape: (300000, 77)\u001b[0m\n",
      "\n",
      "[19:26:18] Layer \u001b[1m1\u001b[0m train process start. Time left 1048.39 secs\n",
      "[19:26:27] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[19:27:13] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7862197041329095\u001b[0m\n",
      "[19:27:13] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[19:27:13] Time left 993.42 secs\n",
      "\n",
      "[19:27:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[19:27:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8026769354294133\u001b[0m\n",
      "[19:27:59] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:27:59] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 104.23 secs\n",
      "[19:29:48] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[19:29:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:30:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8047915401433058\u001b[0m\n",
      "[19:30:25] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:30:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[19:30:57] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7998365731979254\u001b[0m\n",
      "[19:30:57] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:30:57] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[19:36:00] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[19:36:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:36:57] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8011946372050053\u001b[0m\n",
      "[19:36:57] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:36:57] Time left 408.60 secs\n",
      "\n",
      "[19:36:57] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:36:57] Blending: optimization starts with equal weights and score \u001b[1m0.8032211952649807\u001b[0m\n",
      "[19:37:01] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8054003698412109\u001b[0m, weights = \u001b[1m[0.         0.18030126 0.65348077 0.         0.166218  ]\u001b[0m\n",
      "[19:37:05] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8054147129868267\u001b[0m, weights = \u001b[1m[0.         0.23758203 0.6046725  0.         0.15774547]\u001b[0m\n",
      "[19:37:09] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8054147129868267\u001b[0m, weights = \u001b[1m[0.         0.23758203 0.6046725  0.         0.15774547]\u001b[0m\n",
      "[19:37:09] Blending: no score update. Terminated\n",
      "\n",
      "[19:37:09] \u001b[1mAutoml preset training completed in 662.61 seconds\u001b[0m\n",
      "\n",
      "[19:37:09] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.23758 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.60467 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.15775 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[19:37:09] ==================================================\n",
      "[19:37:09] Blending: optimization starts with equal weights and score \u001b[1m0.8062251991996381\u001b[0m\n",
      "[19:37:15] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.80631744004886\u001b[0m, weights = \u001b[1m[0.11575758 0.27557707 0.16227835 0.         0.23582639 0.14550179\n",
      " 0.06505884]\u001b[0m\n",
      "[19:37:20] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8063181076339309\u001b[0m, weights = \u001b[1m[0.13060269 0.27913892 0.15737079 0.         0.22869465 0.14110158\n",
      " 0.06309136]\u001b[0m\n",
      "[19:37:26] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8063181055374322\u001b[0m, weights = \u001b[1m[0.13060269 0.27913895 0.1573708  0.         0.22869465 0.1411016\n",
      " 0.06309137]\u001b[0m\n",
      "[19:37:26] Blending: no score update. Terminated\n",
      "\n",
      "[2024-11-05 19:37:26,264] - [    END     ] - Fitting TabularLamaUtilized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9712412 , 0.02875882],\n",
       "       [0.9814385 , 0.01856149],\n",
       "       [0.89927167, 0.10072834],\n",
       "       ...,\n",
       "       [0.79000854, 0.20999143],\n",
       "       [0.96663874, 0.03336123],\n",
       "       [0.9555454 , 0.0444546 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, categorical_features=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7162af-72b8-48df-b3f8-cd4d2cf66c91",
   "metadata": {},
   "source": [
    "## Inference best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22275e56-48fa-4f3d-9f0c-22efadfde763",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(DATA_PATH / \"test_preproc.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fb86a7e-0937-4109-ac13-3e124361377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + oe_cols + ohe_cols + te_cols])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89a7bdaf-777a-44e1-99ce-24bb21ead2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id', 'target']].to_csv('lama_utilized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2056205-3190-4e56-9814-baf6e0ef51ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    171919.000000\n",
       "mean          0.059728\n",
       "std           0.067016\n",
       "min           0.002106\n",
       "25%           0.014638\n",
       "50%           0.030828\n",
       "75%           0.073483\n",
       "max           0.531220\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"target\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63c27084-59e9-41e2-a619-8b83cd935aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blend\n",
    "\n",
    "pred_1 = pd.read_csv(\"lama_utilized.csv\")\n",
    "pred_2 = pd.read_csv(\"lgmb_oe_ohe_cols_0805.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94ae7c5f-c2fb-4664-91b8-b96426b01161",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1[\"target\"] = 0.8 * pred_1[\"target\"] + 0.2 * pred_2[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fffbc0e9-f3ac-4696-9a7b-4174aad90a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1.to_csv(\"blend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67f921f8-cf49-45f5-bcbe-1c3e910f3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack \n",
    "#from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e40bf7-b86f-421c-8d40-abce8c42150a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_kernel",
   "language": "python",
   "name": "base_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
