{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa3af6a-d478-4c0e-a715-21f3f6707c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../../../automl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe599f1-83eb-4e6b-8115-f05eb659ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.automl.model.lama import TabularLamaUtilized\n",
    "from src.automl.loggers import configure_root_logger\n",
    "from src.automl.constants import create_ml_data_dir\n",
    "from src.automl.model.metrics import RocAuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087a93ef-e784-4dbb-8962-24e871577fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ml_data_dir()\n",
    "configure_root_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4701a7-04a9-42cd-b472-d9ca1dce955d",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9446b478-3af7-4d89-8d52-0d16996734e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 77\n",
    "DATA_PATH = Path(\"../../../data/\")\n",
    "CONFIG_PATH = Path(\"../../../configs/config.yaml\")\n",
    "N_JOBS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5494d0ab-4d12-47b3-bbaa-31fd51961cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CONFIG_PATH.open() as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1cf46-0712-400d-b190-15de4b596d15",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7208e0bf-13a0-4f7a-9f2e-307f386ef935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(DATA_PATH / \"train_preproc_2.parquet\")\n",
    "df_train, df_test = df_train.sort_values(by=\"id\").iloc[:300_000], df_train.sort_values(by=\"id\").iloc[300_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b73ba9-d6c5-4e83-b7ed-480881d44647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    282256\n",
       "1     17744\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83dba0de-f224-4a5a-84db-acb5ff2ba670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample the 0 class\n",
    "#df_train = pd.concat([df_train.loc[df_train.target == 1], df_train.loc[df_train.target == 0].sample(200_000, random_state=RANDOM_SEED)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a4bbaca-2b74-4177-88e4-4897ff07498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = df_train.drop(columns=[\"target\", \"id\"]).select_dtypes(int).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2525aeac-d91b-4864-a2cb-24f94702c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train[cfg[\"selected_features\"] + cat_columns], df_train[\"target\"]\n",
    "X_test, y_test = df_test[cfg[\"selected_features\"] + cat_columns], df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f28cd79-395e-4e5d-9fa6-015a640955d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940853\n",
       "1    0.059147\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.941322\n",
       "1    0.058678\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train.value_counts(normalize=True))\n",
    "display(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12b00734-0a36-4487-93ed-c78e6833ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_features = ohe_cols# + oe_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48abfc9d-95b1-4eda-9665-251676ed3d8f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b32e8180-6799-428d-93d8-50f8c19a074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = RocAuc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bab46f5-c9c4-4567-8fae-11296a05f4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-06 15:11:26,708] - [   START    ] - Fitting TabularLamaUtilized\n",
      "[15:11:26] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[15:11:26] - time: 7200.00 seconds\n",
      "[15:11:26] - CPU: 16 cores\n",
      "[15:11:26] - memory: 16 GB\n",
      "\n",
      "[15:11:26] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[15:11:26] ==================================================\n",
      "[15:11:26] Start 0 automl preset configuration:\n",
      "[15:11:26] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[15:11:26] Stdout logging level is INFO.\n",
      "[15:11:26] Task: binary\n",
      "\n",
      "[15:11:26] Start automl preset with listed constraints:\n",
      "[15:11:26] - time: 7200.00 seconds\n",
      "[15:11:26] - CPU: 16 cores\n",
      "[15:11:26] - memory: 16 GB\n",
      "\n",
      "[15:11:26] \u001b[1mTrain data shape: (300000, 63)\u001b[0m\n",
      "\n",
      "[15:11:37] Layer \u001b[1m1\u001b[0m train process start. Time left 7189.72 secs\n",
      "[15:11:45] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[15:12:22] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7887615115785954\u001b[0m\n",
      "[15:12:22] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[15:12:22] Time left 7144.35 secs\n",
      "\n",
      "[15:12:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[15:13:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8096767352141913\u001b[0m\n",
      "[15:13:06] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:13:06] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[15:13:06] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[15:18:13] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[15:18:13] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[15:18:54] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8123789008468237\u001b[0m\n",
      "[15:18:54] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:18:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[15:19:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8074882408029503\u001b[0m\n",
      "[15:19:29] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:19:29] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[15:24:32] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[15:24:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[15:25:34] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8080419731185968\u001b[0m\n",
      "[15:25:34] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:25:34] Time left 6352.65 secs\n",
      "\n",
      "[15:25:34] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:25:34] Blending: optimization starts with equal weights and score \u001b[1m0.8101471604603747\u001b[0m\n",
      "[15:25:38] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8128099819014584\u001b[0m, weights = \u001b[1m[0.         0.1496114  0.7052956  0.06690707 0.07818598]\u001b[0m\n",
      "[15:25:42] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8128245762275792\u001b[0m, weights = \u001b[1m[0.         0.20008339 0.65861875 0.06828621 0.07301158]\u001b[0m\n",
      "[15:25:46] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8128246348297083\u001b[0m, weights = \u001b[1m[0.         0.20282824 0.65635884 0.0680519  0.07276106]\u001b[0m\n",
      "[15:25:49] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8128246348297083\u001b[0m, weights = \u001b[1m[0.         0.20282824 0.65635884 0.0680519  0.07276106]\u001b[0m\n",
      "[15:25:49] Blending: no score update. Terminated\n",
      "\n",
      "[15:25:49] \u001b[1mAutoml preset training completed in 863.15 seconds\u001b[0m\n",
      "\n",
      "[15:25:49] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.20283 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.65636 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.06805 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.07276 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[15:25:49] ==================================================\n",
      "[15:25:49] Start 1 automl preset configuration:\n",
      "[15:25:49] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n",
      "[15:25:50] Stdout logging level is INFO.\n",
      "[15:25:50] Task: binary\n",
      "\n",
      "[15:25:50] Start automl preset with listed constraints:\n",
      "[15:25:50] - time: 6336.82 seconds\n",
      "[15:25:50] - CPU: 16 cores\n",
      "[15:25:50] - memory: 16 GB\n",
      "\n",
      "[15:25:50] \u001b[1mTrain data shape: (300000, 63)\u001b[0m\n",
      "\n",
      "[15:26:00] Layer \u001b[1m1\u001b[0m train process start. Time left 6326.72 secs\n",
      "[15:26:08] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[15:26:44] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7888683823944155\u001b[0m\n",
      "[15:26:44] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[15:26:44] Time left 6282.35 secs\n",
      "\n",
      "[15:26:53] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:27:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[15:27:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8103793717459785\u001b[0m\n",
      "[15:27:41] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:27:41] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[15:32:48] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[15:32:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[15:33:24] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8131754392537656\u001b[0m\n",
      "[15:33:24] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:33:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[15:33:57] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8067478811722391\u001b[0m\n",
      "[15:33:57] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:33:57] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[15:39:05] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[15:39:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[15:40:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8084925210617211\u001b[0m\n",
      "[15:40:12] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:40:12] Time left 5474.24 secs\n",
      "\n",
      "[15:40:12] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:40:12] Blending: optimization starts with equal weights and score \u001b[1m0.8106265463414664\u001b[0m\n",
      "[15:40:17] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.813550809350869\u001b[0m, weights = \u001b[1m[0.         0.14510722 0.74600303 0.         0.10888976]\u001b[0m\n",
      "[15:40:21] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8135740102032925\u001b[0m, weights = \u001b[1m[0.         0.2028493  0.69802606 0.         0.09912467]\u001b[0m\n",
      "[15:40:26] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8135741909015096\u001b[0m, weights = \u001b[1m[0.         0.20604211 0.69523025 0.         0.09872764]\u001b[0m\n",
      "[15:40:30] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8135741909015096\u001b[0m, weights = \u001b[1m[0.         0.20604211 0.69523025 0.         0.09872764]\u001b[0m\n",
      "[15:40:30] Blending: no score update. Terminated\n",
      "\n",
      "[15:40:30] \u001b[1mAutoml preset training completed in 880.55 seconds\u001b[0m\n",
      "\n",
      "[15:40:30] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.20604 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.69523 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.09873 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[15:40:30] ==================================================\n",
      "[15:40:30] Start 2 automl preset configuration:\n",
      "[15:40:30] \u001b[1mconf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'nn_params': {'random_state': 44}, 'general_params': {'return_all_predictions': False}}\n",
      "[15:40:30] Stdout logging level is INFO.\n",
      "[15:40:30] Task: binary\n",
      "\n",
      "[15:40:30] Start automl preset with listed constraints:\n",
      "[15:40:30] - time: 5456.24 seconds\n",
      "[15:40:30] - CPU: 16 cores\n",
      "[15:40:30] - memory: 16 GB\n",
      "\n",
      "[15:40:30] \u001b[1mTrain data shape: (300000, 63)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:40:31] Layer \u001b[1m1\u001b[0m train process start. Time left 5455.51 secs\n",
      "[15:40:40] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[15:41:17] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7888030003884329\u001b[0m\n",
      "[15:41:17] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[15:41:17] Time left 5408.93 secs\n",
      "\n",
      "[15:41:25] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:41:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[15:42:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8102081895361546\u001b[0m\n",
      "[15:42:11] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:42:11] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[15:47:14] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[15:47:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[15:47:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8127002275014914\u001b[0m\n",
      "[15:47:53] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:47:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[15:48:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8073442059545137\u001b[0m\n",
      "[15:48:31] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:48:31] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[15:53:38] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[15:53:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[15:54:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8083210429460873\u001b[0m\n",
      "[15:54:50] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:54:50] Time left 4596.24 secs\n",
      "\n",
      "[15:54:50] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:54:50] Blending: optimization starts with equal weights and score \u001b[1m0.8106015377082045\u001b[0m\n",
      "[15:54:54] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8133443717208684\u001b[0m, weights = \u001b[1m[0.         0.16847594 0.6568069  0.0591018  0.11561534]\u001b[0m\n",
      "[15:54:58] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8133586276122069\u001b[0m, weights = \u001b[1m[0.         0.21781297 0.6192404  0.05512017 0.10782645]\u001b[0m\n",
      "[15:55:02] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8133589332018439\u001b[0m, weights = \u001b[1m[0.         0.22016114 0.6173814  0.05495469 0.10750274]\u001b[0m\n",
      "[15:55:06] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8133589332018439\u001b[0m, weights = \u001b[1m[0.         0.22016114 0.6173814  0.05495469 0.10750274]\u001b[0m\n",
      "[15:55:06] Blending: no score update. Terminated\n",
      "\n",
      "[15:55:06] \u001b[1mAutoml preset training completed in 875.50 seconds\u001b[0m\n",
      "\n",
      "[15:55:06] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.22016 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.61738 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.05495 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.10750 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[15:55:06] ==================================================\n",
      "[15:55:06] Start 3 automl preset configuration:\n",
      "[15:55:06] \u001b[1mconf_3_sel_type_1_no_inter_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'nn_params': {'random_state': 45}, 'general_params': {'return_all_predictions': False}}\n",
      "[15:55:06] Stdout logging level is INFO.\n",
      "[15:55:06] Task: binary\n",
      "\n",
      "[15:55:06] Start automl preset with listed constraints:\n",
      "[15:55:06] - time: 4580.71 seconds\n",
      "[15:55:06] - CPU: 16 cores\n",
      "[15:55:06] - memory: 16 GB\n",
      "\n",
      "[15:55:06] \u001b[1mTrain data shape: (300000, 63)\u001b[0m\n",
      "\n",
      "[15:55:16] Layer \u001b[1m1\u001b[0m train process start. Time left 4570.73 secs\n",
      "[15:55:25] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[15:56:03] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.78876273383731\u001b[0m\n",
      "[15:56:03] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[15:56:03] Time left 4523.71 secs\n",
      "\n",
      "[15:56:11] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:56:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[15:56:49] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8095915122444594\u001b[0m\n",
      "[15:56:49] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:56:49] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:01:52] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[16:01:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:02:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8124696372086792\u001b[0m\n",
      "[16:02:29] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:02:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[16:03:05] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8074233884124606\u001b[0m\n",
      "[16:03:05] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:03:05] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:08:06] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[16:08:06] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:09:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8080596814440499\u001b[0m\n",
      "[16:09:16] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:09:16] Time left 3730.42 secs\n",
      "\n",
      "[16:09:16] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[16:09:16] Blending: optimization starts with equal weights and score \u001b[1m0.8101742874557749\u001b[0m\n",
      "[16:09:20] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8128764795442238\u001b[0m, weights = \u001b[1m[0.         0.12838541 0.723362   0.06749443 0.08075807]\u001b[0m\n",
      "[16:09:24] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8128912795268793\u001b[0m, weights = \u001b[1m[0.         0.18067363 0.6832881  0.06440581 0.07163249]\u001b[0m\n",
      "[16:09:27] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8128918321040243\u001b[0m, weights = \u001b[1m[0.         0.18059121 0.6854255  0.07107104 0.0629122 ]\u001b[0m\n",
      "[16:09:31] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8128920890748592\u001b[0m, weights = \u001b[1m[0.         0.18303369 0.6764706  0.07840545 0.06209027]\u001b[0m\n",
      "[16:09:35] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8128920890748592\u001b[0m, weights = \u001b[1m[0.         0.18303369 0.6764706  0.07840545 0.06209027]\u001b[0m\n",
      "[16:09:35] Blending: no score update. Terminated\n",
      "\n",
      "[16:09:35] \u001b[1mAutoml preset training completed in 869.40 seconds\u001b[0m\n",
      "\n",
      "[16:09:35] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.18303 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.67647 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.07841 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.06209 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[16:09:35] ==================================================\n",
      "[16:09:35] Start 4 automl preset configuration:\n",
      "[16:09:35] \u001b[1mconf_4_sel_type_0_no_int.yml\u001b[0m, random state: {'reader_params': {'random_state': 46}, 'nn_params': {'random_state': 46}, 'general_params': {'return_all_predictions': False}}\n",
      "[16:09:35] Stdout logging level is INFO.\n",
      "[16:09:35] Task: binary\n",
      "\n",
      "[16:09:35] Start automl preset with listed constraints:\n",
      "[16:09:35] - time: 3711.28 seconds\n",
      "[16:09:35] - CPU: 16 cores\n",
      "[16:09:35] - memory: 16 GB\n",
      "\n",
      "[16:09:35] \u001b[1mTrain data shape: (300000, 63)\u001b[0m\n",
      "\n",
      "[16:09:45] Layer \u001b[1m1\u001b[0m train process start. Time left 3701.33 secs\n",
      "[16:09:46] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[16:10:18] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7889009066758471\u001b[0m\n",
      "[16:10:18] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[16:10:18] Time left 3667.97 secs\n",
      "\n",
      "[16:10:19] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[16:10:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8102868703319241\u001b[0m\n",
      "[16:10:56] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:10:56] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:03] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[16:16:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:16:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.812073111942671\u001b[0m\n",
      "[16:16:39] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:16:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[16:17:13] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8072995972551813\u001b[0m\n",
      "[16:17:13] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:17:13] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:22:14] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[16:22:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:23:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8078172918571538\u001b[0m\n",
      "[16:23:20] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:23:20] Time left 2886.61 secs\n",
      "\n",
      "[16:23:20] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[16:23:20] Blending: optimization starts with equal weights and score \u001b[1m0.8103930245445381\u001b[0m\n",
      "[16:23:24] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8129432671028032\u001b[0m, weights = \u001b[1m[0.         0.23204911 0.6289174  0.06079729 0.07823623]\u001b[0m\n",
      "[16:23:28] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8129716217479146\u001b[0m, weights = \u001b[1m[0.         0.30474836 0.5702936  0.06582752 0.05913058]\u001b[0m\n",
      "[16:23:32] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8129720857729497\u001b[0m, weights = \u001b[1m[0.         0.30126095 0.56376743 0.07651763 0.05845391]\u001b[0m\n",
      "[16:23:36] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8129724685337036\u001b[0m, weights = \u001b[1m[0.         0.2997443  0.57373613 0.07613242 0.05038711]\u001b[0m\n",
      "[16:23:39] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8129724685337036\u001b[0m, weights = \u001b[1m[0.         0.2997443  0.57373613 0.07613242 0.05038711]\u001b[0m\n",
      "[16:23:39] Blending: no score update. Terminated\n",
      "\n",
      "[16:23:39] \u001b[1mAutoml preset training completed in 844.43 seconds\u001b[0m\n",
      "\n",
      "[16:23:39] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.29974 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.57374 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.07613 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.05039 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[16:23:39] ==================================================\n",
      "[16:23:39] Start 5 automl preset configuration:\n",
      "[16:23:39] \u001b[1mconf_5_sel_type_1_tuning_full.yml\u001b[0m, random state: {'reader_params': {'random_state': 47}, 'nn_params': {'random_state': 47}, 'general_params': {'return_all_predictions': False}}\n",
      "[16:23:40] Stdout logging level is INFO.\n",
      "[16:23:40] Task: binary\n",
      "\n",
      "[16:23:40] Start automl preset with listed constraints:\n",
      "[16:23:40] - time: 2866.83 seconds\n",
      "[16:23:40] - CPU: 16 cores\n",
      "[16:23:40] - memory: 16 GB\n",
      "\n",
      "[16:23:40] \u001b[1mTrain data shape: (300000, 63)\u001b[0m\n",
      "\n",
      "[16:23:50] Layer \u001b[1m1\u001b[0m train process start. Time left 2856.74 secs\n",
      "[16:23:58] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[16:24:35] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7888219915713949\u001b[0m\n",
      "[16:24:35] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[16:24:35] Time left 2811.24 secs\n",
      "\n",
      "[16:24:42] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:24:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[16:25:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8100260213738908\u001b[0m\n",
      "[16:25:28] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:25:28] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:25:28] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:26:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8086342784137879\u001b[0m\n",
      "[16:26:07] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:26:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:26:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.811809547519716\u001b[0m\n",
      "[16:26:58] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:26:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:27:34] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8087454632248354\u001b[0m\n",
      "[16:27:34] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:27:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:28:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8095745332010376\u001b[0m\n",
      "[16:28:10] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:28:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:28:45] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8067658814101712\u001b[0m\n",
      "[16:28:45] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:28:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:29:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8120054709094735\u001b[0m\n",
      "[16:29:35] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:29:35] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:30:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8105540547092193\u001b[0m\n",
      "[16:30:22] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:30:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:31:01] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8071340191859225\u001b[0m\n",
      "[16:31:01] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:31:01] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[16:31:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:31:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8119239668288516\u001b[0m\n",
      "[16:31:39] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:31:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[16:32:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.806779706021787\u001b[0m\n",
      "[16:32:12] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:32:12] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:32:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:33:09] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8082567062942662\u001b[0m\n",
      "[16:33:09] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:33:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:33:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8059782417415109\u001b[0m\n",
      "[16:33:39] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:33:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:34:38] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8075331092684492\u001b[0m\n",
      "[16:34:38] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:34:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:35:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8050988296413276\u001b[0m\n",
      "[16:35:02] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:35:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:35:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7985570224663894\u001b[0m\n",
      "[16:35:22] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:35:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:36:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8072087684477186\u001b[0m\n",
      "[16:36:16] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:36:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:36:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8065595727647544\u001b[0m\n",
      "[16:36:48] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:36:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:37:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.807202505108077\u001b[0m\n",
      "[16:37:40] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:37:40] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[16:37:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:38:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8082548081643194\u001b[0m\n",
      "[16:38:53] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:38:53] Time left 1953.47 secs\n",
      "\n",
      "[16:38:53] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[16:38:53] Blending: optimization starts with equal weights and score \u001b[1m0.8101075398305033\u001b[0m\n",
      "[16:38:57] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8127831329417126\u001b[0m, weights = \u001b[1m[0.         0.22282583 0.633284   0.         0.14389022]\u001b[0m\n",
      "[16:39:01] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.812816770064596\u001b[0m, weights = \u001b[1m[0.         0.30053276 0.5699641  0.         0.12950313]\u001b[0m\n",
      "[16:39:04] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8128167706635956\u001b[0m, weights = \u001b[1m[0.         0.3005317  0.569965   0.         0.12950332]\u001b[0m\n",
      "[16:39:08] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8128167706635956\u001b[0m, weights = \u001b[1m[0.         0.3005317  0.569965   0.         0.12950332]\u001b[0m\n",
      "[16:39:08] Blending: no score update. Terminated\n",
      "\n",
      "[16:39:08] \u001b[1mAutoml preset training completed in 928.83 seconds\u001b[0m\n",
      "\n",
      "[16:39:08] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.30053 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.56997 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.12950 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[16:39:08] ==================================================\n",
      "[16:39:08] Start 6 automl preset configuration:\n",
      "[16:39:08] \u001b[1mconf_6_sel_type_1_tuning_full_no_int_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 48}, 'nn_params': {'random_state': 48}, 'general_params': {'return_all_predictions': False}}\n",
      "[16:39:08] Stdout logging level is INFO.\n",
      "[16:39:08] Task: binary\n",
      "\n",
      "[16:39:08] Start automl preset with listed constraints:\n",
      "[16:39:08] - time: 1937.97 seconds\n",
      "[16:39:08] - CPU: 16 cores\n",
      "[16:39:08] - memory: 16 GB\n",
      "\n",
      "[16:39:08] \u001b[1mTrain data shape: (300000, 63)\u001b[0m\n",
      "\n",
      "[16:39:18] Layer \u001b[1m1\u001b[0m train process start. Time left 1927.99 secs\n",
      "[16:39:27] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[16:40:10] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7887185802778518\u001b[0m\n",
      "[16:40:10] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[16:40:10] Time left 1876.52 secs\n",
      "\n",
      "[16:40:18] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:40:19] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[16:40:54] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8096095475238692\u001b[0m\n",
      "[16:40:54] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:40:54] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 290.85 secs\n",
      "[16:45:54] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[16:45:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:46:32] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8127205067332923\u001b[0m\n",
      "[16:46:32] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:46:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[16:47:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8073264513064236\u001b[0m\n",
      "[16:47:08] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:47:08] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:52:13] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[16:52:13] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:53:05] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8085843427110456\u001b[0m\n",
      "[16:53:05] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:53:05] Time left 1101.31 secs\n",
      "\n",
      "[16:53:05] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[16:53:05] Blending: optimization starts with equal weights and score \u001b[1m0.8105057814300753\u001b[0m\n",
      "[16:53:09] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8133105396236104\u001b[0m, weights = \u001b[1m[0.         0.12411588 0.684848   0.         0.1910361 ]\u001b[0m\n",
      "[16:53:13] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8133179032257116\u001b[0m, weights = \u001b[1m[0.         0.1595247  0.65883064 0.         0.18164465]\u001b[0m\n",
      "[16:53:17] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.813317953441846\u001b[0m, weights = \u001b[1m[0.         0.16017085 0.6583242  0.         0.18150501]\u001b[0m\n",
      "[16:53:21] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8133179537413459\u001b[0m, weights = \u001b[1m[0.         0.16017085 0.6583241  0.         0.18150501]\u001b[0m\n",
      "[16:53:24] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8133179535416792\u001b[0m, weights = \u001b[1m[0.         0.1601802  0.65831685 0.         0.181503  ]\u001b[0m\n",
      "[16:53:24] Blending: no score update. Terminated\n",
      "\n",
      "[16:53:24] \u001b[1mAutoml preset training completed in 856.02 seconds\u001b[0m\n",
      "\n",
      "[16:53:24] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.16017 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.65832 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.18151 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[16:53:24] ==================================================\n",
      "[16:53:24] ==================================================\n",
      "[16:53:24] Start 0 automl preset configuration:\n",
      "[16:53:24] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 49}, 'nn_params': {'random_state': 49}, 'general_params': {'return_all_predictions': False}}\n",
      "[16:53:24] Stdout logging level is INFO.\n",
      "[16:53:24] Task: binary\n",
      "\n",
      "[16:53:24] Start automl preset with listed constraints:\n",
      "[16:53:24] - time: 1081.93 seconds\n",
      "[16:53:24] - CPU: 16 cores\n",
      "[16:53:24] - memory: 16 GB\n",
      "\n",
      "[16:53:24] \u001b[1mTrain data shape: (300000, 63)\u001b[0m\n",
      "\n",
      "[16:53:34] Layer \u001b[1m1\u001b[0m train process start. Time left 1071.94 secs\n",
      "[16:53:43] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[16:54:15] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7887384271317639\u001b[0m\n",
      "[16:54:15] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[16:54:15] Time left 1031.00 secs\n",
      "\n",
      "[16:54:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[16:55:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8099857237746212\u001b[0m\n",
      "[16:55:02] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:55:02] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 100.96 secs\n",
      "[16:56:51] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[16:56:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:57:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8116914176076316\u001b[0m\n",
      "[16:57:36] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:57:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[16:58:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8075009334051267\u001b[0m\n",
      "[16:58:19] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:58:19] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:03:24] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[17:03:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:04:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.808792575443059\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:04:39] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:04:39] Time left 406.87 secs\n",
      "\n",
      "[17:04:39] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:04:40] Blending: optimization starts with equal weights and score \u001b[1m0.8105832568389526\u001b[0m\n",
      "[17:04:43] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8129764974051146\u001b[0m, weights = \u001b[1m[0.         0.2100713  0.5476953  0.05638938 0.18584405]\u001b[0m\n",
      "[17:04:47] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8130014665044016\u001b[0m, weights = \u001b[1m[0.         0.25869945 0.5184821  0.         0.22281848]\u001b[0m\n",
      "[17:04:51] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8130018483666561\u001b[0m, weights = \u001b[1m[0.        0.2589566 0.5200349 0.        0.2210085]\u001b[0m\n",
      "[17:04:55] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8130018483666561\u001b[0m, weights = \u001b[1m[0.        0.2589566 0.5200349 0.        0.2210085]\u001b[0m\n",
      "[17:04:55] Blending: no score update. Terminated\n",
      "\n",
      "[17:04:55] \u001b[1mAutoml preset training completed in 690.41 seconds\u001b[0m\n",
      "\n",
      "[17:04:55] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.25896 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.52003 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.22101 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[17:04:55] ==================================================\n",
      "[17:04:55] Blending: optimization starts with equal weights and score \u001b[1m0.8146176644039262\u001b[0m\n",
      "[17:05:01] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8147339243390456\u001b[0m, weights = \u001b[1m[0.         0.27805185 0.25926656 0.         0.13371192 0.10656334\n",
      " 0.22240636]\u001b[0m\n",
      "[17:05:06] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8147353933856015\u001b[0m, weights = \u001b[1m[0.         0.28948614 0.23203279 0.         0.14948915 0.11250022\n",
      " 0.21649173]\u001b[0m\n",
      "[17:05:12] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8147356517541021\u001b[0m, weights = \u001b[1m[0.         0.28363687 0.23935187 0.         0.15028234 0.11309714\n",
      " 0.21363181]\u001b[0m\n",
      "[17:05:18] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8147357239335559\u001b[0m, weights = \u001b[1m[0.         0.28436446 0.23823655 0.         0.15066785 0.11338726\n",
      " 0.21334386]\u001b[0m\n",
      "[17:05:23] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8147357367122143\u001b[0m, weights = \u001b[1m[0.         0.28439945 0.23816885 0.         0.15067819 0.11339504\n",
      " 0.2133585 ]\u001b[0m\n",
      "[2024-11-06 17:05:23,924] - [    END     ] - Fitting TabularLamaUtilized\n",
      "0.8147357367122143\n",
      "0.8077584480269768\n"
     ]
    }
   ],
   "source": [
    "model = TabularLamaUtilized(n_jobs=16, task=\"classification\")\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 60, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(metric(y_train, oof))\n",
    "print(metric(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6dd6ac2-6191-43c5-84da-522b4829abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lamau_8147\"\n",
    "MODEL_DIR = Path(f\"../../../data/models/{MODEL_NAME}\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e4fed09-b428-4509-8644-347cbbb27f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res[MODEL_NAME] = oof[:, 1]\n",
    "res.to_csv(MODEL_DIR / \"oof.csv\", index=False)\n",
    "joblib.dump(model, MODEL_DIR / f\"{MODEL_NAME}.joblib\")\n",
    "\n",
    "with (MODEL_DIR / \"params.yaml\").open(\"w\") as f:\n",
    "    yaml.dump(model.params, f)\n",
    "\n",
    "with (MODEL_DIR / \"score.txt\").open(\"w\") as f:\n",
    "    print(\"OOF:\", metric(y_train, oof), file=f)\n",
    "    print(\"Test:\", metric(y_test, y_pred), file=f)\n",
    "    \n",
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(MODEL_DIR / f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e490c4a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3645213-67f1-4a56-8449-706616b01975",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv('lgb_813.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b626f4-24d7-47cc-8e1c-8d4829422eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pd.read_csv(\"lama_utilized.csv\")\n",
    "pred_2 = pd.read_csv(\"lgmb_oe_ohe_cols_0805.csv\")\n",
    "pred_3 = pd.read_csv(\"catboost_ts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6fd1b74-1c84-47a2-9640-f9afca52a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1[\"target\"] = 0.6 * pred_1[\"target\"] + 0.2 * pred_2[\"target\"] + 0.2 * pred_3[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9a12186-27a7-43e5-bbf9-05d9894bd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1.to_csv(\"blend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1a479dff-a006-4237-9a22-9b4a9d6a52eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Open the file pointed by this path and return a file object, as\n",
       "the built-in open() function does.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/lib/python3.10/pathlib.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_DIR.open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9b1c6-0fb4-461a-9aa9-1c23e299671f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_kernel",
   "language": "python",
   "name": "base_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
