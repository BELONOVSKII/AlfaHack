{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa3af6a-d478-4c0e-a715-21f3f6707c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../../../automl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe599f1-83eb-4e6b-8115-f05eb659ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/lightautoml/ml_algo/dl_model.py:42: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/opt/conda/lib/python3.10/site-packages/lightautoml/text/embed.py:22: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/opt/conda/lib/python3.10/site-packages/lightautoml/text/dl_transformers.py:25: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.automl.model.lama import TabularLamaNN\n",
    "from src.automl.loggers import configure_root_logger\n",
    "from src.automl.constants import create_ml_data_dir\n",
    "from src.automl.model.metrics import RocAuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087a93ef-e784-4dbb-8962-24e871577fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ml_data_dir()\n",
    "configure_root_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4701a7-04a9-42cd-b472-d9ca1dce955d",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9446b478-3af7-4d89-8d52-0d16996734e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 77\n",
    "DATA_PATH = Path(\"../../../data/\")\n",
    "CONFIG_PATH = Path(\"../../../configs/config.yaml\")\n",
    "N_JOBS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5494d0ab-4d12-47b3-bbaa-31fd51961cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CONFIG_PATH.open() as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ecafa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1cf46-0712-400d-b190-15de4b596d15",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7208e0bf-13a0-4f7a-9f2e-307f386ef935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(DATA_PATH / \"train_preproc_2.parquet\")\n",
    "#df_train, df_test = df_train.sort_values(by=\"id\").iloc[:300_000], df_train.sort_values(by=\"id\").iloc[300_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b73ba9-d6c5-4e83-b7ed-480881d44647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940982\n",
       "1    0.059018\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83dba0de-f224-4a5a-84db-acb5ff2ba670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample the 0 class\n",
    "#df_train = pd.concat([df_train.loc[df_train.target == 1], df_train.loc[df_train.target == 0].sample(200_000, random_state=RANDOM_SEED)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4bbaca-2b74-4177-88e4-4897ff07498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = df_train.drop(columns=[\"target\", \"id\"]).select_dtypes(int).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2525aeac-d91b-4864-a2cb-24f94702c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train[cfg[\"selected_features\"] + cat_columns], df_train[\"target\"]\n",
    "#X_test, y_test = df_test[cfg[\"selected_features\"] + cat_columns], df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f28cd79-395e-4e5d-9fa6-015a640955d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940982\n",
       "1    0.059018\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train.value_counts(normalize=True))\n",
    "#display(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b00734-0a36-4487-93ed-c78e6833ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_features = ohe_cols# + oe_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48abfc9d-95b1-4eda-9665-251676ed3d8f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32e8180-6799-428d-93d8-50f8c19a074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = RocAuc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bab46f5-c9c4-4567-8fae-11296a05f4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 12:08:58,759] - [   START    ] - Fitting TabularLamaNN_autoint\n",
      "[12:08:58] Stdout logging level is DEBUG.\n",
      "[12:08:58] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[12:08:58] Task: binary\n",
      "\n",
      "[12:08:58] Start automl preset with listed constraints:\n",
      "[12:08:58] - time: 14400.00 seconds\n",
      "[12:08:58] - CPU: 16 cores\n",
      "[12:08:58] - memory: 16 GB\n",
      "\n",
      "[12:08:58] \u001b[1mTrain data shape: (413194, 63)\u001b[0m\n",
      "\n",
      "[12:09:14] Feats was rejected during automatic roles guess: []\n",
      "[12:09:14] Layer \u001b[1m1\u001b[0m train process start. Time left 14384.51 secs\n",
      "[12:09:23] number of text features: 0 \n",
      "[12:09:23] number of categorical features: 4 \n",
      "[12:09:23] number of continuous features: 58 \n",
      "[12:09:23] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m ...\n",
      "[12:09:23] Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': False, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'autoint', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 50, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 10, 'swa': True}, 'bs': 1024, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': 'UniversalDataset', 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 256], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': 'LeakyReLU', 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'device_ids': None, 'num_dims': 58, 'text_features': [], 'bias': array([-2.76907645])}\n",
      "[12:09:23] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m =====\n",
      "[12:10:01] Epoch: 0, train loss: 2.704885244369507, val loss: 0.3971446454524994, val metric: 0.6984737415607188\n",
      "[12:10:39] Epoch: 1, train loss: 0.7322951555252075, val loss: 0.19451665878295898, val metric: 0.784642849629815\n",
      "[12:11:17] Epoch: 2, train loss: 0.400200754404068, val loss: 0.19295044243335724, val metric: 0.7891592948367236\n",
      "[12:11:54] Epoch: 3, train loss: 0.5384109020233154, val loss: 0.21249039471149445, val metric: 0.7720548720667777\n",
      "[12:12:32] Epoch: 4, train loss: 0.3296090066432953, val loss: 0.192743718624115, val metric: 0.7957828592479705\n",
      "[12:13:10] Epoch: 5, train loss: 0.19823455810546875, val loss: 0.22322304546833038, val metric: 0.7954887158330153\n",
      "[12:13:47] Epoch: 6, train loss: 0.5059359669685364, val loss: 0.19178742170333862, val metric: 0.7966784722543439\n",
      "[12:14:25] Epoch: 7, train loss: 0.19351783394813538, val loss: 0.196466863155365, val metric: 0.7971818733857181\n",
      "[12:15:03] Epoch: 8, train loss: 0.19600772857666016, val loss: 0.22311392426490784, val metric: 0.7827917758046999\n",
      "[12:15:40] Epoch: 9, train loss: 0.29575636982917786, val loss: 0.19172951579093933, val metric: 0.7959476958439302\n",
      "[12:16:18] Epoch: 10, train loss: 0.19410675764083862, val loss: 0.18927697837352753, val metric: 0.8023336396276357\n",
      "[12:16:56] Epoch: 11, train loss: 0.19460275769233704, val loss: 0.19040419161319733, val metric: 0.7996319764290589\n",
      "[12:17:34] Epoch: 12, train loss: 0.1925390064716339, val loss: 0.1939440667629242, val metric: 0.8025549555035456\n",
      "[12:18:11] Epoch: 13, train loss: 0.19333085417747498, val loss: 0.189153254032135, val metric: 0.8035864133141446\n",
      "[12:18:49] Epoch: 14, train loss: 0.19354666769504547, val loss: 0.18977010250091553, val metric: 0.8028253504353492\n",
      "[12:19:27] Epoch: 15, train loss: 0.19304460287094116, val loss: 0.19125397503376007, val metric: 0.7995482614768193\n",
      "[12:20:05] Epoch: 16, train loss: 0.1914888173341751, val loss: 0.19332513213157654, val metric: 0.8005552443614631\n",
      "[12:20:43] Epoch: 17, train loss: 0.19262120127677917, val loss: 0.19588153064250946, val metric: 0.8039889127267016\n",
      "[12:21:22] Epoch: 18, train loss: 0.1895304173231125, val loss: 0.19088315963745117, val metric: 0.8027524517022723\n",
      "[12:22:00] Epoch: 19, train loss: 0.1875389814376831, val loss: 0.19034461677074432, val metric: 0.8017972084208491\n",
      "[12:22:38] Epoch: 20, train loss: 0.18502715229988098, val loss: 0.19373734295368195, val metric: 0.8007131553602431\n",
      "[12:23:16] Epoch: 21, train loss: 0.18435469269752502, val loss: 0.1922703981399536, val metric: 0.8004951157281923\n",
      "[12:23:54] Epoch: 22, train loss: 0.18337585031986237, val loss: 0.1951075941324234, val metric: 0.7963843697100362\n",
      "[12:24:31] Epoch: 23, train loss: 0.1822371929883957, val loss: 0.19321203231811523, val metric: 0.7973893644354286\n",
      "[12:25:09] Epoch: 24, train loss: 0.1813948005437851, val loss: 0.19392430782318115, val metric: 0.7949970168909738\n",
      "[12:25:15] Early stopping: val loss: 0.18882761895656586, val metric: 0.8046005050546786\n",
      "[12:25:15] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m =====\n",
      "[12:25:53] Epoch: 0, train loss: 3.461836814880371, val loss: 0.6560428738594055, val metric: 0.6267548214720798\n",
      "[12:26:31] Epoch: 1, train loss: 0.8502165079116821, val loss: 2.0200421810150146, val metric: 0.585869486668936\n",
      "[12:27:08] Epoch: 2, train loss: 0.3412470519542694, val loss: 0.19364020228385925, val metric: 0.7884517395462654\n",
      "[12:27:46] Epoch: 3, train loss: 0.7214998006820679, val loss: 0.19813063740730286, val metric: 0.7876381605219424\n",
      "[12:28:23] Epoch: 4, train loss: 0.20069338381290436, val loss: 0.1957775354385376, val metric: 0.7904876739479159\n",
      "[12:29:01] Epoch: 5, train loss: 0.20088934898376465, val loss: 0.20170371234416962, val metric: 0.7893302673034761\n",
      "[12:29:38] Epoch: 6, train loss: 0.34118881821632385, val loss: 0.19128280878067017, val metric: 0.7947830181794171\n",
      "[12:30:16] Epoch: 7, train loss: 0.19944173097610474, val loss: 0.1926811933517456, val metric: 0.7969535514897412\n",
      "[12:30:55] Epoch: 8, train loss: 0.21251918375492096, val loss: 0.2118409425020218, val metric: 0.7966419378504899\n",
      "[12:31:33] Epoch: 9, train loss: 0.32080623507499695, val loss: 0.19027090072631836, val metric: 0.7996376297625267\n",
      "[12:32:12] Epoch: 10, train loss: 0.19498829543590546, val loss: 0.19256460666656494, val metric: 0.7999018426792577\n",
      "[12:32:50] Epoch: 11, train loss: 0.19988305866718292, val loss: 0.19359152019023895, val metric: 0.8008003324518685\n",
      "[12:33:29] Epoch: 12, train loss: 0.23914361000061035, val loss: 0.2063084840774536, val metric: 0.7839466840659959\n",
      "[12:34:08] Epoch: 13, train loss: 0.19320546090602875, val loss: 0.1912297010421753, val metric: 0.8019759594947516\n",
      "[12:34:47] Epoch: 14, train loss: 0.1915282905101776, val loss: 0.18891708552837372, val metric: 0.8039847927017278\n",
      "[12:35:25] Epoch: 15, train loss: 0.19302260875701904, val loss: 0.1918020099401474, val metric: 0.7989602844727869\n",
      "[12:36:03] Epoch: 16, train loss: 0.19060660898685455, val loss: 0.1921873539686203, val metric: 0.8008885774539672\n",
      "[12:36:41] Epoch: 17, train loss: 0.19055044651031494, val loss: 0.1920933723449707, val metric: 0.8040382963348411\n",
      "[12:37:19] Epoch: 18, train loss: 0.18987281620502472, val loss: 0.20330744981765747, val metric: 0.8005673921726971\n",
      "[12:37:57] Epoch: 19, train loss: 0.18933698534965515, val loss: 0.18943335115909576, val metric: 0.8050813482253176\n",
      "[12:38:35] Epoch: 20, train loss: 0.18769417703151703, val loss: 0.19103394448757172, val metric: 0.8014631119701179\n",
      "[12:39:13] Epoch: 21, train loss: 0.18445168435573578, val loss: 0.18989835679531097, val metric: 0.7997150163564068\n",
      "[12:39:50] Epoch: 22, train loss: 0.18377487361431122, val loss: 0.18966297805309296, val metric: 0.7995806455323158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:40:28] Epoch: 23, train loss: 0.183428555727005, val loss: 0.19311760365962982, val metric: 0.7957049808879094\n",
      "[12:41:06] Epoch: 24, train loss: 0.18255187571048737, val loss: 0.19092701375484467, val metric: 0.7976241610330523\n",
      "[12:41:43] Epoch: 25, train loss: 0.1813998967409134, val loss: 0.1934359222650528, val metric: 0.7935573166826069\n",
      "[12:42:21] Epoch: 26, train loss: 0.17998187243938446, val loss: 0.19299423694610596, val metric: 0.7897826605480652\n",
      "[12:42:59] Epoch: 27, train loss: 0.1777971237897873, val loss: 0.19352443516254425, val metric: 0.791000470054638\n",
      "[12:43:36] Epoch: 28, train loss: 0.17629578709602356, val loss: 0.19533847272396088, val metric: 0.7896064223597945\n",
      "[12:44:14] Epoch: 29, train loss: 0.17584431171417236, val loss: 0.19515475630760193, val metric: 0.7886150705202986\n",
      "[12:44:52] Epoch: 30, train loss: 0.17505429685115814, val loss: 0.19657976925373077, val metric: 0.7848700337396953\n",
      "[12:45:29] Epoch: 31, train loss: 0.1741061806678772, val loss: 0.19709566235542297, val metric: 0.7834952822642163\n",
      "[12:46:07] Epoch: 32, train loss: 0.1734192818403244, val loss: 0.19697287678718567, val metric: 0.7842143749430086\n",
      "[12:46:13] Early stopping: val loss: 0.18825235962867737, val metric: 0.8057170832404361\n",
      "[12:46:14] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m =====\n",
      "[12:46:52] Epoch: 0, train loss: 2.4017319679260254, val loss: 2.755488157272339, val metric: 0.494044873714102\n",
      "[12:47:29] Epoch: 1, train loss: 0.576862633228302, val loss: 0.1966603547334671, val metric: 0.7837937144603679\n",
      "[12:48:07] Epoch: 2, train loss: 0.7858892679214478, val loss: 0.19452372193336487, val metric: 0.7836134630381708\n",
      "[12:48:45] Epoch: 3, train loss: 0.20130908489227295, val loss: 0.21074657142162323, val metric: 0.7803717456476464\n",
      "[12:49:22] Epoch: 4, train loss: 0.44086775183677673, val loss: 0.1924557089805603, val metric: 0.7906591421360731\n",
      "[12:50:00] Epoch: 5, train loss: 0.20003028213977814, val loss: 0.199134960770607, val metric: 0.7922339844372062\n",
      "[12:50:37] Epoch: 6, train loss: 0.36697885394096375, val loss: 1.197986125946045, val metric: 0.6071160665274369\n",
      "[12:51:15] Epoch: 7, train loss: 0.22234207391738892, val loss: 0.19100764393806458, val metric: 0.7973938997589196\n",
      "[12:51:52] Epoch: 8, train loss: 0.19391340017318726, val loss: 0.19371147453784943, val metric: 0.7982164980123128\n",
      "[12:52:30] Epoch: 9, train loss: 0.20080935955047607, val loss: 0.3762875199317932, val metric: 0.7820722032253986\n",
      "[12:53:08] Epoch: 10, train loss: 0.2018219381570816, val loss: 0.19191095232963562, val metric: 0.798574928319344\n",
      "[12:53:46] Epoch: 11, train loss: 0.26245003938674927, val loss: 0.18988098204135895, val metric: 0.79919671589632\n",
      "[12:54:25] Epoch: 12, train loss: 0.19091719388961792, val loss: 0.18965889513492584, val metric: 0.8009375167586136\n",
      "[12:55:02] Epoch: 13, train loss: 0.19021950662136078, val loss: 0.19190272688865662, val metric: 0.7980400831573711\n",
      "[12:55:40] Epoch: 14, train loss: 0.19020594656467438, val loss: 0.18962663412094116, val metric: 0.8013843014956068\n",
      "[12:56:18] Epoch: 15, train loss: 0.19015763700008392, val loss: 0.19035235047340393, val metric: 0.797879216287874\n",
      "[12:56:56] Epoch: 16, train loss: 0.18873977661132812, val loss: 0.1902632713317871, val metric: 0.7984229633406059\n",
      "[12:57:34] Epoch: 17, train loss: 0.19023016095161438, val loss: 0.1897210031747818, val metric: 0.8001049183806046\n",
      "[12:58:11] Epoch: 18, train loss: 0.1895492523908615, val loss: 0.19228512048721313, val metric: 0.7975251710058224\n",
      "[12:58:49] Epoch: 19, train loss: 0.1873987466096878, val loss: 0.19122914969921112, val metric: 0.7993476828402086\n",
      "[12:59:27] Epoch: 20, train loss: 0.1887039989233017, val loss: 0.19066013395786285, val metric: 0.797443477173034\n",
      "[13:00:04] Epoch: 21, train loss: 0.18206296861171722, val loss: 0.19601556658744812, val metric: 0.7941855354537655\n",
      "[13:00:42] Epoch: 22, train loss: 0.18167312443256378, val loss: 0.19197393953800201, val metric: 0.794753231387664\n",
      "[13:01:20] Epoch: 23, train loss: 0.18103304505348206, val loss: 0.19262681901454926, val metric: 0.7938483697492298\n",
      "[13:01:57] Epoch: 24, train loss: 0.17983518540859222, val loss: 0.19433216750621796, val metric: 0.7915203578779468\n",
      "[13:02:35] Epoch: 25, train loss: 0.1785925179719925, val loss: 0.19575953483581543, val metric: 0.7878457979149399\n",
      "[13:03:13] Epoch: 26, train loss: 0.17754359543323517, val loss: 0.19500000774860382, val metric: 0.7862621539220552\n",
      "[13:03:51] Epoch: 27, train loss: 0.17447717487812042, val loss: 0.19705639779567719, val metric: 0.78438458009631\n",
      "[13:03:57] Early stopping: val loss: 0.18900567293167114, val metric: 0.8027094320495078\n",
      "[13:03:57] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m =====\n",
      "[13:04:36] Epoch: 0, train loss: 3.4016571044921875, val loss: 0.48977968096733093, val metric: 0.7057202215455238\n",
      "[13:05:13] Epoch: 1, train loss: 0.5447100400924683, val loss: 1.0821309089660645, val metric: 0.5855580620530167\n",
      "[13:05:51] Epoch: 2, train loss: 0.7290087342262268, val loss: 0.21157066524028778, val metric: 0.7690515213880165\n",
      "[13:06:28] Epoch: 3, train loss: 0.2274094521999359, val loss: 0.20286642014980316, val metric: 0.7801471212459067\n",
      "[13:07:06] Epoch: 4, train loss: 0.40814247727394104, val loss: 0.208372563123703, val metric: 0.7707327314396586\n",
      "[13:07:44] Epoch: 5, train loss: 0.36362704634666443, val loss: 2.4350290298461914, val metric: 0.5641662519620271\n",
      "[13:08:21] Epoch: 6, train loss: 0.36231377720832825, val loss: 0.19135014712810516, val metric: 0.7942090660473997\n",
      "[13:08:59] Epoch: 7, train loss: 0.19480325281620026, val loss: 0.19602113962173462, val metric: 0.7991291587469957\n",
      "[13:09:36] Epoch: 8, train loss: 0.19785092771053314, val loss: 0.20351701974868774, val metric: 0.7993638891392064\n",
      "[13:10:15] Epoch: 9, train loss: 0.28486740589141846, val loss: 0.19467365741729736, val metric: 0.7994992596689768\n",
      "[13:10:54] Epoch: 10, train loss: 0.19252131879329681, val loss: 0.19705460965633392, val metric: 0.8021361397626527\n",
      "[13:11:32] Epoch: 11, train loss: 0.19174788892269135, val loss: 0.18950004875659943, val metric: 0.8038211302818781\n",
      "[13:12:10] Epoch: 12, train loss: 0.19606667757034302, val loss: 0.19778238236904144, val metric: 0.800275576314488\n",
      "[13:12:48] Epoch: 13, train loss: 0.1970149278640747, val loss: 0.18952606618404388, val metric: 0.8038464243517707\n",
      "[13:13:26] Epoch: 14, train loss: 0.19129161536693573, val loss: 0.2019866406917572, val metric: 0.7976573191099383\n",
      "[13:14:04] Epoch: 15, train loss: 0.19254189729690552, val loss: 0.19570669531822205, val metric: 0.8044054563820802\n",
      "[13:14:41] Epoch: 16, train loss: 0.1912793666124344, val loss: 0.1941455602645874, val metric: 0.8018323367477704\n",
      "[13:15:19] Epoch: 17, train loss: 0.18958210945129395, val loss: 0.19304005801677704, val metric: 0.8044477757376435\n",
      "[13:15:57] Epoch: 18, train loss: 0.18598473072052002, val loss: 0.19227510690689087, val metric: 0.8046488905495529\n",
      "[13:16:34] Epoch: 19, train loss: 0.18557582795619965, val loss: 0.19332194328308105, val metric: 0.8021298178928729\n",
      "[13:17:12] Epoch: 20, train loss: 0.18630768358707428, val loss: 0.19132329523563385, val metric: 0.8037681892360133\n",
      "[13:17:50] Epoch: 21, train loss: 0.18478526175022125, val loss: 0.18949146568775177, val metric: 0.8029514843315252\n",
      "[13:18:28] Epoch: 22, train loss: 0.1843486726284027, val loss: 0.19015780091285706, val metric: 0.8016618426687604\n",
      "[13:19:06] Epoch: 23, train loss: 0.18223784863948822, val loss: 0.19211943447589874, val metric: 0.8000603743836592\n",
      "[13:19:43] Epoch: 24, train loss: 0.1796303391456604, val loss: 0.19336871802806854, val metric: 0.7944810830806575\n",
      "[13:20:21] Epoch: 25, train loss: 0.17913486063480377, val loss: 0.19268232583999634, val metric: 0.7950003463846833\n",
      "[13:20:59] Epoch: 26, train loss: 0.17816540598869324, val loss: 0.1969131976366043, val metric: 0.7926006985407748\n",
      "[13:21:37] Epoch: 27, train loss: 0.17756596207618713, val loss: 0.19452105462551117, val metric: 0.7916158656449028\n",
      "[13:22:15] Epoch: 28, train loss: 0.17638970911502838, val loss: 0.1943781077861786, val metric: 0.790369369820677\n",
      "[13:22:54] Epoch: 29, train loss: 0.17573465406894684, val loss: 0.19884561002254486, val metric: 0.7844107228317818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:23:32] Epoch: 30, train loss: 0.17395038902759552, val loss: 0.19658687710762024, val metric: 0.7908451313844037\n",
      "[13:24:10] Epoch: 31, train loss: 0.17376229166984558, val loss: 0.20260027050971985, val metric: 0.7837468566427026\n",
      "[13:24:16] Early stopping: val loss: 0.18829074501991272, val metric: 0.8059301342489384\n",
      "[13:24:16] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m =====\n",
      "[13:24:54] Epoch: 0, train loss: 2.0756165981292725, val loss: 0.29272064566612244, val metric: 0.6760281684864917\n",
      "[13:25:32] Epoch: 1, train loss: 1.0410487651824951, val loss: 0.2044340819120407, val metric: 0.761761622140692\n",
      "[13:26:09] Epoch: 2, train loss: 0.1988583207130432, val loss: 0.19150947034358978, val metric: 0.7986280810163797\n",
      "[13:26:47] Epoch: 3, train loss: 0.410273015499115, val loss: 0.19233688712120056, val metric: 0.7967691374397543\n",
      "[13:27:25] Epoch: 4, train loss: 0.4932568371295929, val loss: 0.18968094885349274, val metric: 0.8010486340673248\n",
      "[13:28:02] Epoch: 5, train loss: 0.19832034409046173, val loss: 0.19748809933662415, val metric: 0.8015014115176131\n",
      "[13:28:40] Epoch: 6, train loss: 0.20619447529315948, val loss: 0.18891195952892303, val metric: 0.8045278230209214\n",
      "[13:29:17] Epoch: 7, train loss: 0.19882795214653015, val loss: 0.1909458190202713, val metric: 0.8004956062209797\n",
      "[13:29:55] Epoch: 8, train loss: 0.3381143808364868, val loss: 0.19140157103538513, val metric: 0.8034018221956454\n",
      "[13:30:33] Epoch: 9, train loss: 0.19519829750061035, val loss: 0.1893172562122345, val metric: 0.8042600047694812\n",
      "[13:31:10] Epoch: 10, train loss: 0.1951369345188141, val loss: 0.19248788058757782, val metric: 0.8035395316812729\n",
      "[13:31:47] Epoch: 11, train loss: 0.1954159438610077, val loss: 0.18914209306240082, val metric: 0.8063890105568052\n",
      "[13:32:25] Epoch: 12, train loss: 0.1979193538427353, val loss: 0.18900340795516968, val metric: 0.8068389916277827\n",
      "[13:33:03] Epoch: 13, train loss: 0.18876570463180542, val loss: 0.19281165301799774, val metric: 0.8060553040186802\n",
      "[13:33:41] Epoch: 14, train loss: 0.18953059613704681, val loss: 0.18882295489311218, val metric: 0.8064794347317383\n",
      "[13:34:19] Epoch: 15, train loss: 0.18952538073062897, val loss: 0.19811727106571198, val metric: 0.8016479860925785\n",
      "[13:34:57] Epoch: 16, train loss: 0.18914462625980377, val loss: 0.19115591049194336, val metric: 0.8054219142165913\n",
      "[13:35:36] Epoch: 17, train loss: 0.18726062774658203, val loss: 0.19091518223285675, val metric: 0.8043319143028953\n",
      "[13:36:13] Epoch: 18, train loss: 0.19021835923194885, val loss: 0.19089028239250183, val metric: 0.8035255603321183\n",
      "[13:36:52] Epoch: 19, train loss: 0.18622763454914093, val loss: 0.19878053665161133, val metric: 0.797139295790791\n",
      "[13:37:30] Epoch: 20, train loss: 0.18868134915828705, val loss: 0.20337432622909546, val metric: 0.7981915518351279\n",
      "[13:38:09] Epoch: 21, train loss: 0.18305890262126923, val loss: 0.1910034865140915, val metric: 0.8006896506861321\n",
      "[13:38:47] Epoch: 22, train loss: 0.1820075511932373, val loss: 0.19300657510757446, val metric: 0.7978153234556391\n",
      "[13:39:26] Epoch: 23, train loss: 0.18169820308685303, val loss: 0.19270415604114532, val metric: 0.7984557905628392\n",
      "[13:40:04] Epoch: 24, train loss: 0.18198515474796295, val loss: 0.1930702179670334, val metric: 0.7993251863408423\n",
      "[13:40:10] Early stopping: val loss: 0.18786223232746124, val metric: 0.8085521292711861\n",
      "[13:40:11] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m finished. score = \u001b[1m0.8053888481876601\u001b[0m\n",
      "[13:40:11] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m fitting and predicting completed\n",
      "[13:40:11] Time left 8927.69 secs\n",
      "\n",
      "[13:40:11] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[13:40:11] \u001b[1mAutoml preset training completed in 5472.31 seconds\u001b[0m\n",
      "\n",
      "[13:40:11] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_autoint_0) \n",
      "\n",
      "[2024-11-07 13:40:11,248] - [    END     ] - Fitting TabularLamaNN_autoint\n",
      "0.8053888481876601\n"
     ]
    }
   ],
   "source": [
    "model = TabularLamaNN(n_jobs=16, task=\"classification\", nn_name=\"autoint\")\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 60 * 2, categorical_features=cat_columns)\n",
    "model.verbose = 4\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aa170b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8053888481876601\n"
     ]
    }
   ],
   "source": [
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6dd6ac2-6191-43c5-84da-522b4829abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lamann_autoint_8053_full_dataset\"\n",
    "MODEL_DIR = Path(f\"../../../data/models/{MODEL_NAME}\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e4fed09-b428-4509-8644-347cbbb27f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res[MODEL_NAME] = oof[:, 1]\n",
    "res.to_csv(MODEL_DIR / \"oof.csv\", index=False)\n",
    "joblib.dump(model, MODEL_DIR / f\"{MODEL_NAME}.joblib\")\n",
    "\n",
    "with (MODEL_DIR / \"params.yaml\").open(\"w\") as f:\n",
    "    yaml.dump(model.params, f)\n",
    "\n",
    "with (MODEL_DIR / \"score.txt\").open(\"w\") as f:\n",
    "    print(\"OOF:\", metric(y_train, oof), file=f)\n",
    "    \n",
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(MODEL_DIR / f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f687e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame().assign(names=model.models[0].feature_names_, imp=model.models[0].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d1e1081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>feature_185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          names  imp\n",
       "61  feature_185  0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values(by=\"imp\", ascending=False).reset_index(drop=True).query(\"names == 'feature_185'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce7e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_7',\n",
       " 'feature_31',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_71',\n",
       " 'feature_109',\n",
       " 'feature_122',\n",
       " 'feature_156',\n",
       " 'feature_163',\n",
       " 'feature_167',\n",
       " 'feature_179',\n",
       " 'feature_185']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517948d",
   "metadata": {},
   "source": [
    "## With Time series cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fcb3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = RocAuc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d859f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by=\"id\").reset_index(drop=True)\n",
    "X_train, y_train = df_train[cfg[\"selected_features\"] + cat_columns], df_train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e52d68ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 08:27:33,388] - [   START    ] - Tuning LightGBMClassification\n",
      "[2024-11-07 08:27:40,118] - [   OPTUNA   ] - Trial 0. New best score 0.7903405446081995 with parameters {'max_depth': 6, 'num_leaves': 488, 'min_data_in_leaf': 188, 'bagging_fraction': 0.7993292420985183, 'bagging_freq': 0, 'feature_fraction': 0.49359671220172163, 'lambda_l1': 0.5808361216819946, 'lambda_l2': 8.661761457749352, 'min_gain_to_split': 12.022300234864176, 'is_unbalance': True, 'num_iterations': 2}\n",
      "[2024-11-07 08:28:03,043] - [   OPTUNA   ] - Trial 2. New best score 0.7913515589848906 with parameters {'max_depth': 5, 'num_leaves': 194, 'min_data_in_leaf': 117, 'bagging_fraction': 0.8925879806965068, 'bagging_freq': 0, 'feature_fraction': 0.708540663048167, 'lambda_l1': 5.924145688620425, 'lambda_l2': 0.46450412719997725, 'min_gain_to_split': 12.150897038028766, 'is_unbalance': True, 'num_iterations': 2}\n",
      "[2024-11-07 08:28:12,225] - [   OPTUNA   ] - Trial 3. New best score 0.8048686053278628 with parameters {'max_depth': 16, 'num_leaves': 495, 'min_data_in_leaf': 207, 'bagging_fraction': 0.6523068845866853, 'bagging_freq': 0, 'feature_fraction': 0.8105398159072941, 'lambda_l1': 4.4015249373960135, 'lambda_l2': 1.2203823484477883, 'min_gain_to_split': 9.903538202225404, 'is_unbalance': False, 'num_iterations': 201}\n",
      "[2024-11-07 08:28:27,946] - [   OPTUNA   ] - Trial 5. New best score 0.805775359050857 with parameters {'max_depth': 15, 'num_leaves': 54, 'min_data_in_leaf': 51, 'bagging_fraction': 0.522613644455269, 'bagging_freq': 0, 'feature_fraction': 0.6332063738136893, 'lambda_l1': 2.713490317738959, 'lambda_l2': 8.287375091519294, 'min_gain_to_split': 7.135066533871786, 'is_unbalance': False, 'num_iterations': 219}\n",
      "[2024-11-07 08:30:01,873] - [   OPTUNA   ] - Trial 13. New best score 0.8069467403107815 with parameters {'max_depth': 12, 'num_leaves': 120, 'min_data_in_leaf': 83, 'bagging_fraction': 0.5973813098180023, 'bagging_freq': 0, 'feature_fraction': 0.6464487752219038, 'lambda_l1': 1.815539729792131, 'lambda_l2': 9.653379460654552, 'min_gain_to_split': 5.109079440883124, 'is_unbalance': False, 'num_iterations': 194}\n",
      "[2024-11-07 08:30:23,656] - [   OPTUNA   ] - Trial 15. New best score 0.8079174231410097 with parameters {'max_depth': 9, 'num_leaves': 123, 'min_data_in_leaf': 79, 'bagging_fraction': 0.6696558155271586, 'bagging_freq': 0, 'feature_fraction': 0.41254813989004224, 'lambda_l1': 1.5400879612744933, 'lambda_l2': 6.428485487443978, 'min_gain_to_split': 3.4073761639683475, 'is_unbalance': False, 'num_iterations': 221}\n",
      "[2024-11-07 08:30:47,866] - [   OPTUNA   ] - Trial 17. New best score 0.8080338307668665 with parameters {'max_depth': 9, 'num_leaves': 177, 'min_data_in_leaf': 149, 'bagging_fraction': 0.7020257462335121, 'bagging_freq': 0, 'feature_fraction': 0.4001314682445803, 'lambda_l1': 4.277484898844048, 'lambda_l2': 5.915176709957256, 'min_gain_to_split': 2.630193834916201, 'is_unbalance': False, 'num_iterations': 247}\n",
      "[2024-11-07 08:32:56,360] - [   OPTUNA   ] - Trial 26. New best score 0.8083158418056456 with parameters {'max_depth': 13, 'num_leaves': 120, 'min_data_in_leaf': 166, 'bagging_fraction': 0.8112271899455036, 'bagging_freq': 20, 'feature_fraction': 0.5385502023308056, 'lambda_l1': 1.3349604628055485, 'lambda_l2': 8.855392863089838, 'min_gain_to_split': 0.42505008659048693, 'is_unbalance': False, 'num_iterations': 206}\n",
      "[2024-11-07 08:33:39,494] - [   OPTUNA   ] - Trial 28. New best score 0.8085529083857821 with parameters {'max_depth': 14, 'num_leaves': 75, 'min_data_in_leaf': 170, 'bagging_fraction': 0.8264267643219445, 'bagging_freq': 20, 'feature_fraction': 0.5742524097970673, 'lambda_l1': 1.2310934175206736, 'lambda_l2': 8.969396792235317, 'min_gain_to_split': 0.16644360284870074, 'is_unbalance': False, 'num_iterations': 211}\n",
      "[2024-11-07 08:35:41,908] - [   OPTUNA   ] - Trial 35. New best score 0.8085624905981069 with parameters {'max_depth': 13, 'num_leaves': 45, 'min_data_in_leaf': 179, 'bagging_fraction': 0.9090867052918509, 'bagging_freq': 20, 'feature_fraction': 0.5986896700241908, 'lambda_l1': 1.0457599526213117, 'lambda_l2': 8.511810626751942, 'min_gain_to_split': 1.6394745612739139, 'is_unbalance': False, 'num_iterations': 242}\n",
      "[2024-11-07 08:36:11,789] - [   OPTUNA   ] - Trial 37. New best score 0.8086060147129036 with parameters {'max_depth': 15, 'num_leaves': 146, 'min_data_in_leaf': 131, 'bagging_fraction': 0.9727869256250319, 'bagging_freq': 20, 'feature_fraction': 0.594412726250827, 'lambda_l1': 1.3076349982497943, 'lambda_l2': 8.42304491740083, 'min_gain_to_split': 1.95638379105971, 'is_unbalance': False, 'num_iterations': 180}\n",
      "[2024-11-07 08:37:31,532] - [   OPTUNA   ] - Trial 42. New best score 0.8086748450733487 with parameters {'max_depth': 11, 'num_leaves': 95, 'min_data_in_leaf': 155, 'bagging_fraction': 0.9696680239166591, 'bagging_freq': 20, 'feature_fraction': 0.5068877996580057, 'lambda_l1': 0.3880584908457285, 'lambda_l2': 9.519643874182023, 'min_gain_to_split': 1.5176677728376484, 'is_unbalance': False, 'num_iterations': 225}\n",
      "[2024-11-07 08:43:11,113] - [   OPTUNA   ] - Trial 63. New best score 0.8087325744854885 with parameters {'max_depth': 16, 'num_leaves': 160, 'min_data_in_leaf': 166, 'bagging_fraction': 0.936885833403046, 'bagging_freq': 20, 'feature_fraction': 0.4498188675696397, 'lambda_l1': 1.1357746192947442, 'lambda_l2': 7.7534455607773385, 'min_gain_to_split': 2.069412187433082, 'is_unbalance': False, 'num_iterations': 207}\n",
      "[2024-11-07 08:45:27,863] - [   OPTUNA   ] - Trial 71. New best score 0.809046586456055 with parameters {'max_depth': 10, 'num_leaves': 153, 'min_data_in_leaf': 160, 'bagging_fraction': 0.9135728904594532, 'bagging_freq': 10, 'feature_fraction': 0.506921563666065, 'lambda_l1': 0.6725410135999423, 'lambda_l2': 8.841591608898721, 'min_gain_to_split': 1.6964405734320749, 'is_unbalance': False, 'num_iterations': 237}\n",
      "[2024-11-07 08:51:41,348] - [   OPTUNA   ] - Trial 91. New best score 0.8092009955871362 with parameters {'max_depth': 8, 'num_leaves': 331, 'min_data_in_leaf': 57, 'bagging_fraction': 0.9120914616559199, 'bagging_freq': 10, 'feature_fraction': 0.43368773726287124, 'lambda_l1': 3.8666345262680837, 'lambda_l2': 8.173281721666852, 'min_gain_to_split': 0.7062609644931823, 'is_unbalance': False, 'num_iterations': 313}\n",
      "[2024-11-07 09:24:15,316] - [   OPTUNA   ] - Trial 184. New best score 0.8092209952891476 with parameters {'max_depth': 8, 'num_leaves': 258, 'min_data_in_leaf': 21, 'bagging_fraction': 0.8833000021442096, 'bagging_freq': 10, 'feature_fraction': 0.44326798567844145, 'lambda_l1': 1.7734419425628303, 'lambda_l2': 8.481446649565262, 'min_gain_to_split': 0.19263364585511303, 'is_unbalance': False, 'num_iterations': 294}\n",
      "[2024-11-07 09:27:54,872] - [   OPTUNA   ] - 195 trials completed\n",
      "[2024-11-07 09:27:54,874] - [BEST PARAMS ] - {'objective_type': 'binary', 'boosting': 'gbdt', 'num_iterations': 294, 'max_depth': 8, 'learning_rate': 0.03, 'num_leaves': 258, 'min_data_in_leaf': 21, 'bagging_fraction': 0.8833000021442096, 'bagging_freq': 10, 'feature_fraction': 0.44326798567844145, 'early_stopping_round': 100, 'lambda_l1': 1.7734419425628303, 'lambda_l2': 8.481446649565262, 'min_gain_to_split': 0.19263364585511303, 'num_threads': 16, 'random_state': 42, 'is_unbalance': False, 'num_classes': 1, 'verbose': -1}\n",
      "[2024-11-07 09:27:54,875] - [    END     ] - Tuning LightGBMClassification\n",
      "[2024-11-07 09:27:54,877] - [   START    ] - Fitting LightGBMClassification\n",
      "[2024-11-07 09:27:54,892] - [    FIT     ] - LightGBMClassification fold 0\n",
      "[2024-11-07 09:27:56,881] - [    FIT     ] - LightGBMClassification fold 1\n",
      "[2024-11-07 09:27:59,788] - [    FIT     ] - LightGBMClassification fold 2\n",
      "[2024-11-07 09:28:04,156] - [    FIT     ] - LightGBMClassification fold 3\n",
      "[2024-11-07 09:28:09,145] - [    FIT     ] - LightGBMClassification fold 4\n",
      "[2024-11-07 09:28:14,959] - [    END     ] - Fitting LightGBMClassification\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = LightGBMClassification(n_jobs=16, time_series=True)\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 60, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a073f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_oofs_idx = oof[np.any(np.isnan(oof), axis=1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f8165e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095227594190041"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y_train[none_oofs_idx:], oof[none_oofs_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc0326db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lgb_8095_full_dataset_time_series\"\n",
    "MODEL_DIR = Path(f\"../../../data/models/{MODEL_NAME}\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "652cae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res[MODEL_NAME] = oof[none_oofs_idx:, 1]\n",
    "res.to_csv(MODEL_DIR / \"oof.csv\", index=False)\n",
    "joblib.dump(model, MODEL_DIR / f\"{MODEL_NAME}.joblib\")\n",
    "\n",
    "with (MODEL_DIR / \"params.yaml\").open(\"w\") as f:\n",
    "    yaml.dump(model.params, f)\n",
    "\n",
    "with (MODEL_DIR / \"score.txt\").open(\"w\") as f:\n",
    "    print(\"OOF:\", metric(y_train, oof), file=f)\n",
    "    \n",
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(MODEL_DIR / f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c20b42",
   "metadata": {},
   "source": [
    "## TEST \n",
    "**81.22112399468679**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e490c4a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3645213-67f1-4a56-8449-706616b01975",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv('lgb_813.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b626f4-24d7-47cc-8e1c-8d4829422eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pd.read_csv(\"lama_utilized.csv\")\n",
    "pred_2 = pd.read_csv(\"lgmb_oe_ohe_cols_0805.csv\")\n",
    "pred_3 = pd.read_csv(\"catboost_ts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6fd1b74-1c84-47a2-9640-f9afca52a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1[\"target\"] = 0.6 * pred_1[\"target\"] + 0.2 * pred_2[\"target\"] + 0.2 * pred_3[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9a12186-27a7-43e5-bbf9-05d9894bd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1.to_csv(\"blend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1a479dff-a006-4237-9a22-9b4a9d6a52eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Open the file pointed by this path and return a file object, as\n",
       "the built-in open() function does.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/lib/python3.10/pathlib.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_DIR.open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9b1c6-0fb4-461a-9aa9-1c23e299671f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_kernel",
   "language": "python",
   "name": "gpu_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
