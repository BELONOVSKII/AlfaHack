{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa3af6a-d478-4c0e-a715-21f3f6707c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../../../../automl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe599f1-83eb-4e6b-8115-f05eb659ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "[2024-11-08 13:02:50]\n",
      "/home/peter/venvs/base_venv/lib/python3.10/site-packages/lightautoml/ml_algo/dl_model.py:42: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/home/peter/venvs/base_venv/lib/python3.10/site-packages/lightautoml/text/embed.py:22: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/home/peter/venvs/base_venv/lib/python3.10/site-packages/lightautoml/text/dl_transformers.py:25: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.automl.model.lama import TabularLama\n",
    "from src.automl.loggers import configure_root_logger\n",
    "from src.automl.constants import create_ml_data_dir\n",
    "from src.automl.model.metrics import RocAuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087a93ef-e784-4dbb-8962-24e871577fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ml_data_dir()\n",
    "configure_root_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4701a7-04a9-42cd-b472-d9ca1dce955d",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9446b478-3af7-4d89-8d52-0d16996734e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 77\n",
    "DATA_PATH = Path(\"../../../../data/\")\n",
    "CONFIG_PATH = Path(\"../../../../configs/config.yaml\")\n",
    "N_JOBS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5494d0ab-4d12-47b3-bbaa-31fd51961cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CONFIG_PATH.open() as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1cf46-0712-400d-b190-15de4b596d15",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7208e0bf-13a0-4f7a-9f2e-307f386ef935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(DATA_PATH / \"train_preproc_oof.parquet\")\n",
    "#df_train, df_test = df_train.sort_values(by=\"id\").iloc[:300_000], df_train.sort_values(by=\"id\").iloc[300_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b73ba9-d6c5-4e83-b7ed-480881d44647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940982\n",
       "1    0.059018\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83dba0de-f224-4a5a-84db-acb5ff2ba670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample the 0 class\n",
    "#df_train = pd.concat([df_train.loc[df_train.target == 1], df_train.loc[df_train.target == 0].sample(200_000, random_state=RANDOM_SEED)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a4bbaca-2b74-4177-88e4-4897ff07498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2525aeac-d91b-4864-a2cb-24f94702c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train[cfg[\"stack_features\"]], df_train[\"target\"]\n",
    "#X_test, y_test = df_test[cfg[\"selected_features\"] + cat_columns], df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f28cd79-395e-4e5d-9fa6-015a640955d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940982\n",
       "1    0.059018\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train.value_counts(normalize=True))\n",
    "#display(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12b00734-0a36-4487-93ed-c78e6833ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_features = ohe_cols# + oe_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48abfc9d-95b1-4eda-9665-251676ed3d8f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b32e8180-6799-428d-93d8-50f8c19a074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = RocAuc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abe02bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-08 13:03:14,115] - [   START    ] - Fitting TabularLama\n",
      "[13:03:14] Stdout logging level is INFO.\n",
      "[13:03:14] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[13:03:14] Task: binary\n",
      "\n",
      "[13:03:14] Start automl preset with listed constraints:\n",
      "[13:03:14] - time: 3600.00 seconds\n",
      "[13:03:14] - CPU: 16 cores\n",
      "[13:03:14] - memory: 16 GB\n",
      "\n",
      "[13:03:14] \u001b[1mTrain data shape: (413194, 8)\u001b[0m\n",
      "\n",
      "[13:03:15] Layer \u001b[1m1\u001b[0m train process start. Time left 3598.60 secs\n",
      "[13:03:15] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[13:03:17] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8087671381703095\u001b[0m\n",
      "[13:03:17] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[13:03:17] Time left 3596.76 secs\n",
      "\n",
      "[13:03:21] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[13:03:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[13:03:44] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8119925394963108\u001b[0m\n",
      "[13:03:44] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[13:03:44] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[13:08:47] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[13:08:47] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[13:09:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.808751664992544\u001b[0m\n",
      "[13:09:10] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[13:09:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[13:09:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.813625746416388\u001b[0m\n",
      "[13:09:22] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[13:09:22] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[13:12:34] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[13:12:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[13:12:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.813672636235316\u001b[0m\n",
      "[13:12:51] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[13:12:51] Time left 3022.98 secs\n",
      "\n",
      "[13:12:51] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[13:12:51] Blending: optimization starts with equal weights and score \u001b[1m0.8134246646094154\u001b[0m\n",
      "[13:12:57] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8138424048133401\u001b[0m, weights = \u001b[1m[0.         0.1906925  0.         0.40649208 0.4028154 ]\u001b[0m\n",
      "[13:13:02] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8138590811270885\u001b[0m, weights = \u001b[1m[0.06980279 0.15662655 0.05126364 0.40266794 0.31963912]\u001b[0m\n",
      "[13:13:08] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8138632262113605\u001b[0m, weights = \u001b[1m[0.         0.17342554 0.05021075 0.39439768 0.38196597]\u001b[0m\n",
      "[13:13:14] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8138636140203468\u001b[0m, weights = \u001b[1m[0.         0.17620936 0.05101674 0.38029078 0.39248314]\u001b[0m\n",
      "[13:13:20] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8138640676418994\u001b[0m, weights = \u001b[1m[0.         0.17381974 0.05032489 0.3653507  0.41050467]\u001b[0m\n",
      "[13:13:20] \u001b[1mAutoml preset training completed in 606.26 seconds\u001b[0m\n",
      "\n",
      "[13:13:20] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.17382 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.05032 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.36535 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.41050 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[2024-11-08 13:13:20,433] - [    END     ] - Fitting TabularLama\n",
      "0.8138640676418994\n"
     ]
    }
   ],
   "source": [
    "model = TabularLama(n_jobs=16, task=\"classification\")\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 30, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339cafd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-08 09:07:53,431] - [   START    ] - Fitting TabularLama\n",
      "[09:07:53] Stdout logging level is INFO.\n",
      "[09:07:53] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[09:07:53] Task: binary\n",
      "\n",
      "[09:07:53] Start automl preset with listed constraints:\n",
      "[09:07:53] - time: 3600.00 seconds\n",
      "[09:07:53] - CPU: 16 cores\n",
      "[09:07:53] - memory: 16 GB\n",
      "\n",
      "[09:07:53] \u001b[1mTrain data shape: (413194, 21)\u001b[0m\n",
      "\n",
      "[09:07:57] Layer \u001b[1m1\u001b[0m train process start. Time left 3596.00 secs\n",
      "[09:07:57] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[09:08:00] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8082552247714897\u001b[0m\n",
      "[09:08:00] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[09:08:00] Time left 3592.98 secs\n",
      "\n",
      "[09:08:05] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[09:08:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[09:08:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8037248750001251\u001b[0m\n",
      "[09:08:31] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[09:08:31] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[09:13:32] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[09:13:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[09:13:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8064947787988421\u001b[0m\n",
      "[09:13:59] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[09:13:59] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[09:14:13] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8136941708664802\u001b[0m\n",
      "[09:14:13] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[09:14:13] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[09:19:15] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[09:19:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[09:19:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8138271593428363\u001b[0m\n",
      "[09:19:36] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[09:19:36] Time left 2896.71 secs\n",
      "\n",
      "[09:19:36] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[09:19:37] Blending: optimization starts with equal weights and score \u001b[1m0.8130654974315523\u001b[0m\n",
      "[09:19:42] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8139496878398591\u001b[0m, weights = \u001b[1m[0.06885234 0.         0.         0.32243767 0.60871   ]\u001b[0m\n",
      "[09:19:48] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8139970688272529\u001b[0m, weights = \u001b[1m[0.         0.05286201 0.         0.33105996 0.6160781 ]\u001b[0m\n",
      "[09:19:54] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8139970688272529\u001b[0m, weights = \u001b[1m[0.         0.05286201 0.         0.33105996 0.6160781 ]\u001b[0m\n",
      "[09:19:54] Blending: no score update. Terminated\n",
      "\n",
      "[09:19:54] \u001b[1mAutoml preset training completed in 720.40 seconds\u001b[0m\n",
      "\n",
      "[09:19:54] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.05286 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.33106 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.61608 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[2024-11-08 09:19:54,045] - [    END     ] - Fitting TabularLama\n",
      "0.8139970688272529\n"
     ]
    }
   ],
   "source": [
    "model = TabularLama(n_jobs=16, task=\"classification\")\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 30, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bab46f5-c9c4-4567-8fae-11296a05f4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 13:50:21,142] - [   START    ] - Fitting TabularLama\n",
      "[13:50:21] Stdout logging level is INFO.\n",
      "[13:50:21] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[13:50:21] Task: binary\n",
      "\n",
      "[13:50:21] Start automl preset with listed constraints:\n",
      "[13:50:21] - time: 3600.00 seconds\n",
      "[13:50:21] - CPU: 16 cores\n",
      "[13:50:21] - memory: 16 GB\n",
      "\n",
      "[13:50:21] \u001b[1mTrain data shape: (413194, 68)\u001b[0m\n",
      "\n",
      "[13:50:34] Layer \u001b[1m1\u001b[0m train process start. Time left 3586.87 secs\n",
      "[13:50:48] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[13:51:42] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8078772570316353\u001b[0m\n",
      "[13:51:42] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[13:51:42] Time left 3518.73 secs\n",
      "\n",
      "[13:51:49] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[13:52:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[13:52:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8085887315347171\u001b[0m\n",
      "[13:52:35] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[13:52:35] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[13:57:36] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[13:57:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[13:58:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8135094072537528\u001b[0m\n",
      "[13:58:10] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[13:58:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[13:58:32] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8123178836028417\u001b[0m\n",
      "[13:58:32] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[13:58:32] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[14:03:33] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[14:03:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[14:04:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8127419093287513\u001b[0m\n",
      "[14:04:03] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[14:04:03] Time left 2777.90 secs\n",
      "\n",
      "[14:04:03] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[14:04:03] Blending: optimization starts with equal weights and score \u001b[1m0.812999626224278\u001b[0m\n",
      "[14:04:09] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8136549668268129\u001b[0m, weights = \u001b[1m[0.         0.         0.67911774 0.13455844 0.1863238 ]\u001b[0m\n",
      "[14:04:15] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8136595917943832\u001b[0m, weights = \u001b[1m[0.         0.05554909 0.6542768  0.10332279 0.18685132]\u001b[0m\n",
      "[14:04:21] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8136596317143454\u001b[0m, weights = \u001b[1m[0.         0.05520056 0.652223   0.1026745  0.18990196]\u001b[0m\n",
      "[14:04:27] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8136597081792666\u001b[0m, weights = \u001b[1m[0.         0.05469849 0.6553861  0.10174064 0.18817475]\u001b[0m\n",
      "[14:04:33] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8136597081792666\u001b[0m, weights = \u001b[1m[0.         0.05469849 0.6553861  0.10174064 0.18817475]\u001b[0m\n",
      "[14:04:33] Blending: no score update. Terminated\n",
      "\n",
      "[14:04:33] \u001b[1mAutoml preset training completed in 852.33 seconds\u001b[0m\n",
      "\n",
      "[14:04:33] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.05470 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.65539 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.10174 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.18817 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[2024-11-07 14:04:33,610] - [    END     ] - Fitting TabularLama\n",
      "0.8136597081792666\n"
     ]
    }
   ],
   "source": [
    "model = TabularLama(n_jobs=16, task=\"classification\")\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 30, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6dd6ac2-6191-43c5-84da-522b4829abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lama_stack_8136_full_dataset\"\n",
    "MODEL_DIR = Path(f\"../../../../data/models/{MODEL_NAME}\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e4fed09-b428-4509-8644-347cbbb27f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.DataFrame()\n",
    "# res[MODEL_NAME] = oof[:, 1]\n",
    "# res.to_csv(MODEL_DIR / \"oof.csv\", index=False)\n",
    "# #joblib.dump(model, MODEL_DIR / f\"{MODEL_NAME}.joblib\")\n",
    "\n",
    "# with (MODEL_DIR / \"params.yaml\").open(\"w\") as f:\n",
    "#     yaml.dump(model.params, f)\n",
    "\n",
    "# with (MODEL_DIR / \"score.txt\").open(\"w\") as f:\n",
    "#     print(\"OOF:\", metric(y_train, oof), file=f)\n",
    "    \n",
    "# test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "# test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "# test[['id', 'target']].to_csv(MODEL_DIR / f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebab2080",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_oof.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cfg[\"stack_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7446223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lamau_814_full_dataset</td>\n",
       "      <td>78048.337071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb_81325_full_dataset</td>\n",
       "      <td>29297.001751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lama_81298_full_dataset</td>\n",
       "      <td>24098.444188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_162</td>\n",
       "      <td>1398.695796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_24</td>\n",
       "      <td>1321.674997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feature_18</td>\n",
       "      <td>1298.269506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feature_26</td>\n",
       "      <td>1290.120701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feature_145</td>\n",
       "      <td>1287.683197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feature_78</td>\n",
       "      <td>1279.916003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_36</td>\n",
       "      <td>1248.758602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_112</td>\n",
       "      <td>1228.811199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_9</td>\n",
       "      <td>1190.729637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_141</td>\n",
       "      <td>1140.620801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature_75</td>\n",
       "      <td>1127.175495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feature_79</td>\n",
       "      <td>1114.103202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feature_62</td>\n",
       "      <td>1110.960901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feature_35</td>\n",
       "      <td>1088.471595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>feature_44</td>\n",
       "      <td>1078.257104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feature_168</td>\n",
       "      <td>1069.888995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>feature_148</td>\n",
       "      <td>1055.762701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>feature_147</td>\n",
       "      <td>1051.141966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>feature_76</td>\n",
       "      <td>1041.521295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feature_20</td>\n",
       "      <td>1029.698003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>feature_157</td>\n",
       "      <td>998.859297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feature_33</td>\n",
       "      <td>993.189499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>feature_133</td>\n",
       "      <td>992.890409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>feature_59</td>\n",
       "      <td>988.289097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>feature_46</td>\n",
       "      <td>978.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>feature_14</td>\n",
       "      <td>968.263297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>feature_43</td>\n",
       "      <td>967.263209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>feature_142</td>\n",
       "      <td>953.593235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>feature_83</td>\n",
       "      <td>951.608026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>feature_96</td>\n",
       "      <td>936.340199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lgb_8122_full_dataset</td>\n",
       "      <td>899.356003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>feature_126</td>\n",
       "      <td>894.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>feature_100</td>\n",
       "      <td>889.852299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>feature_55</td>\n",
       "      <td>889.369598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>feature_183</td>\n",
       "      <td>882.159472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>feature_127</td>\n",
       "      <td>853.308690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>feature_153</td>\n",
       "      <td>835.863204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>feature_87</td>\n",
       "      <td>802.161905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>feature_8</td>\n",
       "      <td>801.556602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>feature_103</td>\n",
       "      <td>793.046144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>feature_29</td>\n",
       "      <td>783.742097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>feature_134</td>\n",
       "      <td>777.999600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>feature_11</td>\n",
       "      <td>771.673395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>feature_66</td>\n",
       "      <td>770.873203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>feature_72</td>\n",
       "      <td>722.490300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>feature_21</td>\n",
       "      <td>675.958407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>feature_25</td>\n",
       "      <td>664.108699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature    Importance\n",
       "0    lamau_814_full_dataset  78048.337071\n",
       "1    xgb_81325_full_dataset  29297.001751\n",
       "2   lama_81298_full_dataset  24098.444188\n",
       "3               feature_162   1398.695796\n",
       "4                feature_24   1321.674997\n",
       "5                feature_18   1298.269506\n",
       "6                feature_26   1290.120701\n",
       "7               feature_145   1287.683197\n",
       "8                feature_78   1279.916003\n",
       "9                feature_36   1248.758602\n",
       "10              feature_112   1228.811199\n",
       "11                feature_9   1190.729637\n",
       "12              feature_141   1140.620801\n",
       "13               feature_75   1127.175495\n",
       "14               feature_79   1114.103202\n",
       "15               feature_62   1110.960901\n",
       "16               feature_35   1088.471595\n",
       "17               feature_44   1078.257104\n",
       "18              feature_168   1069.888995\n",
       "19              feature_148   1055.762701\n",
       "20              feature_147   1051.141966\n",
       "21               feature_76   1041.521295\n",
       "22               feature_20   1029.698003\n",
       "23              feature_157    998.859297\n",
       "24               feature_33    993.189499\n",
       "25              feature_133    992.890409\n",
       "26               feature_59    988.289097\n",
       "27               feature_46    978.601000\n",
       "28               feature_14    968.263297\n",
       "29               feature_43    967.263209\n",
       "30              feature_142    953.593235\n",
       "31               feature_83    951.608026\n",
       "32               feature_96    936.340199\n",
       "33    lgb_8122_full_dataset    899.356003\n",
       "34              feature_126    894.646700\n",
       "35              feature_100    889.852299\n",
       "36               feature_55    889.369598\n",
       "37              feature_183    882.159472\n",
       "38              feature_127    853.308690\n",
       "39              feature_153    835.863204\n",
       "40               feature_87    802.161905\n",
       "41                feature_8    801.556602\n",
       "42              feature_103    793.046144\n",
       "43               feature_29    783.742097\n",
       "44              feature_134    777.999600\n",
       "45               feature_11    771.673395\n",
       "46               feature_66    770.873203\n",
       "47               feature_72    722.490300\n",
       "48               feature_21    675.958407\n",
       "49               feature_25    664.108699"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.get_feature_scores()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f687e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame().assign(names=model.models[0].feature_names_, imp=model.models[0].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d1e1081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>feature_185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          names  imp\n",
       "61  feature_185  0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values(by=\"imp\", ascending=False).reset_index(drop=True).query(\"names == 'feature_185'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce7e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_7',\n",
       " 'feature_31',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_71',\n",
       " 'feature_109',\n",
       " 'feature_122',\n",
       " 'feature_156',\n",
       " 'feature_163',\n",
       " 'feature_167',\n",
       " 'feature_179',\n",
       " 'feature_185']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517948d",
   "metadata": {},
   "source": [
    "## With Time series cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fcb3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = RocAuc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d859f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by=\"id\").reset_index(drop=True)\n",
    "X_train, y_train = df_train[cfg[\"selected_features\"] + cat_columns], df_train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e52d68ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 08:27:33,388] - [   START    ] - Tuning LightGBMClassification\n",
      "[2024-11-07 08:27:40,118] - [   OPTUNA   ] - Trial 0. New best score 0.7903405446081995 with parameters {'max_depth': 6, 'num_leaves': 488, 'min_data_in_leaf': 188, 'bagging_fraction': 0.7993292420985183, 'bagging_freq': 0, 'feature_fraction': 0.49359671220172163, 'lambda_l1': 0.5808361216819946, 'lambda_l2': 8.661761457749352, 'min_gain_to_split': 12.022300234864176, 'is_unbalance': True, 'num_iterations': 2}\n",
      "[2024-11-07 08:28:03,043] - [   OPTUNA   ] - Trial 2. New best score 0.7913515589848906 with parameters {'max_depth': 5, 'num_leaves': 194, 'min_data_in_leaf': 117, 'bagging_fraction': 0.8925879806965068, 'bagging_freq': 0, 'feature_fraction': 0.708540663048167, 'lambda_l1': 5.924145688620425, 'lambda_l2': 0.46450412719997725, 'min_gain_to_split': 12.150897038028766, 'is_unbalance': True, 'num_iterations': 2}\n",
      "[2024-11-07 08:28:12,225] - [   OPTUNA   ] - Trial 3. New best score 0.8048686053278628 with parameters {'max_depth': 16, 'num_leaves': 495, 'min_data_in_leaf': 207, 'bagging_fraction': 0.6523068845866853, 'bagging_freq': 0, 'feature_fraction': 0.8105398159072941, 'lambda_l1': 4.4015249373960135, 'lambda_l2': 1.2203823484477883, 'min_gain_to_split': 9.903538202225404, 'is_unbalance': False, 'num_iterations': 201}\n",
      "[2024-11-07 08:28:27,946] - [   OPTUNA   ] - Trial 5. New best score 0.805775359050857 with parameters {'max_depth': 15, 'num_leaves': 54, 'min_data_in_leaf': 51, 'bagging_fraction': 0.522613644455269, 'bagging_freq': 0, 'feature_fraction': 0.6332063738136893, 'lambda_l1': 2.713490317738959, 'lambda_l2': 8.287375091519294, 'min_gain_to_split': 7.135066533871786, 'is_unbalance': False, 'num_iterations': 219}\n",
      "[2024-11-07 08:30:01,873] - [   OPTUNA   ] - Trial 13. New best score 0.8069467403107815 with parameters {'max_depth': 12, 'num_leaves': 120, 'min_data_in_leaf': 83, 'bagging_fraction': 0.5973813098180023, 'bagging_freq': 0, 'feature_fraction': 0.6464487752219038, 'lambda_l1': 1.815539729792131, 'lambda_l2': 9.653379460654552, 'min_gain_to_split': 5.109079440883124, 'is_unbalance': False, 'num_iterations': 194}\n",
      "[2024-11-07 08:30:23,656] - [   OPTUNA   ] - Trial 15. New best score 0.8079174231410097 with parameters {'max_depth': 9, 'num_leaves': 123, 'min_data_in_leaf': 79, 'bagging_fraction': 0.6696558155271586, 'bagging_freq': 0, 'feature_fraction': 0.41254813989004224, 'lambda_l1': 1.5400879612744933, 'lambda_l2': 6.428485487443978, 'min_gain_to_split': 3.4073761639683475, 'is_unbalance': False, 'num_iterations': 221}\n",
      "[2024-11-07 08:30:47,866] - [   OPTUNA   ] - Trial 17. New best score 0.8080338307668665 with parameters {'max_depth': 9, 'num_leaves': 177, 'min_data_in_leaf': 149, 'bagging_fraction': 0.7020257462335121, 'bagging_freq': 0, 'feature_fraction': 0.4001314682445803, 'lambda_l1': 4.277484898844048, 'lambda_l2': 5.915176709957256, 'min_gain_to_split': 2.630193834916201, 'is_unbalance': False, 'num_iterations': 247}\n",
      "[2024-11-07 08:32:56,360] - [   OPTUNA   ] - Trial 26. New best score 0.8083158418056456 with parameters {'max_depth': 13, 'num_leaves': 120, 'min_data_in_leaf': 166, 'bagging_fraction': 0.8112271899455036, 'bagging_freq': 20, 'feature_fraction': 0.5385502023308056, 'lambda_l1': 1.3349604628055485, 'lambda_l2': 8.855392863089838, 'min_gain_to_split': 0.42505008659048693, 'is_unbalance': False, 'num_iterations': 206}\n",
      "[2024-11-07 08:33:39,494] - [   OPTUNA   ] - Trial 28. New best score 0.8085529083857821 with parameters {'max_depth': 14, 'num_leaves': 75, 'min_data_in_leaf': 170, 'bagging_fraction': 0.8264267643219445, 'bagging_freq': 20, 'feature_fraction': 0.5742524097970673, 'lambda_l1': 1.2310934175206736, 'lambda_l2': 8.969396792235317, 'min_gain_to_split': 0.16644360284870074, 'is_unbalance': False, 'num_iterations': 211}\n",
      "[2024-11-07 08:35:41,908] - [   OPTUNA   ] - Trial 35. New best score 0.8085624905981069 with parameters {'max_depth': 13, 'num_leaves': 45, 'min_data_in_leaf': 179, 'bagging_fraction': 0.9090867052918509, 'bagging_freq': 20, 'feature_fraction': 0.5986896700241908, 'lambda_l1': 1.0457599526213117, 'lambda_l2': 8.511810626751942, 'min_gain_to_split': 1.6394745612739139, 'is_unbalance': False, 'num_iterations': 242}\n",
      "[2024-11-07 08:36:11,789] - [   OPTUNA   ] - Trial 37. New best score 0.8086060147129036 with parameters {'max_depth': 15, 'num_leaves': 146, 'min_data_in_leaf': 131, 'bagging_fraction': 0.9727869256250319, 'bagging_freq': 20, 'feature_fraction': 0.594412726250827, 'lambda_l1': 1.3076349982497943, 'lambda_l2': 8.42304491740083, 'min_gain_to_split': 1.95638379105971, 'is_unbalance': False, 'num_iterations': 180}\n",
      "[2024-11-07 08:37:31,532] - [   OPTUNA   ] - Trial 42. New best score 0.8086748450733487 with parameters {'max_depth': 11, 'num_leaves': 95, 'min_data_in_leaf': 155, 'bagging_fraction': 0.9696680239166591, 'bagging_freq': 20, 'feature_fraction': 0.5068877996580057, 'lambda_l1': 0.3880584908457285, 'lambda_l2': 9.519643874182023, 'min_gain_to_split': 1.5176677728376484, 'is_unbalance': False, 'num_iterations': 225}\n",
      "[2024-11-07 08:43:11,113] - [   OPTUNA   ] - Trial 63. New best score 0.8087325744854885 with parameters {'max_depth': 16, 'num_leaves': 160, 'min_data_in_leaf': 166, 'bagging_fraction': 0.936885833403046, 'bagging_freq': 20, 'feature_fraction': 0.4498188675696397, 'lambda_l1': 1.1357746192947442, 'lambda_l2': 7.7534455607773385, 'min_gain_to_split': 2.069412187433082, 'is_unbalance': False, 'num_iterations': 207}\n",
      "[2024-11-07 08:45:27,863] - [   OPTUNA   ] - Trial 71. New best score 0.809046586456055 with parameters {'max_depth': 10, 'num_leaves': 153, 'min_data_in_leaf': 160, 'bagging_fraction': 0.9135728904594532, 'bagging_freq': 10, 'feature_fraction': 0.506921563666065, 'lambda_l1': 0.6725410135999423, 'lambda_l2': 8.841591608898721, 'min_gain_to_split': 1.6964405734320749, 'is_unbalance': False, 'num_iterations': 237}\n",
      "[2024-11-07 08:51:41,348] - [   OPTUNA   ] - Trial 91. New best score 0.8092009955871362 with parameters {'max_depth': 8, 'num_leaves': 331, 'min_data_in_leaf': 57, 'bagging_fraction': 0.9120914616559199, 'bagging_freq': 10, 'feature_fraction': 0.43368773726287124, 'lambda_l1': 3.8666345262680837, 'lambda_l2': 8.173281721666852, 'min_gain_to_split': 0.7062609644931823, 'is_unbalance': False, 'num_iterations': 313}\n",
      "[2024-11-07 09:24:15,316] - [   OPTUNA   ] - Trial 184. New best score 0.8092209952891476 with parameters {'max_depth': 8, 'num_leaves': 258, 'min_data_in_leaf': 21, 'bagging_fraction': 0.8833000021442096, 'bagging_freq': 10, 'feature_fraction': 0.44326798567844145, 'lambda_l1': 1.7734419425628303, 'lambda_l2': 8.481446649565262, 'min_gain_to_split': 0.19263364585511303, 'is_unbalance': False, 'num_iterations': 294}\n",
      "[2024-11-07 09:27:54,872] - [   OPTUNA   ] - 195 trials completed\n",
      "[2024-11-07 09:27:54,874] - [BEST PARAMS ] - {'objective_type': 'binary', 'boosting': 'gbdt', 'num_iterations': 294, 'max_depth': 8, 'learning_rate': 0.03, 'num_leaves': 258, 'min_data_in_leaf': 21, 'bagging_fraction': 0.8833000021442096, 'bagging_freq': 10, 'feature_fraction': 0.44326798567844145, 'early_stopping_round': 100, 'lambda_l1': 1.7734419425628303, 'lambda_l2': 8.481446649565262, 'min_gain_to_split': 0.19263364585511303, 'num_threads': 16, 'random_state': 42, 'is_unbalance': False, 'num_classes': 1, 'verbose': -1}\n",
      "[2024-11-07 09:27:54,875] - [    END     ] - Tuning LightGBMClassification\n",
      "[2024-11-07 09:27:54,877] - [   START    ] - Fitting LightGBMClassification\n",
      "[2024-11-07 09:27:54,892] - [    FIT     ] - LightGBMClassification fold 0\n",
      "[2024-11-07 09:27:56,881] - [    FIT     ] - LightGBMClassification fold 1\n",
      "[2024-11-07 09:27:59,788] - [    FIT     ] - LightGBMClassification fold 2\n",
      "[2024-11-07 09:28:04,156] - [    FIT     ] - LightGBMClassification fold 3\n",
      "[2024-11-07 09:28:09,145] - [    FIT     ] - LightGBMClassification fold 4\n",
      "[2024-11-07 09:28:14,959] - [    END     ] - Fitting LightGBMClassification\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = LightGBMClassification(n_jobs=16, time_series=True)\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 60, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a073f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_oofs_idx = oof[np.any(np.isnan(oof), axis=1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f8165e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095227594190041"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y_train[none_oofs_idx:], oof[none_oofs_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc0326db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lgb_8095_full_dataset_time_series\"\n",
    "MODEL_DIR = Path(f\"../../../data/models/{MODEL_NAME}\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "652cae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res[MODEL_NAME] = oof[none_oofs_idx:, 1]\n",
    "res.to_csv(MODEL_DIR / \"oof.csv\", index=False)\n",
    "joblib.dump(model, MODEL_DIR / f\"{MODEL_NAME}.joblib\")\n",
    "\n",
    "with (MODEL_DIR / \"params.yaml\").open(\"w\") as f:\n",
    "    yaml.dump(model.params, f)\n",
    "\n",
    "with (MODEL_DIR / \"score.txt\").open(\"w\") as f:\n",
    "    print(\"OOF:\", metric(y_train, oof), file=f)\n",
    "    \n",
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(MODEL_DIR / f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c20b42",
   "metadata": {},
   "source": [
    "## TEST \n",
    "**81.22112399468679**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e490c4a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3645213-67f1-4a56-8449-706616b01975",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv('lgb_813.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b626f4-24d7-47cc-8e1c-8d4829422eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pd.read_csv(\"lama_utilized.csv\")\n",
    "pred_2 = pd.read_csv(\"lgmb_oe_ohe_cols_0805.csv\")\n",
    "pred_3 = pd.read_csv(\"catboost_ts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6fd1b74-1c84-47a2-9640-f9afca52a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1[\"target\"] = 0.6 * pred_1[\"target\"] + 0.2 * pred_2[\"target\"] + 0.2 * pred_3[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9a12186-27a7-43e5-bbf9-05d9894bd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1.to_csv(\"blend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1a479dff-a006-4237-9a22-9b4a9d6a52eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Open the file pointed by this path and return a file object, as\n",
       "the built-in open() function does.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/lib/python3.10/pathlib.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_DIR.open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9b1c6-0fb4-461a-9aa9-1c23e299671f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_kernel",
   "language": "python",
   "name": "base_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
