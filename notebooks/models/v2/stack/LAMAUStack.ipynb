{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa3af6a-d478-4c0e-a715-21f3f6707c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../../../../automl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe599f1-83eb-4e6b-8115-f05eb659ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "[2024-11-08 11:07:08]\n",
      "/home/peter/venvs/base_venv/lib/python3.10/site-packages/lightautoml/ml_algo/dl_model.py:42: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/home/peter/venvs/base_venv/lib/python3.10/site-packages/lightautoml/text/embed.py:22: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/home/peter/venvs/base_venv/lib/python3.10/site-packages/lightautoml/text/dl_transformers.py:25: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.automl.model.lama import TabularLamaUtilized\n",
    "from src.automl.loggers import configure_root_logger\n",
    "from src.automl.constants import create_ml_data_dir\n",
    "from src.automl.model.metrics import RocAuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087a93ef-e784-4dbb-8962-24e871577fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ml_data_dir()\n",
    "configure_root_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4701a7-04a9-42cd-b472-d9ca1dce955d",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9446b478-3af7-4d89-8d52-0d16996734e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 77\n",
    "DATA_PATH = Path(\"../../../../data/\")\n",
    "CONFIG_PATH = Path(\"../../../../configs/config.yaml\")\n",
    "N_JOBS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5494d0ab-4d12-47b3-bbaa-31fd51961cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CONFIG_PATH.open() as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c5f6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"stack_features\"] = [\"lamau_814_full_dataset\", \"lamann_autoint_8053_full_dataset\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1cf46-0712-400d-b190-15de4b596d15",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7208e0bf-13a0-4f7a-9f2e-307f386ef935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(DATA_PATH / \"train_preproc_oof.parquet\")\n",
    "#df_train, df_test = df_train.sort_values(by=\"id\").iloc[:300_000], df_train.sort_values(by=\"id\").iloc[300_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b73ba9-d6c5-4e83-b7ed-480881d44647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940982\n",
       "1    0.059018\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83dba0de-f224-4a5a-84db-acb5ff2ba670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample the 0 class\n",
    "#df_train = pd.concat([df_train.loc[df_train.target == 1], df_train.loc[df_train.target == 0].sample(200_000, random_state=RANDOM_SEED)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4bbaca-2b74-4177-88e4-4897ff07498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = df_train.drop(columns=[\"target\", \"id\"]).select_dtypes(int).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2525aeac-d91b-4864-a2cb-24f94702c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train[cfg[\"selected_features\"] + cfg[\"stack_features\"] + cat_columns], df_train[\"target\"]\n",
    "#X_test, y_test = df_test[cfg[\"selected_features\"] + cat_columns], df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f28cd79-395e-4e5d-9fa6-015a640955d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940982\n",
       "1    0.059018\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train.value_counts(normalize=True))\n",
    "#display(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b00734-0a36-4487-93ed-c78e6833ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_features = ohe_cols# + oe_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48abfc9d-95b1-4eda-9665-251676ed3d8f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32e8180-6799-428d-93d8-50f8c19a074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = RocAuc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f6e33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_std_out = sys.stdout\n",
    "# sys.stdout = open(\"stdout_logs\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "339cafd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-08 11:07:39,035] - [   START    ] - Fitting TabularLamaUtilized\n",
      "[11:07:39] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[11:07:39] - time: 7200.00 seconds\n",
      "[11:07:39] - CPU: 16 cores\n",
      "[11:07:39] - memory: 16 GB\n",
      "\n",
      "[11:07:39] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[11:07:39] ==================================================\n",
      "[11:07:39] Start 0 automl preset configuration:\n",
      "[11:07:39] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:07:39] Stdout logging level is INFO.\n",
      "[11:07:39] Task: binary\n",
      "\n",
      "[11:07:39] Start automl preset with listed constraints:\n",
      "[11:07:39] - time: 7200.00 seconds\n",
      "[11:07:39] - CPU: 16 cores\n",
      "[11:07:39] - memory: 16 GB\n",
      "\n",
      "[11:07:39] \u001b[1mTrain data shape: (413194, 65)\u001b[0m\n",
      "\n",
      "[11:07:50] Layer \u001b[1m1\u001b[0m train process start. Time left 7188.33 secs\n",
      "[11:08:03] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:08:48] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8068416001087446\u001b[0m\n",
      "[11:08:48] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:08:48] Time left 7130.95 secs\n",
      "\n",
      "[11:09:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:09:32] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8068869323635967\u001b[0m\n",
      "[11:09:32] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:09:32] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:09:32] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[11:14:36] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:14:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:15:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8128596226978552\u001b[0m\n",
      "[11:15:08] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:15:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[11:15:32] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8119005844169414\u001b[0m\n",
      "[11:15:32] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[11:15:32] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:20:38] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[11:20:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[11:21:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8124385763089444\u001b[0m\n",
      "[11:21:16] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[11:21:16] Time left 6382.68 secs\n",
      "\n",
      "[11:21:16] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:21:16] Blending: optimization starts with equal weights and score \u001b[1m0.8127508103201793\u001b[0m\n",
      "[11:21:22] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8132630571060551\u001b[0m, weights = \u001b[1m[0.         0.         0.5706598  0.1577916  0.27154854]\u001b[0m\n",
      "[11:21:28] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8132985866107543\u001b[0m, weights = \u001b[1m[0.         0.07046907 0.54787654 0.12440162 0.25725278]\u001b[0m\n",
      "[11:21:34] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8132989323376666\u001b[0m, weights = \u001b[1m[0.         0.07485626 0.55072975 0.116428   0.25798598]\u001b[0m\n",
      "[11:21:39] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8132989323376666\u001b[0m, weights = \u001b[1m[0.         0.07485626 0.55072975 0.116428   0.25798598]\u001b[0m\n",
      "[11:21:39] Blending: no score update. Terminated\n",
      "\n",
      "[11:21:39] \u001b[1mAutoml preset training completed in 840.81 seconds\u001b[0m\n",
      "\n",
      "[11:21:39] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.07486 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.55073 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.11643 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.25799 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[11:21:39] ==================================================\n",
      "[11:21:39] Start 1 automl preset configuration:\n",
      "[11:21:39] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:21:40] Stdout logging level is INFO.\n",
      "[11:21:40] Task: binary\n",
      "\n",
      "[11:21:40] Start automl preset with listed constraints:\n",
      "[11:21:40] - time: 6359.16 seconds\n",
      "[11:21:40] - CPU: 16 cores\n",
      "[11:21:40] - memory: 16 GB\n",
      "\n",
      "[11:21:40] \u001b[1mTrain data shape: (413194, 65)\u001b[0m\n",
      "\n",
      "[11:21:51] Layer \u001b[1m1\u001b[0m train process start. Time left 6347.79 secs\n",
      "[11:22:04] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:22:51] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8066187401957523\u001b[0m\n",
      "[11:22:51] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:22:51] Time left 6288.11 secs\n",
      "\n",
      "[11:22:57] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:23:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:23:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8079822594523312\u001b[0m\n",
      "[11:23:40] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:23:40] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:28:42] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:28:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:29:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8125234572756874\u001b[0m\n",
      "[11:29:16] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:29:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[11:29:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.811936796990691\u001b[0m\n",
      "[11:29:39] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[11:29:39] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:34:41] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[11:34:41] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[11:35:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8125621326527104\u001b[0m\n",
      "[11:35:17] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[11:35:17] Time left 5541.86 secs\n",
      "\n",
      "[11:35:17] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:35:17] Blending: optimization starts with equal weights and score \u001b[1m0.8128112385434307\u001b[0m\n",
      "[11:35:23] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8132928612338675\u001b[0m, weights = \u001b[1m[0.         0.13139504 0.4529571  0.08679003 0.3288579 ]\u001b[0m\n",
      "[11:35:28] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8133179497436274\u001b[0m, weights = \u001b[1m[0.         0.18345334 0.45191288 0.         0.3646338 ]\u001b[0m\n",
      "[11:35:34] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8133185182207652\u001b[0m, weights = \u001b[1m[0.         0.19282997 0.4443505  0.         0.36281952]\u001b[0m\n",
      "[11:35:40] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8133185182207652\u001b[0m, weights = \u001b[1m[0.         0.19282997 0.4443505  0.         0.36281952]\u001b[0m\n",
      "[11:35:40] Blending: no score update. Terminated\n",
      "\n",
      "[11:35:40] \u001b[1mAutoml preset training completed in 840.12 seconds\u001b[0m\n",
      "\n",
      "[11:35:40] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.19283 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.44435 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.36282 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[11:35:40] ==================================================\n",
      "[11:35:40] Start 2 automl preset configuration:\n",
      "[11:35:40] \u001b[1mconf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'nn_params': {'random_state': 44}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:35:40] Stdout logging level is INFO.\n",
      "[11:35:40] Task: binary\n",
      "\n",
      "[11:35:40] Start automl preset with listed constraints:\n",
      "[11:35:40] - time: 5519.02 seconds\n",
      "[11:35:40] - CPU: 16 cores\n",
      "[11:35:40] - memory: 16 GB\n",
      "\n",
      "[11:35:40] \u001b[1mTrain data shape: (413194, 65)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:35:41] Layer \u001b[1m1\u001b[0m train process start. Time left 5518.17 secs\n",
      "[11:35:54] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:36:37] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8068739902274549\u001b[0m\n",
      "[11:36:37] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:36:37] Time left 5461.96 secs\n",
      "\n",
      "[11:36:43] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:36:55] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:37:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8059020253143211\u001b[0m\n",
      "[11:37:26] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:37:26] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:42:33] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:42:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8139220517298654\u001b[0m\n",
      "[11:43:10] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[11:43:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8121816743712735\u001b[0m\n",
      "[11:43:36] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[11:43:36] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:48:38] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[11:48:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[11:49:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8126184699499475\u001b[0m\n",
      "[11:49:15] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[11:49:15] Time left 4703.47 secs\n",
      "\n",
      "[11:49:15] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:49:15] Blending: optimization starts with equal weights and score \u001b[1m0.8130668009738871\u001b[0m\n",
      "[11:49:21] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8139472012533588\u001b[0m, weights = \u001b[1m[0.         0.         0.883173   0.05841349 0.05841349]\u001b[0m\n",
      "[11:49:27] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8139838679760055\u001b[0m, weights = \u001b[1m[0.         0.06970358 0.8755672  0.05472919 0.        ]\u001b[0m\n",
      "[11:49:32] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8139838961889247\u001b[0m, weights = \u001b[1m[0.         0.07143264 0.8739399  0.05462747 0.        ]\u001b[0m\n",
      "[11:49:38] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8139838961889247\u001b[0m, weights = \u001b[1m[0.         0.07143264 0.8739399  0.05462747 0.        ]\u001b[0m\n",
      "[11:49:38] Blending: no score update. Terminated\n",
      "\n",
      "[11:49:38] \u001b[1mAutoml preset training completed in 838.07 seconds\u001b[0m\n",
      "\n",
      "[11:49:38] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.07143 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.87394 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.05463 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n",
      "[11:49:38] ==================================================\n",
      "[11:49:38] Start 3 automl preset configuration:\n",
      "[11:49:38] \u001b[1mconf_3_sel_type_1_no_inter_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'nn_params': {'random_state': 45}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:49:38] Stdout logging level is INFO.\n",
      "[11:49:38] Task: binary\n",
      "\n",
      "[11:49:38] Start automl preset with listed constraints:\n",
      "[11:49:38] - time: 4680.92 seconds\n",
      "[11:49:38] - CPU: 16 cores\n",
      "[11:49:38] - memory: 16 GB\n",
      "\n",
      "[11:49:38] \u001b[1mTrain data shape: (413194, 65)\u001b[0m\n",
      "\n",
      "[11:49:49] Layer \u001b[1m1\u001b[0m train process start. Time left 4669.79 secs\n",
      "[11:50:02] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:50:49] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.806784027982133\u001b[0m\n",
      "[11:50:49] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:50:49] Time left 4609.49 secs\n",
      "\n",
      "[11:50:57] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:50:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:51:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8045463004699255\u001b[0m\n",
      "[11:51:29] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:51:29] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:56:32] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:56:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:57:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8126174285504564\u001b[0m\n",
      "[11:57:04] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:57:04] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[11:57:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8121478644308142\u001b[0m\n",
      "[11:57:26] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[11:57:26] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:02:30] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[12:02:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:03:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8126276435783701\u001b[0m\n",
      "[12:03:10] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:03:10] Time left 3868.51 secs\n",
      "\n",
      "[12:03:10] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:03:10] Blending: optimization starts with equal weights and score \u001b[1m0.8127945835343914\u001b[0m\n",
      "[12:03:16] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8133150806743182\u001b[0m, weights = \u001b[1m[0.         0.         0.47323027 0.21140325 0.3153665 ]\u001b[0m\n",
      "[12:03:22] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8133334013530116\u001b[0m, weights = \u001b[1m[0.         0.05132451 0.46173015 0.20653157 0.28041378]\u001b[0m\n",
      "[12:03:28] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8133334055717658\u001b[0m, weights = \u001b[1m[0.         0.05132484 0.46173316 0.20652643 0.28041562]\u001b[0m\n",
      "[12:03:33] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8133334084721594\u001b[0m, weights = \u001b[1m[0.         0.0513234  0.46172017 0.20654874 0.28040773]\u001b[0m\n",
      "[12:03:39] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8133334079975495\u001b[0m, weights = \u001b[1m[0.         0.05132339 0.46172014 0.20654872 0.28040773]\u001b[0m\n",
      "[12:03:39] Blending: no score update. Terminated\n",
      "\n",
      "[12:03:39] \u001b[1mAutoml preset training completed in 841.36 seconds\u001b[0m\n",
      "\n",
      "[12:03:39] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.05132 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.46172 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.20655 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.28041 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[12:03:39] ==================================================\n",
      "[12:03:39] Start 4 automl preset configuration:\n",
      "[12:03:39] \u001b[1mconf_4_sel_type_0_no_int.yml\u001b[0m, random state: {'reader_params': {'random_state': 46}, 'nn_params': {'random_state': 46}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:03:39] Stdout logging level is INFO.\n",
      "[12:03:39] Task: binary\n",
      "\n",
      "[12:03:39] Start automl preset with listed constraints:\n",
      "[12:03:39] - time: 3839.53 seconds\n",
      "[12:03:39] - CPU: 16 cores\n",
      "[12:03:39] - memory: 16 GB\n",
      "\n",
      "[12:03:39] \u001b[1mTrain data shape: (413194, 65)\u001b[0m\n",
      "\n",
      "[12:03:50] Layer \u001b[1m1\u001b[0m train process start. Time left 3828.31 secs\n",
      "[12:03:52] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:04:38] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.806621290116301\u001b[0m\n",
      "[12:04:38] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:04:38] Time left 3781.05 secs\n",
      "\n",
      "[12:04:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:05:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8062096940533585\u001b[0m\n",
      "[12:05:11] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:11] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:10:14] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:10:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:10:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8111058075522293\u001b[0m\n",
      "[12:10:43] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:10:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[12:11:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8122375014101819\u001b[0m\n",
      "[12:11:06] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:11:06] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:16:09] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[12:16:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:16:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8123799805016096\u001b[0m\n",
      "[12:16:43] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:16:43] Time left 3056.14 secs\n",
      "\n",
      "[12:16:43] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:16:43] Blending: optimization starts with equal weights and score \u001b[1m0.8125731899021795\u001b[0m\n",
      "[12:16:48] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8129111882148735\u001b[0m, weights = \u001b[1m[0.06326343 0.06634376 0.22331639 0.33783424 0.30924216]\u001b[0m\n",
      "[12:16:54] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.812950558737131\u001b[0m, weights = \u001b[1m[0.         0.07019731 0.24289851 0.35114613 0.3357581 ]\u001b[0m\n",
      "[12:16:59] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8129505593172097\u001b[0m, weights = \u001b[1m[0.         0.07019731 0.2428985  0.3511461  0.33575806]\u001b[0m\n",
      "[12:17:05] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8129505593172097\u001b[0m, weights = \u001b[1m[0.         0.07019731 0.2428985  0.3511461  0.33575806]\u001b[0m\n",
      "[12:17:05] Blending: no score update. Terminated\n",
      "\n",
      "[12:17:05] \u001b[1mAutoml preset training completed in 805.87 seconds\u001b[0m\n",
      "\n",
      "[12:17:05] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.07020 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.24290 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.35115 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.33576 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[12:17:05] ==================================================\n",
      "[12:17:05] Start 5 automl preset configuration:\n",
      "[12:17:05] \u001b[1mconf_5_sel_type_1_tuning_full.yml\u001b[0m, random state: {'reader_params': {'random_state': 47}, 'nn_params': {'random_state': 47}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:17:05] Stdout logging level is INFO.\n",
      "[12:17:05] Task: binary\n",
      "\n",
      "[12:17:05] Start automl preset with listed constraints:\n",
      "[12:17:05] - time: 3033.63 seconds\n",
      "[12:17:05] - CPU: 16 cores\n",
      "[12:17:05] - memory: 16 GB\n",
      "\n",
      "[12:17:05] \u001b[1mTrain data shape: (413194, 65)\u001b[0m\n",
      "\n",
      "[12:17:16] Layer \u001b[1m1\u001b[0m train process start. Time left 3022.56 secs\n",
      "[12:17:29] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:18:22] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8067392212785939\u001b[0m\n",
      "[12:18:22] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:18:22] Time left 2957.17 secs\n",
      "\n",
      "[12:18:28] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:18:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:19:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7988120583984164\u001b[0m\n",
      "[12:19:11] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:19:11] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:19:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:19:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7994623170895594\u001b[0m\n",
      "[12:19:41] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:19:41] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8007468419654298\u001b[0m\n",
      "[12:20:16] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:44] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.806668368513545\u001b[0m\n",
      "[12:20:44] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8013473157175277\u001b[0m\n",
      "[12:21:10] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:38] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8013502253923468\u001b[0m\n",
      "[12:21:38] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8046356402907895\u001b[0m\n",
      "[12:22:04] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7977212215407878\u001b[0m\n",
      "[12:22:31] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:31] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.808663901034603\u001b[0m\n",
      "[12:23:00] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:33] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8040939896314123\u001b[0m\n",
      "[12:23:33] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:24:01] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8016434905660292\u001b[0m\n",
      "[12:24:01] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:24:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:24:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8101165140004686\u001b[0m\n",
      "[12:24:27] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:24:27] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:24:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:24:52] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8101165140004686\u001b[0m\n",
      "[12:24:52] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:24:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[12:25:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8122402247215312\u001b[0m\n",
      "[12:25:16] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:25:16] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:25:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:25:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8122556705828625\u001b[0m\n",
      "[12:25:42] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:25:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:26:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8104359167826285\u001b[0m\n",
      "[12:26:04] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:26:04] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:26:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8123682705053863\u001b[0m\n",
      "[12:26:30] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:26:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:26:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8078098082212022\u001b[0m\n",
      "[12:26:48] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:26:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:27:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8105502893202271\u001b[0m\n",
      "[12:27:06] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:27:06] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:27:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8123630418868147\u001b[0m\n",
      "[12:27:30] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:27:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:27:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8117281667776433\u001b[0m\n",
      "[12:27:51] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:27:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:28:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8123335226303843\u001b[0m\n",
      "[12:28:16] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:28:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:28:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8122382535085992\u001b[0m\n",
      "[12:28:41] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:28:41] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:29:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8120394953387431\u001b[0m\n",
      "[12:29:04] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:29:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:29:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8123451100190616\u001b[0m\n",
      "[12:29:28] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:29:28] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:29:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8124202157630234\u001b[0m\n",
      "[12:29:51] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:29:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:30:14] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8122737697242224\u001b[0m\n",
      "[12:30:14] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:30:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:30:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8122828985811152\u001b[0m\n",
      "[12:30:37] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:30:37] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[12:30:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:31:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8124740213858238\u001b[0m\n",
      "[12:31:11] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:31:11] Time left 2187.84 secs\n",
      "\n",
      "[12:31:11] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:31:11] Blending: optimization starts with equal weights and score \u001b[1m0.8118439765393523\u001b[0m\n",
      "[12:31:17] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.812727840837954\u001b[0m, weights = \u001b[1m[0.06057481 0.         0.3711576  0.23995115 0.32831648]\u001b[0m\n",
      "[12:31:22] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8128418056329526\u001b[0m, weights = \u001b[1m[0.         0.         0.5217872  0.19602144 0.28219134]\u001b[0m\n",
      "[12:31:28] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8128418056329526\u001b[0m, weights = \u001b[1m[0.         0.         0.5217872  0.19602144 0.28219134]\u001b[0m\n",
      "[12:31:28] Blending: no score update. Terminated\n",
      "\n",
      "[12:31:28] \u001b[1mAutoml preset training completed in 862.66 seconds\u001b[0m\n",
      "\n",
      "[12:31:28] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.52179 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.19602 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.28219 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[12:31:28] ==================================================\n",
      "[12:31:28] Start 6 automl preset configuration:\n",
      "[12:31:28] \u001b[1mconf_6_sel_type_1_tuning_full_no_int_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 48}, 'nn_params': {'random_state': 48}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:31:28] Stdout logging level is INFO.\n",
      "[12:31:28] Task: binary\n",
      "\n",
      "[12:31:28] Start automl preset with listed constraints:\n",
      "[12:31:28] - time: 2170.94 seconds\n",
      "[12:31:28] - CPU: 16 cores\n",
      "[12:31:28] - memory: 16 GB\n",
      "\n",
      "[12:31:28] \u001b[1mTrain data shape: (413194, 65)\u001b[0m\n",
      "\n",
      "[12:31:39] Layer \u001b[1m1\u001b[0m train process start. Time left 2159.86 secs\n",
      "[12:31:52] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:32:37] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8066560930987807\u001b[0m\n",
      "[12:32:37] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:32:37] Time left 2101.37 secs\n",
      "\n",
      "[12:32:43] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:32:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:33:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8080760247464228\u001b[0m\n",
      "[12:33:16] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:33:16] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:38:20] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:38:20] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:38:55] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8132906785031433\u001b[0m\n",
      "[12:38:55] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:38:55] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[12:39:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8121094282044239\u001b[0m\n",
      "[12:39:17] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:39:17] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:44:18] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[12:44:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:44:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8123410571673046\u001b[0m\n",
      "[12:44:51] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:44:51] Time left 1367.57 secs\n",
      "\n",
      "[12:44:51] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:44:51] Blending: optimization starts with equal weights and score \u001b[1m0.8126318965045483\u001b[0m\n",
      "[12:44:57] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.813403978897079\u001b[0m, weights = \u001b[1m[0.         0.         0.7186909  0.17051756 0.11079158]\u001b[0m\n",
      "[12:45:02] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8134041602507782\u001b[0m, weights = \u001b[1m[0.         0.         0.71794564 0.17408873 0.10796564]\u001b[0m\n",
      "[12:45:08] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.813404164047657\u001b[0m, weights = \u001b[1m[0.         0.         0.7179425  0.17408799 0.10796959]\u001b[0m\n",
      "[12:45:14] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8134041642585947\u001b[0m, weights = \u001b[1m[0.         0.         0.7179425  0.17408799 0.10796958]\u001b[0m\n",
      "[12:45:19] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8134041642585947\u001b[0m, weights = \u001b[1m[0.         0.         0.7179425  0.17408799 0.10796958]\u001b[0m\n",
      "[12:45:19] Blending: no score update. Terminated\n",
      "\n",
      "[12:45:19] \u001b[1mAutoml preset training completed in 831.46 seconds\u001b[0m\n",
      "\n",
      "[12:45:19] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.71794 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.17409 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.10797 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[12:45:19] ==================================================\n",
      "[12:45:19] ==================================================\n",
      "[12:45:19] Start 0 automl preset configuration:\n",
      "[12:45:19] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 49}, 'nn_params': {'random_state': 49}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:45:19] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:45:19] Task: binary\n",
      "\n",
      "[12:45:19] Start automl preset with listed constraints:\n",
      "[12:45:19] - time: 1339.45 seconds\n",
      "[12:45:19] - CPU: 16 cores\n",
      "[12:45:19] - memory: 16 GB\n",
      "\n",
      "[12:45:19] \u001b[1mTrain data shape: (413194, 65)\u001b[0m\n",
      "\n",
      "[12:45:30] Layer \u001b[1m1\u001b[0m train process start. Time left 1328.36 secs\n",
      "[12:45:43] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:46:28] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8067974022241808\u001b[0m\n",
      "[12:46:28] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:46:28] Time left 1270.79 secs\n",
      "\n",
      "[12:46:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:47:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8029268520676753\u001b[0m\n",
      "[12:47:11] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:47:11] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 197.75 secs\n",
      "[12:50:32] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:50:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:51:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8135288538652259\u001b[0m\n",
      "[12:51:03] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:51:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[12:51:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8118541953114105\u001b[0m\n",
      "[12:51:26] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:51:26] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:56:31] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[12:56:31] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[12:57:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8125435772530765\u001b[0m\n",
      "[12:57:07] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:57:07] Time left 631.77 secs\n",
      "\n",
      "[12:57:07] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:57:07] Blending: optimization starts with equal weights and score \u001b[1m0.8127304816726574\u001b[0m\n",
      "[12:57:13] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8136064512581931\u001b[0m, weights = \u001b[1m[0.         0.         0.7451511  0.08375842 0.1710905 ]\u001b[0m\n",
      "[12:57:18] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8137535753035394\u001b[0m, weights = \u001b[1m[0.         0.09180629 0.7855583  0.         0.12263542]\u001b[0m\n",
      "[12:57:24] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8137623070701867\u001b[0m, weights = \u001b[1m[0.         0.10800181 0.79236335 0.         0.09963482]\u001b[0m\n",
      "[12:57:29] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8137623070701867\u001b[0m, weights = \u001b[1m[0.         0.10800181 0.79236335 0.         0.09963482]\u001b[0m\n",
      "[12:57:29] Blending: no score update. Terminated\n",
      "\n",
      "[12:57:29] \u001b[1mAutoml preset training completed in 730.22 seconds\u001b[0m\n",
      "\n",
      "[12:57:29] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.10800 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.79236 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.09963 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[12:57:29] ==================================================\n",
      "[12:57:30] Blending: optimization starts with equal weights and score \u001b[1m0.8137841262563261\u001b[0m\n",
      "[12:57:38] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8140105120459331\u001b[0m, weights = \u001b[1m[0.         0.         0.68752646 0.26057234 0.         0.\n",
      " 0.05190118]\u001b[0m\n",
      "[12:57:46] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8140187873961031\u001b[0m, weights = \u001b[1m[0.06853759 0.         0.75392145 0.17754099 0.         0.\n",
      " 0.        ]\u001b[0m\n",
      "[12:57:54] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8140215389731059\u001b[0m, weights = \u001b[1m[0.10379085 0.05839453 0.6985847  0.13922994 0.         0.\n",
      " 0.        ]\u001b[0m\n",
      "[12:58:02] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8140217371490877\u001b[0m, weights = \u001b[1m[0.09066706 0.05919364 0.70814466 0.14199463 0.         0.\n",
      " 0.        ]\u001b[0m\n",
      "[12:58:10] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8140217779655352\u001b[0m, weights = \u001b[1m[0.08798068 0.05936852 0.71023667 0.14241412 0.         0.\n",
      " 0.        ]\u001b[0m\n",
      "[2024-11-08 12:58:10,833] - [    END     ] - Fitting TabularLamaUtilized\n",
      "0.8140217779655352\n"
     ]
    }
   ],
   "source": [
    "model = TabularLamaUtilized(n_jobs=16, task=\"classification\")\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 60, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "594acc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8140217779655352\n"
     ]
    }
   ],
   "source": [
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f90941e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lamau_814_full_dataset</td>\n",
       "      <td>155900.645331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_83</td>\n",
       "      <td>1862.207562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_14</td>\n",
       "      <td>1780.640471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_24</td>\n",
       "      <td>1777.973118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_148</td>\n",
       "      <td>1773.221087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>feature_122</td>\n",
       "      <td>20.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>feature_179</td>\n",
       "      <td>19.531767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>feature_156</td>\n",
       "      <td>17.388200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>feature_109</td>\n",
       "      <td>16.693633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>feature_31</td>\n",
       "      <td>4.051000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature     Importance\n",
       "0   lamau_814_full_dataset  155900.645331\n",
       "1               feature_83    1862.207562\n",
       "2               feature_14    1780.640471\n",
       "3               feature_24    1777.973118\n",
       "4              feature_148    1773.221087\n",
       "..                     ...            ...\n",
       "59             feature_122      20.285800\n",
       "60             feature_179      19.531767\n",
       "61             feature_156      17.388200\n",
       "62             feature_109      16.693633\n",
       "63              feature_31       4.051000\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.get_feature_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6dd6ac2-6191-43c5-84da-522b4829abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lamau_stack_8140_full_dataset\"\n",
    "MODEL_DIR = Path(f\"../../../../data/models/{MODEL_NAME}\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e4fed09-b428-4509-8644-347cbbb27f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res[MODEL_NAME] = oof[:, 1]\n",
    "res.to_csv(MODEL_DIR / \"oof.csv\", index=False)\n",
    "#joblib.dump(model, MODEL_DIR / f\"{MODEL_NAME}.joblib\")\n",
    "\n",
    "with (MODEL_DIR / \"params.yaml\").open(\"w\") as f:\n",
    "    yaml.dump(model.params, f)\n",
    "\n",
    "with (MODEL_DIR / \"score.txt\").open(\"w\") as f:\n",
    "    print(\"OOF:\", metric(y_train, oof), file=f)\n",
    "    \n",
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_oof.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"]+ cfg[\"stack_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(MODEL_DIR / f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebab2080",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_oof.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cfg[\"stack_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7446223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lamau_814_full_dataset</td>\n",
       "      <td>78048.337071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb_81325_full_dataset</td>\n",
       "      <td>29297.001751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lama_81298_full_dataset</td>\n",
       "      <td>24098.444188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_162</td>\n",
       "      <td>1398.695796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_24</td>\n",
       "      <td>1321.674997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feature_18</td>\n",
       "      <td>1298.269506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feature_26</td>\n",
       "      <td>1290.120701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feature_145</td>\n",
       "      <td>1287.683197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feature_78</td>\n",
       "      <td>1279.916003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_36</td>\n",
       "      <td>1248.758602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_112</td>\n",
       "      <td>1228.811199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_9</td>\n",
       "      <td>1190.729637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_141</td>\n",
       "      <td>1140.620801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature_75</td>\n",
       "      <td>1127.175495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feature_79</td>\n",
       "      <td>1114.103202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feature_62</td>\n",
       "      <td>1110.960901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feature_35</td>\n",
       "      <td>1088.471595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>feature_44</td>\n",
       "      <td>1078.257104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feature_168</td>\n",
       "      <td>1069.888995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>feature_148</td>\n",
       "      <td>1055.762701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>feature_147</td>\n",
       "      <td>1051.141966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>feature_76</td>\n",
       "      <td>1041.521295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feature_20</td>\n",
       "      <td>1029.698003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>feature_157</td>\n",
       "      <td>998.859297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feature_33</td>\n",
       "      <td>993.189499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>feature_133</td>\n",
       "      <td>992.890409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>feature_59</td>\n",
       "      <td>988.289097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>feature_46</td>\n",
       "      <td>978.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>feature_14</td>\n",
       "      <td>968.263297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>feature_43</td>\n",
       "      <td>967.263209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>feature_142</td>\n",
       "      <td>953.593235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>feature_83</td>\n",
       "      <td>951.608026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>feature_96</td>\n",
       "      <td>936.340199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lgb_8122_full_dataset</td>\n",
       "      <td>899.356003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>feature_126</td>\n",
       "      <td>894.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>feature_100</td>\n",
       "      <td>889.852299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>feature_55</td>\n",
       "      <td>889.369598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>feature_183</td>\n",
       "      <td>882.159472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>feature_127</td>\n",
       "      <td>853.308690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>feature_153</td>\n",
       "      <td>835.863204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>feature_87</td>\n",
       "      <td>802.161905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>feature_8</td>\n",
       "      <td>801.556602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>feature_103</td>\n",
       "      <td>793.046144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>feature_29</td>\n",
       "      <td>783.742097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>feature_134</td>\n",
       "      <td>777.999600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>feature_11</td>\n",
       "      <td>771.673395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>feature_66</td>\n",
       "      <td>770.873203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>feature_72</td>\n",
       "      <td>722.490300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>feature_21</td>\n",
       "      <td>675.958407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>feature_25</td>\n",
       "      <td>664.108699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature    Importance\n",
       "0    lamau_814_full_dataset  78048.337071\n",
       "1    xgb_81325_full_dataset  29297.001751\n",
       "2   lama_81298_full_dataset  24098.444188\n",
       "3               feature_162   1398.695796\n",
       "4                feature_24   1321.674997\n",
       "5                feature_18   1298.269506\n",
       "6                feature_26   1290.120701\n",
       "7               feature_145   1287.683197\n",
       "8                feature_78   1279.916003\n",
       "9                feature_36   1248.758602\n",
       "10              feature_112   1228.811199\n",
       "11                feature_9   1190.729637\n",
       "12              feature_141   1140.620801\n",
       "13               feature_75   1127.175495\n",
       "14               feature_79   1114.103202\n",
       "15               feature_62   1110.960901\n",
       "16               feature_35   1088.471595\n",
       "17               feature_44   1078.257104\n",
       "18              feature_168   1069.888995\n",
       "19              feature_148   1055.762701\n",
       "20              feature_147   1051.141966\n",
       "21               feature_76   1041.521295\n",
       "22               feature_20   1029.698003\n",
       "23              feature_157    998.859297\n",
       "24               feature_33    993.189499\n",
       "25              feature_133    992.890409\n",
       "26               feature_59    988.289097\n",
       "27               feature_46    978.601000\n",
       "28               feature_14    968.263297\n",
       "29               feature_43    967.263209\n",
       "30              feature_142    953.593235\n",
       "31               feature_83    951.608026\n",
       "32               feature_96    936.340199\n",
       "33    lgb_8122_full_dataset    899.356003\n",
       "34              feature_126    894.646700\n",
       "35              feature_100    889.852299\n",
       "36               feature_55    889.369598\n",
       "37              feature_183    882.159472\n",
       "38              feature_127    853.308690\n",
       "39              feature_153    835.863204\n",
       "40               feature_87    802.161905\n",
       "41                feature_8    801.556602\n",
       "42              feature_103    793.046144\n",
       "43               feature_29    783.742097\n",
       "44              feature_134    777.999600\n",
       "45               feature_11    771.673395\n",
       "46               feature_66    770.873203\n",
       "47               feature_72    722.490300\n",
       "48               feature_21    675.958407\n",
       "49               feature_25    664.108699"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.get_feature_scores()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f687e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame().assign(names=model.models[0].feature_names_, imp=model.models[0].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d1e1081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>feature_185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          names  imp\n",
       "61  feature_185  0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values(by=\"imp\", ascending=False).reset_index(drop=True).query(\"names == 'feature_185'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce7e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_7',\n",
       " 'feature_31',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_71',\n",
       " 'feature_109',\n",
       " 'feature_122',\n",
       " 'feature_156',\n",
       " 'feature_163',\n",
       " 'feature_167',\n",
       " 'feature_179',\n",
       " 'feature_185']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517948d",
   "metadata": {},
   "source": [
    "## With Time series cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fcb3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = RocAuc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d859f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by=\"id\").reset_index(drop=True)\n",
    "X_train, y_train = df_train[cfg[\"selected_features\"] + cat_columns], df_train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e52d68ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 08:27:33,388] - [   START    ] - Tuning LightGBMClassification\n",
      "[2024-11-07 08:27:40,118] - [   OPTUNA   ] - Trial 0. New best score 0.7903405446081995 with parameters {'max_depth': 6, 'num_leaves': 488, 'min_data_in_leaf': 188, 'bagging_fraction': 0.7993292420985183, 'bagging_freq': 0, 'feature_fraction': 0.49359671220172163, 'lambda_l1': 0.5808361216819946, 'lambda_l2': 8.661761457749352, 'min_gain_to_split': 12.022300234864176, 'is_unbalance': True, 'num_iterations': 2}\n",
      "[2024-11-07 08:28:03,043] - [   OPTUNA   ] - Trial 2. New best score 0.7913515589848906 with parameters {'max_depth': 5, 'num_leaves': 194, 'min_data_in_leaf': 117, 'bagging_fraction': 0.8925879806965068, 'bagging_freq': 0, 'feature_fraction': 0.708540663048167, 'lambda_l1': 5.924145688620425, 'lambda_l2': 0.46450412719997725, 'min_gain_to_split': 12.150897038028766, 'is_unbalance': True, 'num_iterations': 2}\n",
      "[2024-11-07 08:28:12,225] - [   OPTUNA   ] - Trial 3. New best score 0.8048686053278628 with parameters {'max_depth': 16, 'num_leaves': 495, 'min_data_in_leaf': 207, 'bagging_fraction': 0.6523068845866853, 'bagging_freq': 0, 'feature_fraction': 0.8105398159072941, 'lambda_l1': 4.4015249373960135, 'lambda_l2': 1.2203823484477883, 'min_gain_to_split': 9.903538202225404, 'is_unbalance': False, 'num_iterations': 201}\n",
      "[2024-11-07 08:28:27,946] - [   OPTUNA   ] - Trial 5. New best score 0.805775359050857 with parameters {'max_depth': 15, 'num_leaves': 54, 'min_data_in_leaf': 51, 'bagging_fraction': 0.522613644455269, 'bagging_freq': 0, 'feature_fraction': 0.6332063738136893, 'lambda_l1': 2.713490317738959, 'lambda_l2': 8.287375091519294, 'min_gain_to_split': 7.135066533871786, 'is_unbalance': False, 'num_iterations': 219}\n",
      "[2024-11-07 08:30:01,873] - [   OPTUNA   ] - Trial 13. New best score 0.8069467403107815 with parameters {'max_depth': 12, 'num_leaves': 120, 'min_data_in_leaf': 83, 'bagging_fraction': 0.5973813098180023, 'bagging_freq': 0, 'feature_fraction': 0.6464487752219038, 'lambda_l1': 1.815539729792131, 'lambda_l2': 9.653379460654552, 'min_gain_to_split': 5.109079440883124, 'is_unbalance': False, 'num_iterations': 194}\n",
      "[2024-11-07 08:30:23,656] - [   OPTUNA   ] - Trial 15. New best score 0.8079174231410097 with parameters {'max_depth': 9, 'num_leaves': 123, 'min_data_in_leaf': 79, 'bagging_fraction': 0.6696558155271586, 'bagging_freq': 0, 'feature_fraction': 0.41254813989004224, 'lambda_l1': 1.5400879612744933, 'lambda_l2': 6.428485487443978, 'min_gain_to_split': 3.4073761639683475, 'is_unbalance': False, 'num_iterations': 221}\n",
      "[2024-11-07 08:30:47,866] - [   OPTUNA   ] - Trial 17. New best score 0.8080338307668665 with parameters {'max_depth': 9, 'num_leaves': 177, 'min_data_in_leaf': 149, 'bagging_fraction': 0.7020257462335121, 'bagging_freq': 0, 'feature_fraction': 0.4001314682445803, 'lambda_l1': 4.277484898844048, 'lambda_l2': 5.915176709957256, 'min_gain_to_split': 2.630193834916201, 'is_unbalance': False, 'num_iterations': 247}\n",
      "[2024-11-07 08:32:56,360] - [   OPTUNA   ] - Trial 26. New best score 0.8083158418056456 with parameters {'max_depth': 13, 'num_leaves': 120, 'min_data_in_leaf': 166, 'bagging_fraction': 0.8112271899455036, 'bagging_freq': 20, 'feature_fraction': 0.5385502023308056, 'lambda_l1': 1.3349604628055485, 'lambda_l2': 8.855392863089838, 'min_gain_to_split': 0.42505008659048693, 'is_unbalance': False, 'num_iterations': 206}\n",
      "[2024-11-07 08:33:39,494] - [   OPTUNA   ] - Trial 28. New best score 0.8085529083857821 with parameters {'max_depth': 14, 'num_leaves': 75, 'min_data_in_leaf': 170, 'bagging_fraction': 0.8264267643219445, 'bagging_freq': 20, 'feature_fraction': 0.5742524097970673, 'lambda_l1': 1.2310934175206736, 'lambda_l2': 8.969396792235317, 'min_gain_to_split': 0.16644360284870074, 'is_unbalance': False, 'num_iterations': 211}\n",
      "[2024-11-07 08:35:41,908] - [   OPTUNA   ] - Trial 35. New best score 0.8085624905981069 with parameters {'max_depth': 13, 'num_leaves': 45, 'min_data_in_leaf': 179, 'bagging_fraction': 0.9090867052918509, 'bagging_freq': 20, 'feature_fraction': 0.5986896700241908, 'lambda_l1': 1.0457599526213117, 'lambda_l2': 8.511810626751942, 'min_gain_to_split': 1.6394745612739139, 'is_unbalance': False, 'num_iterations': 242}\n",
      "[2024-11-07 08:36:11,789] - [   OPTUNA   ] - Trial 37. New best score 0.8086060147129036 with parameters {'max_depth': 15, 'num_leaves': 146, 'min_data_in_leaf': 131, 'bagging_fraction': 0.9727869256250319, 'bagging_freq': 20, 'feature_fraction': 0.594412726250827, 'lambda_l1': 1.3076349982497943, 'lambda_l2': 8.42304491740083, 'min_gain_to_split': 1.95638379105971, 'is_unbalance': False, 'num_iterations': 180}\n",
      "[2024-11-07 08:37:31,532] - [   OPTUNA   ] - Trial 42. New best score 0.8086748450733487 with parameters {'max_depth': 11, 'num_leaves': 95, 'min_data_in_leaf': 155, 'bagging_fraction': 0.9696680239166591, 'bagging_freq': 20, 'feature_fraction': 0.5068877996580057, 'lambda_l1': 0.3880584908457285, 'lambda_l2': 9.519643874182023, 'min_gain_to_split': 1.5176677728376484, 'is_unbalance': False, 'num_iterations': 225}\n",
      "[2024-11-07 08:43:11,113] - [   OPTUNA   ] - Trial 63. New best score 0.8087325744854885 with parameters {'max_depth': 16, 'num_leaves': 160, 'min_data_in_leaf': 166, 'bagging_fraction': 0.936885833403046, 'bagging_freq': 20, 'feature_fraction': 0.4498188675696397, 'lambda_l1': 1.1357746192947442, 'lambda_l2': 7.7534455607773385, 'min_gain_to_split': 2.069412187433082, 'is_unbalance': False, 'num_iterations': 207}\n",
      "[2024-11-07 08:45:27,863] - [   OPTUNA   ] - Trial 71. New best score 0.809046586456055 with parameters {'max_depth': 10, 'num_leaves': 153, 'min_data_in_leaf': 160, 'bagging_fraction': 0.9135728904594532, 'bagging_freq': 10, 'feature_fraction': 0.506921563666065, 'lambda_l1': 0.6725410135999423, 'lambda_l2': 8.841591608898721, 'min_gain_to_split': 1.6964405734320749, 'is_unbalance': False, 'num_iterations': 237}\n",
      "[2024-11-07 08:51:41,348] - [   OPTUNA   ] - Trial 91. New best score 0.8092009955871362 with parameters {'max_depth': 8, 'num_leaves': 331, 'min_data_in_leaf': 57, 'bagging_fraction': 0.9120914616559199, 'bagging_freq': 10, 'feature_fraction': 0.43368773726287124, 'lambda_l1': 3.8666345262680837, 'lambda_l2': 8.173281721666852, 'min_gain_to_split': 0.7062609644931823, 'is_unbalance': False, 'num_iterations': 313}\n",
      "[2024-11-07 09:24:15,316] - [   OPTUNA   ] - Trial 184. New best score 0.8092209952891476 with parameters {'max_depth': 8, 'num_leaves': 258, 'min_data_in_leaf': 21, 'bagging_fraction': 0.8833000021442096, 'bagging_freq': 10, 'feature_fraction': 0.44326798567844145, 'lambda_l1': 1.7734419425628303, 'lambda_l2': 8.481446649565262, 'min_gain_to_split': 0.19263364585511303, 'is_unbalance': False, 'num_iterations': 294}\n",
      "[2024-11-07 09:27:54,872] - [   OPTUNA   ] - 195 trials completed\n",
      "[2024-11-07 09:27:54,874] - [BEST PARAMS ] - {'objective_type': 'binary', 'boosting': 'gbdt', 'num_iterations': 294, 'max_depth': 8, 'learning_rate': 0.03, 'num_leaves': 258, 'min_data_in_leaf': 21, 'bagging_fraction': 0.8833000021442096, 'bagging_freq': 10, 'feature_fraction': 0.44326798567844145, 'early_stopping_round': 100, 'lambda_l1': 1.7734419425628303, 'lambda_l2': 8.481446649565262, 'min_gain_to_split': 0.19263364585511303, 'num_threads': 16, 'random_state': 42, 'is_unbalance': False, 'num_classes': 1, 'verbose': -1}\n",
      "[2024-11-07 09:27:54,875] - [    END     ] - Tuning LightGBMClassification\n",
      "[2024-11-07 09:27:54,877] - [   START    ] - Fitting LightGBMClassification\n",
      "[2024-11-07 09:27:54,892] - [    FIT     ] - LightGBMClassification fold 0\n",
      "[2024-11-07 09:27:56,881] - [    FIT     ] - LightGBMClassification fold 1\n",
      "[2024-11-07 09:27:59,788] - [    FIT     ] - LightGBMClassification fold 2\n",
      "[2024-11-07 09:28:04,156] - [    FIT     ] - LightGBMClassification fold 3\n",
      "[2024-11-07 09:28:09,145] - [    FIT     ] - LightGBMClassification fold 4\n",
      "[2024-11-07 09:28:14,959] - [    END     ] - Fitting LightGBMClassification\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = LightGBMClassification(n_jobs=16, time_series=True)\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 60, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a073f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_oofs_idx = oof[np.any(np.isnan(oof), axis=1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f8165e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095227594190041"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y_train[none_oofs_idx:], oof[none_oofs_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc0326db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lgb_8095_full_dataset_time_series\"\n",
    "MODEL_DIR = Path(f\"../../../data/models/{MODEL_NAME}\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "652cae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res[MODEL_NAME] = oof[none_oofs_idx:, 1]\n",
    "res.to_csv(MODEL_DIR / \"oof.csv\", index=False)\n",
    "joblib.dump(model, MODEL_DIR / f\"{MODEL_NAME}.joblib\")\n",
    "\n",
    "with (MODEL_DIR / \"params.yaml\").open(\"w\") as f:\n",
    "    yaml.dump(model.params, f)\n",
    "\n",
    "with (MODEL_DIR / \"score.txt\").open(\"w\") as f:\n",
    "    print(\"OOF:\", metric(y_train, oof), file=f)\n",
    "    \n",
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(MODEL_DIR / f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c20b42",
   "metadata": {},
   "source": [
    "## TEST \n",
    "**81.22112399468679**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e490c4a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3645213-67f1-4a56-8449-706616b01975",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv('lgb_813.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b626f4-24d7-47cc-8e1c-8d4829422eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pd.read_csv(\"lama_utilized.csv\")\n",
    "pred_2 = pd.read_csv(\"lgmb_oe_ohe_cols_0805.csv\")\n",
    "pred_3 = pd.read_csv(\"catboost_ts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6fd1b74-1c84-47a2-9640-f9afca52a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1[\"target\"] = 0.6 * pred_1[\"target\"] + 0.2 * pred_2[\"target\"] + 0.2 * pred_3[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9a12186-27a7-43e5-bbf9-05d9894bd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1.to_csv(\"blend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1a479dff-a006-4237-9a22-9b4a9d6a52eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Open the file pointed by this path and return a file object, as\n",
       "the built-in open() function does.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/lib/python3.10/pathlib.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_DIR.open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9b1c6-0fb4-461a-9aa9-1c23e299671f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_kernel",
   "language": "python",
   "name": "base_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
