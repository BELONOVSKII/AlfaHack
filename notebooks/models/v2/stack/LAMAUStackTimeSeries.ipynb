{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa3af6a-d478-4c0e-a715-21f3f6707c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../../../../automl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe599f1-83eb-4e6b-8115-f05eb659ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.automl.model.lama import TabularLamaUtilized\n",
    "from src.automl.loggers import configure_root_logger\n",
    "from src.automl.constants import create_ml_data_dir\n",
    "from src.automl.model.metrics import RocAuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087a93ef-e784-4dbb-8962-24e871577fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ml_data_dir()\n",
    "configure_root_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4701a7-04a9-42cd-b472-d9ca1dce955d",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9446b478-3af7-4d89-8d52-0d16996734e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 77\n",
    "DATA_PATH = Path(\"../../../../data/\")\n",
    "CONFIG_PATH = Path(\"../../../../configs/config.yaml\")\n",
    "N_JOBS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5494d0ab-4d12-47b3-bbaa-31fd51961cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CONFIG_PATH.open() as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1cf46-0712-400d-b190-15de4b596d15",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7208e0bf-13a0-4f7a-9f2e-307f386ef935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(DATA_PATH / \"train_preproc_oof.parquet\")\n",
    "#df_train, df_test = df_train.sort_values(by=\"id\").iloc[:300_000], df_train.sort_values(by=\"id\").iloc[300_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d55cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by=\"id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b73ba9-d6c5-4e83-b7ed-480881d44647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940982\n",
       "1    0.059018\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83dba0de-f224-4a5a-84db-acb5ff2ba670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample the 0 class\n",
    "#df_train = pd.concat([df_train.loc[df_train.target == 1], df_train.loc[df_train.target == 0].sample(200_000, random_state=RANDOM_SEED)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4bbaca-2b74-4177-88e4-4897ff07498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = df_train.drop(columns=[\"target\", \"id\"]).select_dtypes(int).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2525aeac-d91b-4864-a2cb-24f94702c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train[cfg[\"stack_features\"] + cfg[\"selected_features\"] + cat_columns], df_train[\"target\"]\n",
    "#X_test, y_test = df_test[cfg[\"selected_features\"] + cat_columns], df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f28cd79-395e-4e5d-9fa6-015a640955d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940982\n",
       "1    0.059018\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train.value_counts(normalize=True))\n",
    "#display(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b00734-0a36-4487-93ed-c78e6833ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_features = ohe_cols# + oe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "622bf7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>smpl</th>\n",
       "      <th>id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>feature_34</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_154</th>\n",
       "      <th>feature_155</th>\n",
       "      <th>feature_156</th>\n",
       "      <th>feature_157</th>\n",
       "      <th>feature_158</th>\n",
       "      <th>feature_159</th>\n",
       "      <th>feature_160</th>\n",
       "      <th>feature_161</th>\n",
       "      <th>feature_162</th>\n",
       "      <th>feature_163</th>\n",
       "      <th>feature_164</th>\n",
       "      <th>feature_165</th>\n",
       "      <th>feature_166</th>\n",
       "      <th>feature_167</th>\n",
       "      <th>feature_168</th>\n",
       "      <th>feature_169</th>\n",
       "      <th>feature_170</th>\n",
       "      <th>feature_171</th>\n",
       "      <th>feature_172</th>\n",
       "      <th>feature_173</th>\n",
       "      <th>feature_174</th>\n",
       "      <th>feature_175</th>\n",
       "      <th>feature_176</th>\n",
       "      <th>feature_177</th>\n",
       "      <th>feature_178</th>\n",
       "      <th>feature_179</th>\n",
       "      <th>feature_180</th>\n",
       "      <th>feature_181</th>\n",
       "      <th>feature_182</th>\n",
       "      <th>feature_183</th>\n",
       "      <th>feature_184</th>\n",
       "      <th>feature_185</th>\n",
       "      <th>feature_186</th>\n",
       "      <th>lamau_81425_full_dataset</th>\n",
       "      <th>lgb_8122_full_dataset</th>\n",
       "      <th>cb_8114_full_dataset</th>\n",
       "      <th>xgb_81325_full_dataset</th>\n",
       "      <th>lama_81298_full_dataset</th>\n",
       "      <th>lamann_autoint_8053_full_dataset</th>\n",
       "      <th>lamann_fttransformer_8050_full_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131533</td>\n",
       "      <td>0.953282</td>\n",
       "      <td>-0.753298</td>\n",
       "      <td>0.321620</td>\n",
       "      <td>0.753557</td>\n",
       "      <td>-1.050702</td>\n",
       "      <td>49</td>\n",
       "      <td>0.279169</td>\n",
       "      <td>0.722191</td>\n",
       "      <td>-0.730610</td>\n",
       "      <td>-0.760519</td>\n",
       "      <td>0.386393</td>\n",
       "      <td>1.281216</td>\n",
       "      <td>0.782489</td>\n",
       "      <td>0.311110</td>\n",
       "      <td>-0.522017</td>\n",
       "      <td>1.260190</td>\n",
       "      <td>-1.227740</td>\n",
       "      <td>-1.049272</td>\n",
       "      <td>-0.769352</td>\n",
       "      <td>-0.604599</td>\n",
       "      <td>0.192394</td>\n",
       "      <td>-0.993057</td>\n",
       "      <td>-1.323136</td>\n",
       "      <td>-1.288055</td>\n",
       "      <td>0.527455</td>\n",
       "      <td>-0.022240</td>\n",
       "      <td>0.973419</td>\n",
       "      <td>-0.739394</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.818497</td>\n",
       "      <td>-0.156309</td>\n",
       "      <td>-0.261131</td>\n",
       "      <td>-1.341291</td>\n",
       "      <td>0.894532</td>\n",
       "      <td>0.779233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123593</td>\n",
       "      <td>0.277190</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.633261</td>\n",
       "      <td>1.048579</td>\n",
       "      <td>-0.534421</td>\n",
       "      <td>-0.313637</td>\n",
       "      <td>-1.031983</td>\n",
       "      <td>-1.021433</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.493691</td>\n",
       "      <td>-1.986774</td>\n",
       "      <td>0.370009</td>\n",
       "      <td>0</td>\n",
       "      <td>1.376156</td>\n",
       "      <td>-1.340452</td>\n",
       "      <td>0.192977</td>\n",
       "      <td>-1.551252</td>\n",
       "      <td>0.269545</td>\n",
       "      <td>-0.794526</td>\n",
       "      <td>-0.234620</td>\n",
       "      <td>-0.055814</td>\n",
       "      <td>0.277029</td>\n",
       "      <td>-1.244719</td>\n",
       "      <td>-0.919482</td>\n",
       "      <td>8</td>\n",
       "      <td>1.466316</td>\n",
       "      <td>0.089004</td>\n",
       "      <td>1.837843</td>\n",
       "      <td>0.725687</td>\n",
       "      <td>-0.754875</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.021047</td>\n",
       "      <td>0.023596</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>0.079370</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.017239</td>\n",
       "      <td>0.023806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1.178071</td>\n",
       "      <td>0.398071</td>\n",
       "      <td>-0.505135</td>\n",
       "      <td>1.095571</td>\n",
       "      <td>0.714723</td>\n",
       "      <td>1.120692</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333070</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.947475</td>\n",
       "      <td>0.375749</td>\n",
       "      <td>-0.026053</td>\n",
       "      <td>-0.132769</td>\n",
       "      <td>-0.676351</td>\n",
       "      <td>0.462917</td>\n",
       "      <td>1.407544</td>\n",
       "      <td>1.188619</td>\n",
       "      <td>0.945775</td>\n",
       "      <td>-0.564650</td>\n",
       "      <td>0.607051</td>\n",
       "      <td>-0.236859</td>\n",
       "      <td>-0.684764</td>\n",
       "      <td>-0.831154</td>\n",
       "      <td>0.598141</td>\n",
       "      <td>0.658130</td>\n",
       "      <td>0.728178</td>\n",
       "      <td>0.530996</td>\n",
       "      <td>1.393327</td>\n",
       "      <td>0.382338</td>\n",
       "      <td>-0.578627</td>\n",
       "      <td>1</td>\n",
       "      <td>0.241344</td>\n",
       "      <td>1.037941</td>\n",
       "      <td>-2.053609</td>\n",
       "      <td>0.897298</td>\n",
       "      <td>-0.163447</td>\n",
       "      <td>-0.135790</td>\n",
       "      <td>...</td>\n",
       "      <td>1.013775</td>\n",
       "      <td>-0.492519</td>\n",
       "      <td>0</td>\n",
       "      <td>1.204630</td>\n",
       "      <td>0.484895</td>\n",
       "      <td>-3.228340</td>\n",
       "      <td>0.275244</td>\n",
       "      <td>0.292676</td>\n",
       "      <td>0.811725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610282</td>\n",
       "      <td>1.103147</td>\n",
       "      <td>-0.927065</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.558339</td>\n",
       "      <td>0.744327</td>\n",
       "      <td>1.681108</td>\n",
       "      <td>-0.015643</td>\n",
       "      <td>-1.240324</td>\n",
       "      <td>-0.599710</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>-0.222279</td>\n",
       "      <td>-0.102038</td>\n",
       "      <td>-0.109116</td>\n",
       "      <td>-0.712783</td>\n",
       "      <td>8</td>\n",
       "      <td>0.168960</td>\n",
       "      <td>0.506208</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>-1.227253</td>\n",
       "      <td>1.307303</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.367065</td>\n",
       "      <td>0.021009</td>\n",
       "      <td>0.021553</td>\n",
       "      <td>0.050553</td>\n",
       "      <td>0.025267</td>\n",
       "      <td>0.019179</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.013266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.645169</td>\n",
       "      <td>-0.227738</td>\n",
       "      <td>-0.978297</td>\n",
       "      <td>-1.213392</td>\n",
       "      <td>-0.806471</td>\n",
       "      <td>-0.377594</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096883</td>\n",
       "      <td>0.728835</td>\n",
       "      <td>0.745346</td>\n",
       "      <td>-0.407901</td>\n",
       "      <td>0.571526</td>\n",
       "      <td>-0.726239</td>\n",
       "      <td>0.391985</td>\n",
       "      <td>1.572188</td>\n",
       "      <td>0.468137</td>\n",
       "      <td>-0.610774</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>-1.025929</td>\n",
       "      <td>-0.445001</td>\n",
       "      <td>-0.012261</td>\n",
       "      <td>0.107585</td>\n",
       "      <td>1.632128</td>\n",
       "      <td>0.535899</td>\n",
       "      <td>-0.171477</td>\n",
       "      <td>-1.133167</td>\n",
       "      <td>0.385826</td>\n",
       "      <td>-1.621111</td>\n",
       "      <td>-0.467349</td>\n",
       "      <td>-0.921219</td>\n",
       "      <td>2</td>\n",
       "      <td>0.758828</td>\n",
       "      <td>-0.598302</td>\n",
       "      <td>-1.328814</td>\n",
       "      <td>0.227190</td>\n",
       "      <td>-0.769274</td>\n",
       "      <td>-0.834413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.969851</td>\n",
       "      <td>-0.165852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153001</td>\n",
       "      <td>-1.700664</td>\n",
       "      <td>1.601700</td>\n",
       "      <td>-0.838072</td>\n",
       "      <td>-0.454915</td>\n",
       "      <td>-0.053284</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>0.141476</td>\n",
       "      <td>-0.552134</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.052573</td>\n",
       "      <td>-0.007031</td>\n",
       "      <td>-0.267300</td>\n",
       "      <td>3.064286</td>\n",
       "      <td>-1.409659</td>\n",
       "      <td>0.944090</td>\n",
       "      <td>-0.950352</td>\n",
       "      <td>-0.139095</td>\n",
       "      <td>0.020943</td>\n",
       "      <td>-0.434769</td>\n",
       "      <td>-0.597094</td>\n",
       "      <td>8</td>\n",
       "      <td>0.095252</td>\n",
       "      <td>-0.601783</td>\n",
       "      <td>-0.535835</td>\n",
       "      <td>-0.687882</td>\n",
       "      <td>0.270950</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.565696</td>\n",
       "      <td>0.067791</td>\n",
       "      <td>0.070798</td>\n",
       "      <td>0.215963</td>\n",
       "      <td>0.065025</td>\n",
       "      <td>0.069205</td>\n",
       "      <td>0.086875</td>\n",
       "      <td>0.189735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.955243</td>\n",
       "      <td>-0.229058</td>\n",
       "      <td>1.158362</td>\n",
       "      <td>1.446567</td>\n",
       "      <td>1.133692</td>\n",
       "      <td>-0.917416</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.165934</td>\n",
       "      <td>1.577401</td>\n",
       "      <td>-0.464564</td>\n",
       "      <td>-0.190382</td>\n",
       "      <td>0.941792</td>\n",
       "      <td>0.690178</td>\n",
       "      <td>-0.429863</td>\n",
       "      <td>0.024189</td>\n",
       "      <td>0.100419</td>\n",
       "      <td>1.977306</td>\n",
       "      <td>-0.264587</td>\n",
       "      <td>-0.248304</td>\n",
       "      <td>0.879089</td>\n",
       "      <td>-0.284751</td>\n",
       "      <td>-0.023610</td>\n",
       "      <td>-0.237903</td>\n",
       "      <td>1.089011</td>\n",
       "      <td>-1.188013</td>\n",
       "      <td>0.090692</td>\n",
       "      <td>1.621569</td>\n",
       "      <td>1.978759</td>\n",
       "      <td>1.004087</td>\n",
       "      <td>-0.385069</td>\n",
       "      <td>1</td>\n",
       "      <td>0.622043</td>\n",
       "      <td>0.442276</td>\n",
       "      <td>-0.607518</td>\n",
       "      <td>-1.553079</td>\n",
       "      <td>-0.877991</td>\n",
       "      <td>0.479469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512077</td>\n",
       "      <td>0.280452</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105890</td>\n",
       "      <td>0.781871</td>\n",
       "      <td>1.143187</td>\n",
       "      <td>2.059018</td>\n",
       "      <td>-0.078121</td>\n",
       "      <td>0.361635</td>\n",
       "      <td>2</td>\n",
       "      <td>1.124844</td>\n",
       "      <td>-0.423303</td>\n",
       "      <td>1.030308</td>\n",
       "      <td>3</td>\n",
       "      <td>1.077594</td>\n",
       "      <td>-0.554907</td>\n",
       "      <td>-1.583742</td>\n",
       "      <td>-0.258054</td>\n",
       "      <td>2.287308</td>\n",
       "      <td>-0.510872</td>\n",
       "      <td>0.482168</td>\n",
       "      <td>-0.299237</td>\n",
       "      <td>1.335138</td>\n",
       "      <td>-0.983365</td>\n",
       "      <td>-1.504039</td>\n",
       "      <td>8</td>\n",
       "      <td>0.547632</td>\n",
       "      <td>0.296662</td>\n",
       "      <td>0.043079</td>\n",
       "      <td>0.980345</td>\n",
       "      <td>1.723855</td>\n",
       "      <td>2</td>\n",
       "      <td>0.929542</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.021344</td>\n",
       "      <td>0.070169</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.021638</td>\n",
       "      <td>0.028460</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>0.442111</td>\n",
       "      <td>0.195168</td>\n",
       "      <td>-0.386245</td>\n",
       "      <td>0.407316</td>\n",
       "      <td>-0.436025</td>\n",
       "      <td>1.134586</td>\n",
       "      <td>1</td>\n",
       "      <td>1.872517</td>\n",
       "      <td>-1.484988</td>\n",
       "      <td>-0.690340</td>\n",
       "      <td>1.783132</td>\n",
       "      <td>1.428712</td>\n",
       "      <td>-0.713936</td>\n",
       "      <td>0.702171</td>\n",
       "      <td>1.203967</td>\n",
       "      <td>1.378309</td>\n",
       "      <td>-0.325925</td>\n",
       "      <td>1.064929</td>\n",
       "      <td>0.248372</td>\n",
       "      <td>2.037269</td>\n",
       "      <td>1.180247</td>\n",
       "      <td>-0.500312</td>\n",
       "      <td>2.248632</td>\n",
       "      <td>0.384196</td>\n",
       "      <td>0.046286</td>\n",
       "      <td>-1.001776</td>\n",
       "      <td>-0.543578</td>\n",
       "      <td>-1.023683</td>\n",
       "      <td>1.339766</td>\n",
       "      <td>-1.531914</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344246</td>\n",
       "      <td>1.989566</td>\n",
       "      <td>-0.651738</td>\n",
       "      <td>-0.191820</td>\n",
       "      <td>-0.145032</td>\n",
       "      <td>0.460657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.663086</td>\n",
       "      <td>0.140905</td>\n",
       "      <td>1</td>\n",
       "      <td>0.496315</td>\n",
       "      <td>1.188229</td>\n",
       "      <td>0.519970</td>\n",
       "      <td>0.054354</td>\n",
       "      <td>1.777253</td>\n",
       "      <td>-0.884452</td>\n",
       "      <td>1</td>\n",
       "      <td>1.446233</td>\n",
       "      <td>-1.720222</td>\n",
       "      <td>0.978612</td>\n",
       "      <td>2</td>\n",
       "      <td>0.664399</td>\n",
       "      <td>-0.021149</td>\n",
       "      <td>0.374739</td>\n",
       "      <td>1.549963</td>\n",
       "      <td>1.701781</td>\n",
       "      <td>0.053870</td>\n",
       "      <td>1.049770</td>\n",
       "      <td>2.181977</td>\n",
       "      <td>1.437121</td>\n",
       "      <td>2.145431</td>\n",
       "      <td>0.872518</td>\n",
       "      <td>8</td>\n",
       "      <td>0.113541</td>\n",
       "      <td>0.521924</td>\n",
       "      <td>0.094967</td>\n",
       "      <td>1.438343</td>\n",
       "      <td>-0.146671</td>\n",
       "      <td>1</td>\n",
       "      <td>2.055875</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413189</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>413189</td>\n",
       "      <td>-1.154941</td>\n",
       "      <td>-0.829717</td>\n",
       "      <td>-1.268453</td>\n",
       "      <td>-0.356428</td>\n",
       "      <td>-0.822933</td>\n",
       "      <td>0.964195</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.484778</td>\n",
       "      <td>0.029571</td>\n",
       "      <td>0.774053</td>\n",
       "      <td>1.201873</td>\n",
       "      <td>0.094709</td>\n",
       "      <td>-0.198506</td>\n",
       "      <td>-1.110228</td>\n",
       "      <td>-0.234575</td>\n",
       "      <td>0.281889</td>\n",
       "      <td>0.299335</td>\n",
       "      <td>0.875548</td>\n",
       "      <td>0.216249</td>\n",
       "      <td>0.530497</td>\n",
       "      <td>0.316565</td>\n",
       "      <td>0.623539</td>\n",
       "      <td>0.253259</td>\n",
       "      <td>-0.969736</td>\n",
       "      <td>-0.678112</td>\n",
       "      <td>0.753615</td>\n",
       "      <td>-1.149565</td>\n",
       "      <td>-0.587701</td>\n",
       "      <td>0.257227</td>\n",
       "      <td>0.736858</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.327038</td>\n",
       "      <td>-0.867046</td>\n",
       "      <td>-1.405382</td>\n",
       "      <td>-1.158684</td>\n",
       "      <td>0.101827</td>\n",
       "      <td>-0.021304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112123</td>\n",
       "      <td>-0.127416</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.511600</td>\n",
       "      <td>-0.615228</td>\n",
       "      <td>-0.425402</td>\n",
       "      <td>-0.867366</td>\n",
       "      <td>1.252485</td>\n",
       "      <td>-1.447330</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.557916</td>\n",
       "      <td>-0.355228</td>\n",
       "      <td>0.671082</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.674425</td>\n",
       "      <td>-0.660521</td>\n",
       "      <td>0.971358</td>\n",
       "      <td>-0.806504</td>\n",
       "      <td>-2.315549</td>\n",
       "      <td>-0.526383</td>\n",
       "      <td>-1.600757</td>\n",
       "      <td>0.214823</td>\n",
       "      <td>0.388441</td>\n",
       "      <td>0.125703</td>\n",
       "      <td>-0.108432</td>\n",
       "      <td>8</td>\n",
       "      <td>0.173829</td>\n",
       "      <td>-0.666265</td>\n",
       "      <td>-0.153305</td>\n",
       "      <td>0.352068</td>\n",
       "      <td>-0.991257</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017719</td>\n",
       "      <td>0.027886</td>\n",
       "      <td>0.025632</td>\n",
       "      <td>0.107231</td>\n",
       "      <td>0.024223</td>\n",
       "      <td>0.028619</td>\n",
       "      <td>0.035453</td>\n",
       "      <td>0.026665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413190</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>413190</td>\n",
       "      <td>-0.557809</td>\n",
       "      <td>-0.370656</td>\n",
       "      <td>-1.117603</td>\n",
       "      <td>0.434343</td>\n",
       "      <td>-0.801104</td>\n",
       "      <td>-0.515650</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.241646</td>\n",
       "      <td>1.029897</td>\n",
       "      <td>1.892813</td>\n",
       "      <td>-0.495689</td>\n",
       "      <td>-0.707535</td>\n",
       "      <td>-0.143122</td>\n",
       "      <td>-0.399202</td>\n",
       "      <td>1.437433</td>\n",
       "      <td>-0.421678</td>\n",
       "      <td>-0.421050</td>\n",
       "      <td>-1.810876</td>\n",
       "      <td>-0.252017</td>\n",
       "      <td>-1.753064</td>\n",
       "      <td>-0.296607</td>\n",
       "      <td>1.127620</td>\n",
       "      <td>-0.412457</td>\n",
       "      <td>-1.674431</td>\n",
       "      <td>-2.120332</td>\n",
       "      <td>-0.541750</td>\n",
       "      <td>0.449971</td>\n",
       "      <td>0.134161</td>\n",
       "      <td>-0.938971</td>\n",
       "      <td>1.402169</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.260702</td>\n",
       "      <td>0.154833</td>\n",
       "      <td>0.181406</td>\n",
       "      <td>-0.527623</td>\n",
       "      <td>-0.447073</td>\n",
       "      <td>0.873399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.920233</td>\n",
       "      <td>-1.761184</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.555512</td>\n",
       "      <td>1.130002</td>\n",
       "      <td>-0.077044</td>\n",
       "      <td>-0.564217</td>\n",
       "      <td>-0.653959</td>\n",
       "      <td>2.095708</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349993</td>\n",
       "      <td>1.529211</td>\n",
       "      <td>0.035925</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.860280</td>\n",
       "      <td>-0.533620</td>\n",
       "      <td>0.433028</td>\n",
       "      <td>-1.186149</td>\n",
       "      <td>-0.276115</td>\n",
       "      <td>-0.802790</td>\n",
       "      <td>-2.231033</td>\n",
       "      <td>-1.427847</td>\n",
       "      <td>-0.518919</td>\n",
       "      <td>-0.708357</td>\n",
       "      <td>1.255197</td>\n",
       "      <td>8</td>\n",
       "      <td>0.593378</td>\n",
       "      <td>-1.332561</td>\n",
       "      <td>1.600622</td>\n",
       "      <td>-0.952750</td>\n",
       "      <td>-0.881013</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.057485</td>\n",
       "      <td>0.042629</td>\n",
       "      <td>0.044959</td>\n",
       "      <td>0.133694</td>\n",
       "      <td>0.042827</td>\n",
       "      <td>0.036438</td>\n",
       "      <td>0.048080</td>\n",
       "      <td>0.044908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413191</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>413191</td>\n",
       "      <td>-0.579914</td>\n",
       "      <td>-1.080645</td>\n",
       "      <td>-0.855200</td>\n",
       "      <td>0.820872</td>\n",
       "      <td>-1.433521</td>\n",
       "      <td>-0.497681</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.444906</td>\n",
       "      <td>-1.897505</td>\n",
       "      <td>1.095496</td>\n",
       "      <td>-2.173016</td>\n",
       "      <td>-0.889065</td>\n",
       "      <td>0.038481</td>\n",
       "      <td>-1.750720</td>\n",
       "      <td>1.560384</td>\n",
       "      <td>-1.174797</td>\n",
       "      <td>-0.898809</td>\n",
       "      <td>-0.975876</td>\n",
       "      <td>-1.009634</td>\n",
       "      <td>0.088143</td>\n",
       "      <td>-0.911838</td>\n",
       "      <td>-2.756771</td>\n",
       "      <td>-1.254225</td>\n",
       "      <td>0.017606</td>\n",
       "      <td>-0.476039</td>\n",
       "      <td>-0.160221</td>\n",
       "      <td>0.565799</td>\n",
       "      <td>-0.767802</td>\n",
       "      <td>-2.505023</td>\n",
       "      <td>0.335085</td>\n",
       "      <td>2</td>\n",
       "      <td>0.374183</td>\n",
       "      <td>0.036883</td>\n",
       "      <td>-0.113893</td>\n",
       "      <td>-1.035395</td>\n",
       "      <td>0.138019</td>\n",
       "      <td>-2.071544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421071</td>\n",
       "      <td>0.149998</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.672017</td>\n",
       "      <td>0.165187</td>\n",
       "      <td>0.476620</td>\n",
       "      <td>-0.050669</td>\n",
       "      <td>-1.714348</td>\n",
       "      <td>-0.252365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071071</td>\n",
       "      <td>-0.636588</td>\n",
       "      <td>-1.427133</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.879168</td>\n",
       "      <td>-0.720226</td>\n",
       "      <td>-1.092033</td>\n",
       "      <td>-1.191655</td>\n",
       "      <td>0.731434</td>\n",
       "      <td>1.042668</td>\n",
       "      <td>-1.906482</td>\n",
       "      <td>-1.037265</td>\n",
       "      <td>1.796735</td>\n",
       "      <td>-0.259775</td>\n",
       "      <td>0.814502</td>\n",
       "      <td>8</td>\n",
       "      <td>0.494727</td>\n",
       "      <td>0.229257</td>\n",
       "      <td>1.521202</td>\n",
       "      <td>-0.779365</td>\n",
       "      <td>-1.379297</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.051693</td>\n",
       "      <td>0.234578</td>\n",
       "      <td>0.229939</td>\n",
       "      <td>0.525223</td>\n",
       "      <td>0.208905</td>\n",
       "      <td>0.234172</td>\n",
       "      <td>0.269151</td>\n",
       "      <td>0.244836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413192</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>413192</td>\n",
       "      <td>-1.298108</td>\n",
       "      <td>0.703867</td>\n",
       "      <td>-1.172353</td>\n",
       "      <td>0.319265</td>\n",
       "      <td>-0.308155</td>\n",
       "      <td>0.765472</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.342075</td>\n",
       "      <td>0.217699</td>\n",
       "      <td>-0.780007</td>\n",
       "      <td>-0.147333</td>\n",
       "      <td>1.165468</td>\n",
       "      <td>1.155035</td>\n",
       "      <td>-0.185783</td>\n",
       "      <td>-0.308199</td>\n",
       "      <td>0.499064</td>\n",
       "      <td>-0.153823</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>0.445216</td>\n",
       "      <td>-0.685717</td>\n",
       "      <td>-0.279427</td>\n",
       "      <td>-0.147268</td>\n",
       "      <td>-0.835158</td>\n",
       "      <td>0.120869</td>\n",
       "      <td>-0.905613</td>\n",
       "      <td>1.904665</td>\n",
       "      <td>-0.133373</td>\n",
       "      <td>0.321738</td>\n",
       "      <td>-0.284887</td>\n",
       "      <td>-1.298973</td>\n",
       "      <td>2</td>\n",
       "      <td>1.877799</td>\n",
       "      <td>-1.874387</td>\n",
       "      <td>1.422751</td>\n",
       "      <td>-0.928803</td>\n",
       "      <td>0.804263</td>\n",
       "      <td>0.717711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207983</td>\n",
       "      <td>-0.461711</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.283647</td>\n",
       "      <td>0.254410</td>\n",
       "      <td>-1.051102</td>\n",
       "      <td>-1.533752</td>\n",
       "      <td>-0.250063</td>\n",
       "      <td>-1.746837</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.152660</td>\n",
       "      <td>0.043048</td>\n",
       "      <td>-0.951610</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.695175</td>\n",
       "      <td>-1.320789</td>\n",
       "      <td>0.198907</td>\n",
       "      <td>1.454876</td>\n",
       "      <td>-1.634491</td>\n",
       "      <td>-0.356433</td>\n",
       "      <td>0.228286</td>\n",
       "      <td>-0.980427</td>\n",
       "      <td>-0.020701</td>\n",
       "      <td>-1.730386</td>\n",
       "      <td>-0.034418</td>\n",
       "      <td>8</td>\n",
       "      <td>0.144395</td>\n",
       "      <td>0.628633</td>\n",
       "      <td>1.031002</td>\n",
       "      <td>0.618204</td>\n",
       "      <td>0.370275</td>\n",
       "      <td>1</td>\n",
       "      <td>1.183939</td>\n",
       "      <td>0.043712</td>\n",
       "      <td>0.039810</td>\n",
       "      <td>0.136429</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>0.031114</td>\n",
       "      <td>0.019104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413193</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>413193</td>\n",
       "      <td>-1.635370</td>\n",
       "      <td>0.542366</td>\n",
       "      <td>-0.780242</td>\n",
       "      <td>-1.233677</td>\n",
       "      <td>0.033867</td>\n",
       "      <td>-1.093566</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.679575</td>\n",
       "      <td>-0.909570</td>\n",
       "      <td>0.306132</td>\n",
       "      <td>-0.082532</td>\n",
       "      <td>-1.832096</td>\n",
       "      <td>-0.544132</td>\n",
       "      <td>-0.465898</td>\n",
       "      <td>1.382257</td>\n",
       "      <td>-0.470554</td>\n",
       "      <td>0.475950</td>\n",
       "      <td>-0.712038</td>\n",
       "      <td>0.064221</td>\n",
       "      <td>-1.905510</td>\n",
       "      <td>-1.228778</td>\n",
       "      <td>0.292467</td>\n",
       "      <td>0.782724</td>\n",
       "      <td>-0.974967</td>\n",
       "      <td>-0.486079</td>\n",
       "      <td>0.615874</td>\n",
       "      <td>0.397755</td>\n",
       "      <td>-0.027285</td>\n",
       "      <td>0.155776</td>\n",
       "      <td>-1.663052</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.561884</td>\n",
       "      <td>-0.495880</td>\n",
       "      <td>-0.759751</td>\n",
       "      <td>-0.389649</td>\n",
       "      <td>0.115259</td>\n",
       "      <td>-0.069546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139308</td>\n",
       "      <td>-0.542668</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736080</td>\n",
       "      <td>0.435848</td>\n",
       "      <td>-0.229890</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>-0.063450</td>\n",
       "      <td>-0.489551</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159795</td>\n",
       "      <td>0.047676</td>\n",
       "      <td>0.027554</td>\n",
       "      <td>2</td>\n",
       "      <td>1.021729</td>\n",
       "      <td>-1.540519</td>\n",
       "      <td>0.574824</td>\n",
       "      <td>0.627503</td>\n",
       "      <td>-0.243138</td>\n",
       "      <td>0.187813</td>\n",
       "      <td>-1.555089</td>\n",
       "      <td>0.466872</td>\n",
       "      <td>-0.671550</td>\n",
       "      <td>-1.806633</td>\n",
       "      <td>-0.601470</td>\n",
       "      <td>8</td>\n",
       "      <td>0.292478</td>\n",
       "      <td>-0.506839</td>\n",
       "      <td>1.519194</td>\n",
       "      <td>-0.177712</td>\n",
       "      <td>-1.081721</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.082175</td>\n",
       "      <td>0.027550</td>\n",
       "      <td>0.019051</td>\n",
       "      <td>0.114805</td>\n",
       "      <td>0.023348</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.020523</td>\n",
       "      <td>0.021346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413194 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target  ... lamann_fttransformer_8050_full_dataset\n",
       "0            0  ...                               0.023806\n",
       "1            0  ...                               0.013266\n",
       "2            1  ...                               0.189735\n",
       "3            0  ...                               0.033119\n",
       "4            0  ...                               0.003179\n",
       "...        ...  ...                                    ...\n",
       "413189       0  ...                               0.026665\n",
       "413190       0  ...                               0.044908\n",
       "413191       0  ...                               0.244836\n",
       "413192       0  ...                               0.019104\n",
       "413193       0  ...                               0.021346\n",
       "\n",
       "[413194 rows x 196 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48abfc9d-95b1-4eda-9665-251676ed3d8f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b32e8180-6799-428d-93d8-50f8c19a074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = RocAuc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe02bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-10 16:44:46,576] - [   START    ] - Fitting TabularLamaUtilized\n",
      "[16:44:46] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[16:44:46] - time: 7200.00 seconds\n",
      "[16:44:46] - CPU: 16 cores\n",
      "[16:44:46] - memory: 16 GB\n",
      "\n",
      "[16:44:46] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[16:44:46] ==================================================\n",
      "[16:44:46] Start 0 automl preset configuration:\n",
      "[16:44:46] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[16:44:46] Stdout logging level is INFO.\n",
      "[16:44:46] Task: binary\n",
      "\n",
      "[16:44:46] Start automl preset with listed constraints:\n",
      "[16:44:46] - time: 7200.00 seconds\n",
      "[16:44:46] - CPU: 16 cores\n",
      "[16:44:46] - memory: 16 GB\n",
      "\n",
      "[16:44:46] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[16:45:00] Layer \u001b[1m1\u001b[0m train process start. Time left 7186.26 secs\n",
      "[16:45:14] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[16:45:39] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8081600874331184\u001b[0m\n",
      "[16:45:39] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[16:45:39] Time left 7146.91 secs\n",
      "\n",
      "[16:45:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[16:46:14] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7988605370132498\u001b[0m\n",
      "[16:46:14] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:46:14] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:46:14] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[16:51:16] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[16:51:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[16:51:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8135837532729969\u001b[0m\n",
      "[16:51:35] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:51:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[16:51:49] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8130710695561807\u001b[0m\n",
      "[16:51:49] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:51:49] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:54:13] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[16:54:13] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[16:54:32] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8134795343600518\u001b[0m\n",
      "[16:54:32] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:54:32] Time left 6614.42 secs\n",
      "\n",
      "[16:54:32] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[16:54:32] Blending: optimization starts with equal weights and score \u001b[1m0.8135393476718319\u001b[0m\n",
      "[16:54:37] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8143097026517786\u001b[0m, weights = \u001b[1m[0.         0.05874373 0.5219629  0.20308037 0.21621306]\u001b[0m\n",
      "[16:54:42] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8143235643944617\u001b[0m, weights = \u001b[1m[0.         0.08716116 0.49963686 0.20623711 0.20696494]\u001b[0m\n",
      "[16:54:46] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.814323682799053\u001b[0m, weights = \u001b[1m[0.         0.08739533 0.49829254 0.20679119 0.20752098]\u001b[0m\n",
      "[16:54:51] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.814323682799053\u001b[0m, weights = \u001b[1m[0.         0.0873954  0.49829215 0.20679134 0.20752113]\u001b[0m\n",
      "[16:54:51] Blending: no score update. Terminated\n",
      "\n",
      "[16:54:51] \u001b[1mAutoml preset training completed in 605.01 seconds\u001b[0m\n",
      "\n",
      "[16:54:51] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.08740 * (4 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.49829 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.20679 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.20752 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[16:54:51] ==================================================\n",
      "[16:54:51] Start 1 automl preset configuration:\n",
      "[16:54:51] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n",
      "[16:54:51] Stdout logging level is INFO.\n",
      "[16:54:51] Task: binary\n",
      "\n",
      "[16:54:51] Start automl preset with listed constraints:\n",
      "[16:54:51] - time: 6594.96 seconds\n",
      "[16:54:51] - CPU: 16 cores\n",
      "[16:54:51] - memory: 16 GB\n",
      "\n",
      "[16:54:51] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[16:55:04] Layer \u001b[1m1\u001b[0m train process start. Time left 6581.86 secs\n",
      "[16:55:18] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[16:55:38] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8083336178074355\u001b[0m\n",
      "[16:55:38] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[16:55:38] Time left 6548.22 secs\n",
      "\n",
      "[16:55:46] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:55:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[16:56:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8076171343301696\u001b[0m\n",
      "[16:56:22] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:56:22] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:01:26] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[17:01:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:01:47] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8126756613437726\u001b[0m\n",
      "[17:01:47] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:01:47] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[17:01:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8127703795208137\u001b[0m\n",
      "[17:01:58] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:01:58] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:04:09] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[17:04:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:04:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8136103809703445\u001b[0m\n",
      "[17:04:28] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:04:28] Time left 6018.54 secs\n",
      "\n",
      "[17:04:28] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:04:28] Blending: optimization starts with equal weights and score \u001b[1m0.8136247658754295\u001b[0m\n",
      "[17:04:33] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8139466940574553\u001b[0m, weights = \u001b[1m[0.         0.11502776 0.22717363 0.14315245 0.51464623]\u001b[0m\n",
      "[17:04:37] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8139522462225042\u001b[0m, weights = \u001b[1m[0.         0.12562291 0.22938664 0.09043991 0.5545505 ]\u001b[0m\n",
      "[17:04:42] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8139523619599613\u001b[0m, weights = \u001b[1m[0.         0.12163923 0.23285125 0.08757193 0.55793756]\u001b[0m\n",
      "[17:04:47] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8139524393068511\u001b[0m, weights = \u001b[1m[0.         0.12103614 0.23340084 0.08764514 0.5579179 ]\u001b[0m\n",
      "[17:04:51] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8139524393068511\u001b[0m, weights = \u001b[1m[0.         0.12103614 0.23340084 0.08764514 0.5579179 ]\u001b[0m\n",
      "[17:04:51] Blending: no score update. Terminated\n",
      "\n",
      "[17:04:51] \u001b[1mAutoml preset training completed in 600.15 seconds\u001b[0m\n",
      "\n",
      "[17:04:51] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.12104 * (4 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.23340 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.08765 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.55792 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[17:04:51] ==================================================\n",
      "[17:04:51] Start 2 automl preset configuration:\n",
      "[17:04:51] \u001b[1mconf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'nn_params': {'random_state': 44}, 'general_params': {'return_all_predictions': False}}\n",
      "[17:04:51] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:04:51] Task: binary\n",
      "\n",
      "[17:04:51] Start automl preset with listed constraints:\n",
      "[17:04:51] - time: 5994.79 seconds\n",
      "[17:04:51] - CPU: 16 cores\n",
      "[17:04:51] - memory: 16 GB\n",
      "\n",
      "[17:04:51] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[17:04:52] Layer \u001b[1m1\u001b[0m train process start. Time left 5993.82 secs\n",
      "[17:05:06] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[17:05:28] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8083145050433943\u001b[0m\n",
      "[17:05:28] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[17:05:28] Time left 5958.07 secs\n",
      "\n",
      "[17:05:36] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:05:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[17:06:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8001843686375795\u001b[0m\n",
      "[17:06:11] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:06:11] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:11:17] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[17:11:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:11:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8126272367755757\u001b[0m\n",
      "[17:11:35] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:11:35] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[17:11:49] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8131198777067595\u001b[0m\n",
      "[17:11:49] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:11:49] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:14:04] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[17:14:04] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:14:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8135333885667717\u001b[0m\n",
      "[17:14:19] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:14:19] Time left 5427.37 secs\n",
      "\n",
      "[17:14:19] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:14:19] Blending: optimization starts with equal weights and score \u001b[1m0.8130425931307654\u001b[0m\n",
      "[17:14:24] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8137752013736181\u001b[0m, weights = \u001b[1m[0.07483385 0.         0.19853105 0.2361194  0.49051568]\u001b[0m\n",
      "[17:14:29] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8138578261987306\u001b[0m, weights = \u001b[1m[0.         0.         0.27095655 0.27198413 0.4570593 ]\u001b[0m\n",
      "[17:14:33] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8138579547869248\u001b[0m, weights = \u001b[1m[0.         0.         0.27315426 0.26516637 0.4616794 ]\u001b[0m\n",
      "[17:14:38] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8138579553526805\u001b[0m, weights = \u001b[1m[0.         0.         0.27315423 0.26516637 0.46167937]\u001b[0m\n",
      "[17:14:43] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8138579553526805\u001b[0m, weights = \u001b[1m[0.         0.         0.27315423 0.26516637 0.46167937]\u001b[0m\n",
      "[17:14:43] Blending: no score update. Terminated\n",
      "\n",
      "[17:14:43] \u001b[1mAutoml preset training completed in 591.47 seconds\u001b[0m\n",
      "\n",
      "[17:14:43] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.27315 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.26517 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.46168 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[17:14:43] ==================================================\n",
      "[17:14:43] Start 3 automl preset configuration:\n",
      "[17:14:43] \u001b[1mconf_3_sel_type_1_no_inter_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'nn_params': {'random_state': 45}, 'general_params': {'return_all_predictions': False}}\n",
      "[17:14:43] Stdout logging level is INFO.\n",
      "[17:14:43] Task: binary\n",
      "\n",
      "[17:14:43] Start automl preset with listed constraints:\n",
      "[17:14:43] - time: 5403.30 seconds\n",
      "[17:14:43] - CPU: 16 cores\n",
      "[17:14:43] - memory: 16 GB\n",
      "\n",
      "[17:14:43] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[17:14:56] Layer \u001b[1m1\u001b[0m train process start. Time left 5390.00 secs\n",
      "[17:15:10] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[17:15:35] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8083137408690532\u001b[0m\n",
      "[17:15:35] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[17:15:35] Time left 5350.95 secs\n",
      "\n",
      "[17:15:43] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:15:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[17:16:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7973882179493402\u001b[0m\n",
      "[17:16:07] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:16:07] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:21:08] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[17:21:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:21:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8116944152594638\u001b[0m\n",
      "[17:21:26] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:21:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[17:21:38] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8128732946900996\u001b[0m\n",
      "[17:21:38] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:21:38] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:23:44] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[17:23:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:24:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8135762907125065\u001b[0m\n",
      "[17:24:00] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:24:00] Time left 4846.58 secs\n",
      "\n",
      "[17:24:00] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:24:00] Blending: optimization starts with equal weights and score \u001b[1m0.8132269239435335\u001b[0m\n",
      "[17:24:05] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8138086590357324\u001b[0m, weights = \u001b[1m[0.08345528 0.05002951 0.18102446 0.16823521 0.51725554]\u001b[0m\n",
      "[17:24:10] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8139047147401317\u001b[0m, weights = \u001b[1m[0.         0.07482529 0.23719947 0.14808463 0.53989065]\u001b[0m\n",
      "[17:24:14] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8139050984841583\u001b[0m, weights = \u001b[1m[0.         0.07693438 0.23645598 0.15225866 0.534351  ]\u001b[0m\n",
      "[17:24:19] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8139053805537988\u001b[0m, weights = \u001b[1m[0.         0.07872529 0.23424292 0.14024197 0.5467898 ]\u001b[0m\n",
      "[17:24:24] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8139054096498075\u001b[0m, weights = \u001b[1m[0.         0.07889531 0.23255627 0.14057769 0.5479707 ]\u001b[0m\n",
      "[17:24:24] \u001b[1mAutoml preset training completed in 581.16 seconds\u001b[0m\n",
      "\n",
      "[17:24:24] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.07890 * (4 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.23256 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.14058 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.54797 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[17:24:24] ==================================================\n",
      "[17:24:24] Start 4 automl preset configuration:\n",
      "[17:24:24] \u001b[1mconf_4_sel_type_0_no_int.yml\u001b[0m, random state: {'reader_params': {'random_state': 46}, 'nn_params': {'random_state': 46}, 'general_params': {'return_all_predictions': False}}\n",
      "[17:24:24] Stdout logging level is INFO.\n",
      "[17:24:24] Task: binary\n",
      "\n",
      "[17:24:24] Start automl preset with listed constraints:\n",
      "[17:24:24] - time: 4822.12 seconds\n",
      "[17:24:24] - CPU: 16 cores\n",
      "[17:24:24] - memory: 16 GB\n",
      "\n",
      "[17:24:24] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[17:24:37] Layer \u001b[1m1\u001b[0m train process start. Time left 4808.83 secs\n",
      "[17:24:40] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[17:25:07] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8081847431484723\u001b[0m\n",
      "[17:25:07] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[17:25:07] Time left 4779.65 secs\n",
      "\n",
      "[17:25:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8024688673049791\u001b[0m\n",
      "[17:25:30] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:25:30] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:30:32] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[17:30:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:30:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8141230085156994\u001b[0m\n",
      "[17:30:51] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:30:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[17:31:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8129466418487088\u001b[0m\n",
      "[17:31:03] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:31:03] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:33:11] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[17:33:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:33:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8132929562038964\u001b[0m\n",
      "[17:33:29] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:33:29] Time left 4276.87 secs\n",
      "\n",
      "[17:33:29] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:33:30] Blending: optimization starts with equal weights and score \u001b[1m0.8134329032375058\u001b[0m\n",
      "[17:33:34] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8142863858377609\u001b[0m, weights = \u001b[1m[0.         0.         0.69668764 0.17008737 0.13322504]\u001b[0m\n",
      "[17:33:39] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8142866234551657\u001b[0m, weights = \u001b[1m[0.         0.         0.694277   0.17696142 0.1287616 ]\u001b[0m\n",
      "[17:33:44] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.814286681243072\u001b[0m, weights = \u001b[1m[0.         0.         0.692561   0.1789957  0.12844333]\u001b[0m\n",
      "[17:33:48] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.814286681243072\u001b[0m, weights = \u001b[1m[0.         0.         0.692561   0.1789957  0.12844333]\u001b[0m\n",
      "[17:33:48] Blending: no score update. Terminated\n",
      "\n",
      "[17:33:48] \u001b[1mAutoml preset training completed in 564.17 seconds\u001b[0m\n",
      "\n",
      "[17:33:48] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.69256 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.17900 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.12844 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[17:33:48] ==================================================\n",
      "[17:33:48] Start 5 automl preset configuration:\n",
      "[17:33:48] \u001b[1mconf_5_sel_type_1_tuning_full.yml\u001b[0m, random state: {'reader_params': {'random_state': 47}, 'nn_params': {'random_state': 47}, 'general_params': {'return_all_predictions': False}}\n",
      "[17:33:48] Stdout logging level is INFO.\n",
      "[17:33:48] Task: binary\n",
      "\n",
      "[17:33:48] Start automl preset with listed constraints:\n",
      "[17:33:48] - time: 4257.93 seconds\n",
      "[17:33:48] - CPU: 16 cores\n",
      "[17:33:48] - memory: 16 GB\n",
      "\n",
      "[17:33:48] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[17:34:02] Layer \u001b[1m1\u001b[0m train process start. Time left 4244.70 secs\n",
      "[17:34:16] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[17:34:42] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.808272156045115\u001b[0m\n",
      "[17:34:42] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[17:34:42] Time left 4204.60 secs\n",
      "\n",
      "[17:34:49] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:35:02] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[17:35:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8019799589876078\u001b[0m\n",
      "[17:35:26] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:35:26] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:35:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:35:49] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.79778559555743\u001b[0m\n",
      "[17:35:49] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:35:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:36:13] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8052624334594183\u001b[0m\n",
      "[17:36:13] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:36:13] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:36:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8037629594946469\u001b[0m\n",
      "[17:36:31] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:36:31] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:36:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8000898827436747\u001b[0m\n",
      "[17:36:50] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:36:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:37:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8065390553547389\u001b[0m\n",
      "[17:37:11] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:37:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:37:33] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8064917316663622\u001b[0m\n",
      "[17:37:33] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:37:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:37:54] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8106918178773511\u001b[0m\n",
      "[17:37:54] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:37:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:38:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8044308991100803\u001b[0m\n",
      "[17:38:17] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:38:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:38:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8052943122589463\u001b[0m\n",
      "[17:38:40] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:38:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:39:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7973268138941036\u001b[0m\n",
      "[17:39:02] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:39:02] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:39:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.814237466879882\u001b[0m\n",
      "[17:39:22] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:39:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:39:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8113528272276099\u001b[0m\n",
      "[17:39:42] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:39:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:40:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8009658151777088\u001b[0m\n",
      "[17:40:04] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:40:04] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:40:24] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8134314793111661\u001b[0m\n",
      "[17:40:24] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:40:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:40:44] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8037068210087728\u001b[0m\n",
      "[17:40:44] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:40:44] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[17:40:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:41:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.814237466879882\u001b[0m\n",
      "[17:41:04] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:04] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[17:41:14] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8127052237777145\u001b[0m\n",
      "[17:41:14] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:41:14] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:41:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:41:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8132172374781069\u001b[0m\n",
      "[17:41:26] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:41:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:41:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8128069262900133\u001b[0m\n",
      "[17:41:37] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:41:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:41:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8133547929006189\u001b[0m\n",
      "[17:41:50] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:41:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:42:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8123382544083769\u001b[0m\n",
      "[17:42:00] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:42:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:42:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8108057754668941\u001b[0m\n",
      "[17:42:11] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:42:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:42:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8132579516848053\u001b[0m\n",
      "[17:42:26] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:42:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:42:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8129474682561797\u001b[0m\n",
      "[17:42:37] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:42:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:42:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8131818784726426\u001b[0m\n",
      "[17:42:50] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:42:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:43:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8131949204352789\u001b[0m\n",
      "[17:43:02] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:43:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:43:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8128442202608823\u001b[0m\n",
      "[17:43:17] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:43:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:43:32] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8133992314772605\u001b[0m\n",
      "[17:43:32] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:43:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:43:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8135013778653373\u001b[0m\n",
      "[17:43:48] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:43:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:43:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8129871277325607\u001b[0m\n",
      "[17:43:59] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:44:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:44:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8135125903356009\u001b[0m\n",
      "[17:44:12] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:44:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:44:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8133803131715442\u001b[0m\n",
      "[17:44:25] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:44:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:44:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8129894470885698\u001b[0m\n",
      "[17:44:36] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:44:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:44:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8135327912095475\u001b[0m\n",
      "[17:44:50] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:44:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:45:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8128711992925357\u001b[0m\n",
      "[17:45:00] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:45:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:45:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8131602382353071\u001b[0m\n",
      "[17:45:15] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:45:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:45:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8130866778676117\u001b[0m\n",
      "[17:45:27] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:45:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:45:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8132032134443528\u001b[0m\n",
      "[17:45:40] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:45:41] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:45:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8134938209044628\u001b[0m\n",
      "[17:45:53] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:45:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:46:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8133938182456533\u001b[0m\n",
      "[17:46:03] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:46:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:46:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8131568070076521\u001b[0m\n",
      "[17:46:16] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:46:16] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[17:46:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:46:32] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8130581605461398\u001b[0m\n",
      "[17:46:32] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:46:32] Time left 3494.02 secs\n",
      "\n",
      "[17:46:32] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:46:32] Blending: optimization starts with equal weights and score \u001b[1m0.8134622129402829\u001b[0m\n",
      "[17:46:37] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8144032179513244\u001b[0m, weights = \u001b[1m[0.         0.         0.7537941  0.12310297 0.12310297]\u001b[0m\n",
      "[17:46:42] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8144032179513244\u001b[0m, weights = \u001b[1m[0.         0.         0.7537941  0.12310297 0.12310297]\u001b[0m\n",
      "[17:46:42] Blending: no score update. Terminated\n",
      "\n",
      "[17:46:42] \u001b[1mAutoml preset training completed in 773.42 seconds\u001b[0m\n",
      "\n",
      "[17:46:42] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.75379 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.12310 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.12310 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[17:46:42] ==================================================\n",
      "[17:46:42] Start 6 automl preset configuration:\n",
      "[17:46:42] \u001b[1mconf_6_sel_type_1_tuning_full_no_int_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 48}, 'nn_params': {'random_state': 48}, 'general_params': {'return_all_predictions': False}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:46:42] Stdout logging level is INFO.\n",
      "[17:46:42] Task: binary\n",
      "\n",
      "[17:46:42] Start automl preset with listed constraints:\n",
      "[17:46:42] - time: 3484.49 seconds\n",
      "[17:46:42] - CPU: 16 cores\n",
      "[17:46:42] - memory: 16 GB\n",
      "\n",
      "[17:46:42] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[17:46:55] Layer \u001b[1m1\u001b[0m train process start. Time left 3471.52 secs\n",
      "[17:47:09] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[17:47:30] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.808231610514445\u001b[0m\n",
      "[17:47:30] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[17:47:30] Time left 3435.96 secs\n",
      "\n",
      "[17:47:38] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:47:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[17:48:01] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8043815766067242\u001b[0m\n",
      "[17:48:01] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:48:01] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:53:08] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[17:53:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[17:53:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8139516849120019\u001b[0m\n",
      "[17:53:28] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:53:28] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[17:53:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8130770698805865\u001b[0m\n",
      "[17:53:41] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:53:41] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:55:49] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[17:55:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[17:56:05] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8134100707103894\u001b[0m\n",
      "[17:56:05] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:56:05] Time left 2921.50 secs\n",
      "\n",
      "[17:56:05] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:56:05] Blending: optimization starts with equal weights and score \u001b[1m0.813633111580608\u001b[0m\n",
      "[17:56:10] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8143162016494458\u001b[0m, weights = \u001b[1m[0.         0.         0.6348953  0.2251604  0.13994423]\u001b[0m\n",
      "[17:56:15] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.814316665569141\u001b[0m, weights = \u001b[1m[0.         0.         0.6298691  0.24361283 0.12651807]\u001b[0m\n",
      "[17:56:19] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.814316665569141\u001b[0m, weights = \u001b[1m[0.         0.         0.6298691  0.24361283 0.12651807]\u001b[0m\n",
      "[17:56:19] Blending: no score update. Terminated\n",
      "\n",
      "[17:56:19] \u001b[1mAutoml preset training completed in 577.56 seconds\u001b[0m\n",
      "\n",
      "[17:56:19] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.62987 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.24361 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.12652 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[17:56:19] ==================================================\n",
      "[17:56:19] ==================================================\n",
      "[17:56:19] Start 0 automl preset configuration:\n",
      "[17:56:19] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 49}, 'nn_params': {'random_state': 49}, 'general_params': {'return_all_predictions': False}}\n",
      "[17:56:19] Stdout logging level is INFO.\n",
      "[17:56:19] Task: binary\n",
      "\n",
      "[17:56:19] Start automl preset with listed constraints:\n",
      "[17:56:19] - time: 2906.90 seconds\n",
      "[17:56:19] - CPU: 16 cores\n",
      "[17:56:19] - memory: 16 GB\n",
      "\n",
      "[17:56:19] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[17:56:32] Layer \u001b[1m1\u001b[0m train process start. Time left 2893.94 secs\n",
      "[17:56:46] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[17:57:10] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8082702892936864\u001b[0m\n",
      "[17:57:10] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[17:57:10] Time left 2856.41 secs\n",
      "\n",
      "[17:57:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[17:57:46] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8048570883942638\u001b[0m\n",
      "[17:57:46] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:57:46] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:02:48] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[18:02:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[18:03:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8124224193822196\u001b[0m\n",
      "[18:03:08] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:03:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[18:03:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8129398714499376\u001b[0m\n",
      "[18:03:21] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:03:21] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:05:34] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[18:05:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[18:05:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8135032831689775\u001b[0m\n",
      "[18:05:50] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:05:50] Time left 2335.86 secs\n",
      "\n",
      "[18:05:50] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[18:05:51] Blending: optimization starts with equal weights and score \u001b[1m0.8133399526429967\u001b[0m\n",
      "[18:05:55] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8137401362378421\u001b[0m, weights = \u001b[1m[0.08479131 0.05035355 0.22211498 0.26077417 0.38196602]\u001b[0m\n",
      "[18:06:00] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8138056305453321\u001b[0m, weights = \u001b[1m[0.         0.05023485 0.22454855 0.22372162 0.50149494]\u001b[0m\n",
      "[18:06:05] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8138056303836875\u001b[0m, weights = \u001b[1m[0.         0.05023486 0.22454856 0.22372164 0.50149494]\u001b[0m\n",
      "[18:06:05] Blending: no score update. Terminated\n",
      "\n",
      "[18:06:05] \u001b[1mAutoml preset training completed in 585.76 seconds\u001b[0m\n",
      "\n",
      "[18:06:05] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.05023 * (4 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.22455 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.22372 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.50149 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[18:06:05] ==================================================\n",
      "[18:06:05] Start 1 automl preset configuration:\n",
      "[18:06:05] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 50}, 'nn_params': {'random_state': 50}, 'general_params': {'return_all_predictions': False}}\n",
      "[18:06:05] Stdout logging level is INFO.\n",
      "[18:06:05] Task: binary\n",
      "\n",
      "[18:06:05] Start automl preset with listed constraints:\n",
      "[18:06:05] - time: 2321.12 seconds\n",
      "[18:06:05] - CPU: 16 cores\n",
      "[18:06:05] - memory: 16 GB\n",
      "\n",
      "[18:06:05] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[18:06:18] Layer \u001b[1m1\u001b[0m train process start. Time left 2307.95 secs\n",
      "[18:06:32] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[18:06:59] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8083392302658804\u001b[0m\n",
      "[18:06:59] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[18:06:59] Time left 2267.24 secs\n",
      "\n",
      "[18:07:07] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:07:19] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[18:07:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8042581068853407\u001b[0m\n",
      "[18:07:43] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:07:43] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:12:45] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[18:12:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:13:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8137078614901281\u001b[0m\n",
      "[18:13:07] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:13:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[18:13:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8129637020509768\u001b[0m\n",
      "[18:13:19] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:13:19] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:15:32] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[18:15:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[18:15:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8134898959337038\u001b[0m\n",
      "[18:15:53] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:15:53] Time left 1732.84 secs\n",
      "\n",
      "[18:15:53] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[18:15:54] Blending: optimization starts with equal weights and score \u001b[1m0.8138946691006415\u001b[0m\n",
      "[18:15:58] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.814401094508441\u001b[0m, weights = \u001b[1m[0.         0.11800601 0.5244211  0.12150498 0.23606798]\u001b[0m\n",
      "[18:16:03] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8144173182004573\u001b[0m, weights = \u001b[1m[0.         0.15279503 0.4687931  0.14234386 0.23606795]\u001b[0m\n",
      "[18:16:08] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8144175599397966\u001b[0m, weights = \u001b[1m[0.         0.1540658  0.47269198 0.13521095 0.2380313 ]\u001b[0m\n",
      "[18:16:13] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8144176195057923\u001b[0m, weights = \u001b[1m[0.         0.15269041 0.47488672 0.13328643 0.23913649]\u001b[0m\n",
      "[18:16:17] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8144177432446518\u001b[0m, weights = \u001b[1m[0.         0.15295778 0.4805121  0.13351981 0.2330103 ]\u001b[0m\n",
      "[18:16:17] \u001b[1mAutoml preset training completed in 612.33 seconds\u001b[0m\n",
      "\n",
      "[18:16:17] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.15296 * (4 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.48051 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.13352 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.23301 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[18:16:17] ==================================================\n",
      "[18:16:17] Start 2 automl preset configuration:\n",
      "[18:16:17] \u001b[1mconf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 51}, 'nn_params': {'random_state': 51}, 'general_params': {'return_all_predictions': False}}\n",
      "[18:16:17] Stdout logging level is INFO.\n",
      "[18:16:17] Task: binary\n",
      "\n",
      "[18:16:17] Start automl preset with listed constraints:\n",
      "[18:16:17] - time: 1708.77 seconds\n",
      "[18:16:17] - CPU: 16 cores\n",
      "[18:16:17] - memory: 16 GB\n",
      "\n",
      "[18:16:17] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[18:16:18] Layer \u001b[1m1\u001b[0m train process start. Time left 1707.79 secs\n",
      "[18:16:32] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[18:16:52] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8082619700173825\u001b[0m\n",
      "[18:16:52] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[18:16:52] Time left 1673.78 secs\n",
      "\n",
      "[18:17:01] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:17:13] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[18:17:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8064537631530235\u001b[0m\n",
      "[18:17:36] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:17:36] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 269.44 secs\n",
      "[18:22:10] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[18:22:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[18:22:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8125450120205836\u001b[0m\n",
      "[18:22:28] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:22:28] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[18:22:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8133449977292706\u001b[0m\n",
      "[18:22:40] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:22:40] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:24:47] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[18:24:47] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[18:25:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8133856872043617\u001b[0m\n",
      "[18:25:02] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:25:02] Time left 1184.22 secs\n",
      "\n",
      "[18:25:02] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[18:25:02] Blending: optimization starts with equal weights and score \u001b[1m0.813660772994489\u001b[0m\n",
      "[18:25:07] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8140009620740776\u001b[0m, weights = \u001b[1m[0.         0.13526443 0.23850039 0.39621344 0.23002164]\u001b[0m\n",
      "[18:25:12] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8140013856634717\u001b[0m, weights = \u001b[1m[0.         0.13328426 0.24843495 0.37867773 0.23960303]\u001b[0m\n",
      "[18:25:16] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8140014588884271\u001b[0m, weights = \u001b[1m[0.         0.12759799 0.25141162 0.3803373  0.2406531 ]\u001b[0m\n",
      "[18:25:21] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8140014588884271\u001b[0m, weights = \u001b[1m[0.         0.12759799 0.25141162 0.3803373  0.2406531 ]\u001b[0m\n",
      "[18:25:21] Blending: no score update. Terminated\n",
      "\n",
      "[18:25:21] \u001b[1mAutoml preset training completed in 543.37 seconds\u001b[0m\n",
      "\n",
      "[18:25:21] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.12760 * (4 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.25141 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.38034 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.24065 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[18:25:21] ==================================================\n",
      "[18:25:21] Start 3 automl preset configuration:\n",
      "[18:25:21] \u001b[1mconf_3_sel_type_1_no_inter_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 52}, 'nn_params': {'random_state': 52}, 'general_params': {'return_all_predictions': False}}\n",
      "[18:25:21] Stdout logging level is INFO.\n",
      "[18:25:21] Task: binary\n",
      "\n",
      "[18:25:21] Start automl preset with listed constraints:\n",
      "[18:25:21] - time: 1165.38 seconds\n",
      "[18:25:21] - CPU: 16 cores\n",
      "[18:25:21] - memory: 16 GB\n",
      "\n",
      "[18:25:21] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[18:25:34] Layer \u001b[1m1\u001b[0m train process start. Time left 1152.32 secs\n",
      "[18:25:48] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[18:26:11] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8082145797314747\u001b[0m\n",
      "[18:26:11] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[18:26:11] Time left 1114.99 secs\n",
      "\n",
      "[18:26:19] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:26:20] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[18:26:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8061915930003613\u001b[0m\n",
      "[18:26:43] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:26:43] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 148.03 secs\n",
      "[18:29:16] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[18:29:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[18:29:34] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8126255504194014\u001b[0m\n",
      "[18:29:34] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:29:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[18:29:45] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8127932590056554\u001b[0m\n",
      "[18:29:45] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:29:45] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:31:57] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[18:31:57] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:32:13] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8134819285574613\u001b[0m\n",
      "[18:32:13] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:32:13] Time left 753.03 secs\n",
      "\n",
      "[18:32:13] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[18:32:13] Blending: optimization starts with equal weights and score \u001b[1m0.8136570756999985\u001b[0m\n",
      "[18:32:18] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8139929531552004\u001b[0m, weights = \u001b[1m[0.         0.13541941 0.30341718 0.13679096 0.42437243]\u001b[0m\n",
      "[18:32:23] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8139988096160076\u001b[0m, weights = \u001b[1m[0.         0.14959873 0.2974844  0.09410293 0.45881397]\u001b[0m\n",
      "[18:32:27] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8139998229653347\u001b[0m, weights = \u001b[1m[0.         0.15242389 0.30310234 0.07054314 0.47393057]\u001b[0m\n",
      "[18:32:32] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8139999717590907\u001b[0m, weights = \u001b[1m[0.         0.15308547 0.3028329  0.06702238 0.47705925]\u001b[0m\n",
      "[18:32:37] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8140000015824996\u001b[0m, weights = \u001b[1m[0.         0.15361775 0.30008578 0.06757849 0.47871795]\u001b[0m\n",
      "[18:32:37] \u001b[1mAutoml preset training completed in 436.05 seconds\u001b[0m\n",
      "\n",
      "[18:32:37] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.15362 * (4 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.30009 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.06758 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.47872 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[18:32:37] ==================================================\n",
      "[18:32:37] Start 4 automl preset configuration:\n",
      "[18:32:37] \u001b[1mconf_4_sel_type_0_no_int.yml\u001b[0m, random state: {'reader_params': {'random_state': 53}, 'nn_params': {'random_state': 53}, 'general_params': {'return_all_predictions': False}}\n",
      "[18:32:37] Stdout logging level is INFO.\n",
      "[18:32:37] Task: binary\n",
      "\n",
      "[18:32:37] Start automl preset with listed constraints:\n",
      "[18:32:37] - time: 729.30 seconds\n",
      "[18:32:37] - CPU: 16 cores\n",
      "[18:32:37] - memory: 16 GB\n",
      "\n",
      "[18:32:37] \u001b[1mTrain data shape: (413194, 70)\u001b[0m\n",
      "\n",
      "[18:32:50] Layer \u001b[1m1\u001b[0m train process start. Time left 715.88 secs\n",
      "[18:32:53] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[18:33:21] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8083652674758948\u001b[0m\n",
      "[18:33:21] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[18:33:21] Time left 685.31 secs\n",
      "\n",
      "[18:33:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[18:33:44] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8004721959740526\u001b[0m\n",
      "[18:33:44] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:33:44] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 92.58 secs\n",
      "[18:35:22] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[18:35:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[18:35:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8143762224319328\u001b[0m\n",
      "[18:35:43] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:35:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[18:35:55] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8129406037803137\u001b[0m\n",
      "[18:35:55] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:35:55] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[18:38:03] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[18:38:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[18:38:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8135310273448387\u001b[0m\n",
      "[18:38:20] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[18:38:20] Time left 385.92 secs\n",
      "\n",
      "[18:38:20] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[18:38:20] Blending: optimization starts with equal weights and score \u001b[1m0.8136145000761399\u001b[0m\n",
      "[18:38:25] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.814582245612385\u001b[0m, weights = \u001b[1m[0.         0.         0.66797405 0.18045704 0.15156895]\u001b[0m\n",
      "[18:38:30] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8145822457740297\u001b[0m, weights = \u001b[1m[0.         0.         0.667974   0.18045703 0.15156895]\u001b[0m\n",
      "[18:38:35] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8145822451274516\u001b[0m, weights = \u001b[1m[0.         0.         0.667974   0.18045703 0.15156896]\u001b[0m\n",
      "[18:38:35] Blending: no score update. Terminated\n",
      "\n",
      "[18:38:35] \u001b[1mAutoml preset training completed in 357.88 seconds\u001b[0m\n",
      "\n",
      "[18:38:35] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.66797 * (4 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.18046 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.15157 * (4 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[18:38:35] ==================================================\n",
      "[2024-11-10 18:38:35]\n",
      "/home/peter/venvs/base_venv/lib/python3.10/site-packages/lightautoml/automl/blend.py:231: RuntimeWarning: Mean of empty slice\n",
      "  pred = np.nanmean([x.data for x in splitted_preds], axis=0)\n",
      "[18:38:35] Blending: optimization starts with equal weights and score \u001b[1m0.8144950114945521\u001b[0m\n",
      "[18:38:42] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8145845843657336\u001b[0m, weights = \u001b[1m[0.         0.11776612 0.         0.         0.2881006  0.45299503\n",
      " 0.14113827]\u001b[0m\n",
      "[18:38:49] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8145961500292144\u001b[0m, weights = \u001b[1m[0.         0.2632263  0.         0.         0.21650995 0.39729917\n",
      " 0.12296458]\u001b[0m\n",
      "[18:38:56] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.814596150190859\u001b[0m, weights = \u001b[1m[0.         0.2632263  0.         0.         0.21650995 0.39729914\n",
      " 0.12296458]\u001b[0m\n",
      "[18:39:03] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.814596150190859\u001b[0m, weights = \u001b[1m[0.         0.2632263  0.         0.         0.21650994 0.3972991\n",
      " 0.12296457]\u001b[0m\n",
      "[18:39:03] Blending: no score update. Terminated\n",
      "\n",
      "[2024-11-10 18:39:03,267] - [    END     ] - Fitting TabularLamaUtilized\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = TabularLamaUtilized(n_jobs=16, task=\"classification\", time_series=True)\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 60, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3445ba53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lamau_81425_full_dataset',\n",
       " 'lgb_8122_full_dataset',\n",
       " 'cb_8114_full_dataset',\n",
       " 'xgb_81325_full_dataset',\n",
       " 'lama_81298_full_dataset',\n",
       " 'lamann_autoint_8053_full_dataset',\n",
       " 'lamann_fttransformer_8050_full_dataset']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg[\"stack_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c537a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_oof.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cfg[\"stack_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(f'lamau_stack_time_series.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e7eb895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb_81325_full_dataset</td>\n",
       "      <td>20775.868872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lama_81298_full_dataset</td>\n",
       "      <td>17319.485724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lamau_81425_full_dataset</td>\n",
       "      <td>16520.024417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgb_8122_full_dataset</td>\n",
       "      <td>4307.927217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cb_8114_full_dataset</td>\n",
       "      <td>2223.026608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lamann_fttransformer_8050_full_dataset</td>\n",
       "      <td>1503.685369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feature_14</td>\n",
       "      <td>1115.478760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feature_18</td>\n",
       "      <td>1104.183290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feature_20</td>\n",
       "      <td>1060.814309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_96</td>\n",
       "      <td>1060.335950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_62</td>\n",
       "      <td>1044.886307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_44</td>\n",
       "      <td>1038.005770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_147</td>\n",
       "      <td>993.079983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature_162</td>\n",
       "      <td>959.950580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feature_145</td>\n",
       "      <td>905.389469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature    Importance\n",
       "0                   xgb_81325_full_dataset  20775.868872\n",
       "1                  lama_81298_full_dataset  17319.485724\n",
       "2                 lamau_81425_full_dataset  16520.024417\n",
       "3                    lgb_8122_full_dataset   4307.927217\n",
       "4                     cb_8114_full_dataset   2223.026608\n",
       "5   lamann_fttransformer_8050_full_dataset   1503.685369\n",
       "6                               feature_14   1115.478760\n",
       "7                               feature_18   1104.183290\n",
       "8                               feature_20   1060.814309\n",
       "9                               feature_96   1060.335950\n",
       "10                              feature_62   1044.886307\n",
       "11                              feature_44   1038.005770\n",
       "12                             feature_147    993.079983\n",
       "13                             feature_162    959.950580\n",
       "14                             feature_145    905.389469"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.get_feature_scores()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339cafd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-08 09:07:53,431] - [   START    ] - Fitting TabularLama\n",
      "[09:07:53] Stdout logging level is INFO.\n",
      "[09:07:53] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[09:07:53] Task: binary\n",
      "\n",
      "[09:07:53] Start automl preset with listed constraints:\n",
      "[09:07:53] - time: 3600.00 seconds\n",
      "[09:07:53] - CPU: 16 cores\n",
      "[09:07:53] - memory: 16 GB\n",
      "\n",
      "[09:07:53] \u001b[1mTrain data shape: (413194, 21)\u001b[0m\n",
      "\n",
      "[09:07:57] Layer \u001b[1m1\u001b[0m train process start. Time left 3596.00 secs\n",
      "[09:07:57] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[09:08:00] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8082552247714897\u001b[0m\n",
      "[09:08:00] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[09:08:00] Time left 3592.98 secs\n",
      "\n",
      "[09:08:05] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[09:08:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[09:08:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8037248750001251\u001b[0m\n",
      "[09:08:31] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[09:08:31] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[09:13:32] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[09:13:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[09:13:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8064947787988421\u001b[0m\n",
      "[09:13:59] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[09:13:59] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[09:14:13] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8136941708664802\u001b[0m\n",
      "[09:14:13] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[09:14:13] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[09:19:15] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[09:19:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[09:19:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8138271593428363\u001b[0m\n",
      "[09:19:36] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[09:19:36] Time left 2896.71 secs\n",
      "\n",
      "[09:19:36] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[09:19:37] Blending: optimization starts with equal weights and score \u001b[1m0.8130654974315523\u001b[0m\n",
      "[09:19:42] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8139496878398591\u001b[0m, weights = \u001b[1m[0.06885234 0.         0.         0.32243767 0.60871   ]\u001b[0m\n",
      "[09:19:48] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8139970688272529\u001b[0m, weights = \u001b[1m[0.         0.05286201 0.         0.33105996 0.6160781 ]\u001b[0m\n",
      "[09:19:54] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8139970688272529\u001b[0m, weights = \u001b[1m[0.         0.05286201 0.         0.33105996 0.6160781 ]\u001b[0m\n",
      "[09:19:54] Blending: no score update. Terminated\n",
      "\n",
      "[09:19:54] \u001b[1mAutoml preset training completed in 720.40 seconds\u001b[0m\n",
      "\n",
      "[09:19:54] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.05286 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.33106 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.61608 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[2024-11-08 09:19:54,045] - [    END     ] - Fitting TabularLama\n",
      "0.8139970688272529\n"
     ]
    }
   ],
   "source": [
    "model = TabularLama(n_jobs=16, task=\"classification\")\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 30, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bab46f5-c9c4-4567-8fae-11296a05f4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 13:50:21,142] - [   START    ] - Fitting TabularLama\n",
      "[13:50:21] Stdout logging level is INFO.\n",
      "[13:50:21] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[13:50:21] Task: binary\n",
      "\n",
      "[13:50:21] Start automl preset with listed constraints:\n",
      "[13:50:21] - time: 3600.00 seconds\n",
      "[13:50:21] - CPU: 16 cores\n",
      "[13:50:21] - memory: 16 GB\n",
      "\n",
      "[13:50:21] \u001b[1mTrain data shape: (413194, 68)\u001b[0m\n",
      "\n",
      "[13:50:34] Layer \u001b[1m1\u001b[0m train process start. Time left 3586.87 secs\n",
      "[13:50:48] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[13:51:42] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8078772570316353\u001b[0m\n",
      "[13:51:42] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[13:51:42] Time left 3518.73 secs\n",
      "\n",
      "[13:51:49] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[13:52:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[13:52:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8085887315347171\u001b[0m\n",
      "[13:52:35] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[13:52:35] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[13:57:36] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[13:57:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[13:58:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8135094072537528\u001b[0m\n",
      "[13:58:10] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[13:58:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[13:58:32] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8123178836028417\u001b[0m\n",
      "[13:58:32] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[13:58:32] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[14:03:33] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[14:03:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[14:04:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8127419093287513\u001b[0m\n",
      "[14:04:03] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[14:04:03] Time left 2777.90 secs\n",
      "\n",
      "[14:04:03] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[14:04:03] Blending: optimization starts with equal weights and score \u001b[1m0.812999626224278\u001b[0m\n",
      "[14:04:09] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8136549668268129\u001b[0m, weights = \u001b[1m[0.         0.         0.67911774 0.13455844 0.1863238 ]\u001b[0m\n",
      "[14:04:15] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8136595917943832\u001b[0m, weights = \u001b[1m[0.         0.05554909 0.6542768  0.10332279 0.18685132]\u001b[0m\n",
      "[14:04:21] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8136596317143454\u001b[0m, weights = \u001b[1m[0.         0.05520056 0.652223   0.1026745  0.18990196]\u001b[0m\n",
      "[14:04:27] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8136597081792666\u001b[0m, weights = \u001b[1m[0.         0.05469849 0.6553861  0.10174064 0.18817475]\u001b[0m\n",
      "[14:04:33] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8136597081792666\u001b[0m, weights = \u001b[1m[0.         0.05469849 0.6553861  0.10174064 0.18817475]\u001b[0m\n",
      "[14:04:33] Blending: no score update. Terminated\n",
      "\n",
      "[14:04:33] \u001b[1mAutoml preset training completed in 852.33 seconds\u001b[0m\n",
      "\n",
      "[14:04:33] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.05470 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.65539 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.10174 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.18817 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[2024-11-07 14:04:33,610] - [    END     ] - Fitting TabularLama\n",
      "0.8136597081792666\n"
     ]
    }
   ],
   "source": [
    "model = TabularLama(n_jobs=16, task=\"classification\")\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 30, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6dd6ac2-6191-43c5-84da-522b4829abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lama_stack_8136_full_dataset\"\n",
    "MODEL_DIR = Path(f\"../../../../data/models/{MODEL_NAME}\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e4fed09-b428-4509-8644-347cbbb27f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.DataFrame()\n",
    "# res[MODEL_NAME] = oof[:, 1]\n",
    "# res.to_csv(MODEL_DIR / \"oof.csv\", index=False)\n",
    "# #joblib.dump(model, MODEL_DIR / f\"{MODEL_NAME}.joblib\")\n",
    "\n",
    "# with (MODEL_DIR / \"params.yaml\").open(\"w\") as f:\n",
    "#     yaml.dump(model.params, f)\n",
    "\n",
    "# with (MODEL_DIR / \"score.txt\").open(\"w\") as f:\n",
    "#     print(\"OOF:\", metric(y_train, oof), file=f)\n",
    "    \n",
    "# test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "# test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "# test[['id', 'target']].to_csv(MODEL_DIR / f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebab2080",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_oof.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cfg[\"stack_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7446223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lamau_814_full_dataset</td>\n",
       "      <td>78048.337071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb_81325_full_dataset</td>\n",
       "      <td>29297.001751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lama_81298_full_dataset</td>\n",
       "      <td>24098.444188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_162</td>\n",
       "      <td>1398.695796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_24</td>\n",
       "      <td>1321.674997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feature_18</td>\n",
       "      <td>1298.269506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feature_26</td>\n",
       "      <td>1290.120701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feature_145</td>\n",
       "      <td>1287.683197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feature_78</td>\n",
       "      <td>1279.916003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_36</td>\n",
       "      <td>1248.758602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_112</td>\n",
       "      <td>1228.811199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_9</td>\n",
       "      <td>1190.729637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_141</td>\n",
       "      <td>1140.620801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature_75</td>\n",
       "      <td>1127.175495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feature_79</td>\n",
       "      <td>1114.103202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feature_62</td>\n",
       "      <td>1110.960901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feature_35</td>\n",
       "      <td>1088.471595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>feature_44</td>\n",
       "      <td>1078.257104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feature_168</td>\n",
       "      <td>1069.888995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>feature_148</td>\n",
       "      <td>1055.762701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>feature_147</td>\n",
       "      <td>1051.141966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>feature_76</td>\n",
       "      <td>1041.521295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feature_20</td>\n",
       "      <td>1029.698003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>feature_157</td>\n",
       "      <td>998.859297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feature_33</td>\n",
       "      <td>993.189499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>feature_133</td>\n",
       "      <td>992.890409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>feature_59</td>\n",
       "      <td>988.289097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>feature_46</td>\n",
       "      <td>978.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>feature_14</td>\n",
       "      <td>968.263297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>feature_43</td>\n",
       "      <td>967.263209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>feature_142</td>\n",
       "      <td>953.593235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>feature_83</td>\n",
       "      <td>951.608026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>feature_96</td>\n",
       "      <td>936.340199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lgb_8122_full_dataset</td>\n",
       "      <td>899.356003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>feature_126</td>\n",
       "      <td>894.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>feature_100</td>\n",
       "      <td>889.852299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>feature_55</td>\n",
       "      <td>889.369598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>feature_183</td>\n",
       "      <td>882.159472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>feature_127</td>\n",
       "      <td>853.308690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>feature_153</td>\n",
       "      <td>835.863204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>feature_87</td>\n",
       "      <td>802.161905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>feature_8</td>\n",
       "      <td>801.556602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>feature_103</td>\n",
       "      <td>793.046144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>feature_29</td>\n",
       "      <td>783.742097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>feature_134</td>\n",
       "      <td>777.999600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>feature_11</td>\n",
       "      <td>771.673395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>feature_66</td>\n",
       "      <td>770.873203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>feature_72</td>\n",
       "      <td>722.490300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>feature_21</td>\n",
       "      <td>675.958407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>feature_25</td>\n",
       "      <td>664.108699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature    Importance\n",
       "0    lamau_814_full_dataset  78048.337071\n",
       "1    xgb_81325_full_dataset  29297.001751\n",
       "2   lama_81298_full_dataset  24098.444188\n",
       "3               feature_162   1398.695796\n",
       "4                feature_24   1321.674997\n",
       "5                feature_18   1298.269506\n",
       "6                feature_26   1290.120701\n",
       "7               feature_145   1287.683197\n",
       "8                feature_78   1279.916003\n",
       "9                feature_36   1248.758602\n",
       "10              feature_112   1228.811199\n",
       "11                feature_9   1190.729637\n",
       "12              feature_141   1140.620801\n",
       "13               feature_75   1127.175495\n",
       "14               feature_79   1114.103202\n",
       "15               feature_62   1110.960901\n",
       "16               feature_35   1088.471595\n",
       "17               feature_44   1078.257104\n",
       "18              feature_168   1069.888995\n",
       "19              feature_148   1055.762701\n",
       "20              feature_147   1051.141966\n",
       "21               feature_76   1041.521295\n",
       "22               feature_20   1029.698003\n",
       "23              feature_157    998.859297\n",
       "24               feature_33    993.189499\n",
       "25              feature_133    992.890409\n",
       "26               feature_59    988.289097\n",
       "27               feature_46    978.601000\n",
       "28               feature_14    968.263297\n",
       "29               feature_43    967.263209\n",
       "30              feature_142    953.593235\n",
       "31               feature_83    951.608026\n",
       "32               feature_96    936.340199\n",
       "33    lgb_8122_full_dataset    899.356003\n",
       "34              feature_126    894.646700\n",
       "35              feature_100    889.852299\n",
       "36               feature_55    889.369598\n",
       "37              feature_183    882.159472\n",
       "38              feature_127    853.308690\n",
       "39              feature_153    835.863204\n",
       "40               feature_87    802.161905\n",
       "41                feature_8    801.556602\n",
       "42              feature_103    793.046144\n",
       "43               feature_29    783.742097\n",
       "44              feature_134    777.999600\n",
       "45               feature_11    771.673395\n",
       "46               feature_66    770.873203\n",
       "47               feature_72    722.490300\n",
       "48               feature_21    675.958407\n",
       "49               feature_25    664.108699"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.get_feature_scores()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f687e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame().assign(names=model.models[0].feature_names_, imp=model.models[0].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d1e1081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>feature_185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          names  imp\n",
       "61  feature_185  0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values(by=\"imp\", ascending=False).reset_index(drop=True).query(\"names == 'feature_185'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce7e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_7',\n",
       " 'feature_31',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_71',\n",
       " 'feature_109',\n",
       " 'feature_122',\n",
       " 'feature_156',\n",
       " 'feature_163',\n",
       " 'feature_167',\n",
       " 'feature_179',\n",
       " 'feature_185']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517948d",
   "metadata": {},
   "source": [
    "## With Time series cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fcb3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = RocAuc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d859f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by=\"id\").reset_index(drop=True)\n",
    "X_train, y_train = df_train[cfg[\"selected_features\"] + cat_columns], df_train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e52d68ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 08:27:33,388] - [   START    ] - Tuning LightGBMClassification\n",
      "[2024-11-07 08:27:40,118] - [   OPTUNA   ] - Trial 0. New best score 0.7903405446081995 with parameters {'max_depth': 6, 'num_leaves': 488, 'min_data_in_leaf': 188, 'bagging_fraction': 0.7993292420985183, 'bagging_freq': 0, 'feature_fraction': 0.49359671220172163, 'lambda_l1': 0.5808361216819946, 'lambda_l2': 8.661761457749352, 'min_gain_to_split': 12.022300234864176, 'is_unbalance': True, 'num_iterations': 2}\n",
      "[2024-11-07 08:28:03,043] - [   OPTUNA   ] - Trial 2. New best score 0.7913515589848906 with parameters {'max_depth': 5, 'num_leaves': 194, 'min_data_in_leaf': 117, 'bagging_fraction': 0.8925879806965068, 'bagging_freq': 0, 'feature_fraction': 0.708540663048167, 'lambda_l1': 5.924145688620425, 'lambda_l2': 0.46450412719997725, 'min_gain_to_split': 12.150897038028766, 'is_unbalance': True, 'num_iterations': 2}\n",
      "[2024-11-07 08:28:12,225] - [   OPTUNA   ] - Trial 3. New best score 0.8048686053278628 with parameters {'max_depth': 16, 'num_leaves': 495, 'min_data_in_leaf': 207, 'bagging_fraction': 0.6523068845866853, 'bagging_freq': 0, 'feature_fraction': 0.8105398159072941, 'lambda_l1': 4.4015249373960135, 'lambda_l2': 1.2203823484477883, 'min_gain_to_split': 9.903538202225404, 'is_unbalance': False, 'num_iterations': 201}\n",
      "[2024-11-07 08:28:27,946] - [   OPTUNA   ] - Trial 5. New best score 0.805775359050857 with parameters {'max_depth': 15, 'num_leaves': 54, 'min_data_in_leaf': 51, 'bagging_fraction': 0.522613644455269, 'bagging_freq': 0, 'feature_fraction': 0.6332063738136893, 'lambda_l1': 2.713490317738959, 'lambda_l2': 8.287375091519294, 'min_gain_to_split': 7.135066533871786, 'is_unbalance': False, 'num_iterations': 219}\n",
      "[2024-11-07 08:30:01,873] - [   OPTUNA   ] - Trial 13. New best score 0.8069467403107815 with parameters {'max_depth': 12, 'num_leaves': 120, 'min_data_in_leaf': 83, 'bagging_fraction': 0.5973813098180023, 'bagging_freq': 0, 'feature_fraction': 0.6464487752219038, 'lambda_l1': 1.815539729792131, 'lambda_l2': 9.653379460654552, 'min_gain_to_split': 5.109079440883124, 'is_unbalance': False, 'num_iterations': 194}\n",
      "[2024-11-07 08:30:23,656] - [   OPTUNA   ] - Trial 15. New best score 0.8079174231410097 with parameters {'max_depth': 9, 'num_leaves': 123, 'min_data_in_leaf': 79, 'bagging_fraction': 0.6696558155271586, 'bagging_freq': 0, 'feature_fraction': 0.41254813989004224, 'lambda_l1': 1.5400879612744933, 'lambda_l2': 6.428485487443978, 'min_gain_to_split': 3.4073761639683475, 'is_unbalance': False, 'num_iterations': 221}\n",
      "[2024-11-07 08:30:47,866] - [   OPTUNA   ] - Trial 17. New best score 0.8080338307668665 with parameters {'max_depth': 9, 'num_leaves': 177, 'min_data_in_leaf': 149, 'bagging_fraction': 0.7020257462335121, 'bagging_freq': 0, 'feature_fraction': 0.4001314682445803, 'lambda_l1': 4.277484898844048, 'lambda_l2': 5.915176709957256, 'min_gain_to_split': 2.630193834916201, 'is_unbalance': False, 'num_iterations': 247}\n",
      "[2024-11-07 08:32:56,360] - [   OPTUNA   ] - Trial 26. New best score 0.8083158418056456 with parameters {'max_depth': 13, 'num_leaves': 120, 'min_data_in_leaf': 166, 'bagging_fraction': 0.8112271899455036, 'bagging_freq': 20, 'feature_fraction': 0.5385502023308056, 'lambda_l1': 1.3349604628055485, 'lambda_l2': 8.855392863089838, 'min_gain_to_split': 0.42505008659048693, 'is_unbalance': False, 'num_iterations': 206}\n",
      "[2024-11-07 08:33:39,494] - [   OPTUNA   ] - Trial 28. New best score 0.8085529083857821 with parameters {'max_depth': 14, 'num_leaves': 75, 'min_data_in_leaf': 170, 'bagging_fraction': 0.8264267643219445, 'bagging_freq': 20, 'feature_fraction': 0.5742524097970673, 'lambda_l1': 1.2310934175206736, 'lambda_l2': 8.969396792235317, 'min_gain_to_split': 0.16644360284870074, 'is_unbalance': False, 'num_iterations': 211}\n",
      "[2024-11-07 08:35:41,908] - [   OPTUNA   ] - Trial 35. New best score 0.8085624905981069 with parameters {'max_depth': 13, 'num_leaves': 45, 'min_data_in_leaf': 179, 'bagging_fraction': 0.9090867052918509, 'bagging_freq': 20, 'feature_fraction': 0.5986896700241908, 'lambda_l1': 1.0457599526213117, 'lambda_l2': 8.511810626751942, 'min_gain_to_split': 1.6394745612739139, 'is_unbalance': False, 'num_iterations': 242}\n",
      "[2024-11-07 08:36:11,789] - [   OPTUNA   ] - Trial 37. New best score 0.8086060147129036 with parameters {'max_depth': 15, 'num_leaves': 146, 'min_data_in_leaf': 131, 'bagging_fraction': 0.9727869256250319, 'bagging_freq': 20, 'feature_fraction': 0.594412726250827, 'lambda_l1': 1.3076349982497943, 'lambda_l2': 8.42304491740083, 'min_gain_to_split': 1.95638379105971, 'is_unbalance': False, 'num_iterations': 180}\n",
      "[2024-11-07 08:37:31,532] - [   OPTUNA   ] - Trial 42. New best score 0.8086748450733487 with parameters {'max_depth': 11, 'num_leaves': 95, 'min_data_in_leaf': 155, 'bagging_fraction': 0.9696680239166591, 'bagging_freq': 20, 'feature_fraction': 0.5068877996580057, 'lambda_l1': 0.3880584908457285, 'lambda_l2': 9.519643874182023, 'min_gain_to_split': 1.5176677728376484, 'is_unbalance': False, 'num_iterations': 225}\n",
      "[2024-11-07 08:43:11,113] - [   OPTUNA   ] - Trial 63. New best score 0.8087325744854885 with parameters {'max_depth': 16, 'num_leaves': 160, 'min_data_in_leaf': 166, 'bagging_fraction': 0.936885833403046, 'bagging_freq': 20, 'feature_fraction': 0.4498188675696397, 'lambda_l1': 1.1357746192947442, 'lambda_l2': 7.7534455607773385, 'min_gain_to_split': 2.069412187433082, 'is_unbalance': False, 'num_iterations': 207}\n",
      "[2024-11-07 08:45:27,863] - [   OPTUNA   ] - Trial 71. New best score 0.809046586456055 with parameters {'max_depth': 10, 'num_leaves': 153, 'min_data_in_leaf': 160, 'bagging_fraction': 0.9135728904594532, 'bagging_freq': 10, 'feature_fraction': 0.506921563666065, 'lambda_l1': 0.6725410135999423, 'lambda_l2': 8.841591608898721, 'min_gain_to_split': 1.6964405734320749, 'is_unbalance': False, 'num_iterations': 237}\n",
      "[2024-11-07 08:51:41,348] - [   OPTUNA   ] - Trial 91. New best score 0.8092009955871362 with parameters {'max_depth': 8, 'num_leaves': 331, 'min_data_in_leaf': 57, 'bagging_fraction': 0.9120914616559199, 'bagging_freq': 10, 'feature_fraction': 0.43368773726287124, 'lambda_l1': 3.8666345262680837, 'lambda_l2': 8.173281721666852, 'min_gain_to_split': 0.7062609644931823, 'is_unbalance': False, 'num_iterations': 313}\n",
      "[2024-11-07 09:24:15,316] - [   OPTUNA   ] - Trial 184. New best score 0.8092209952891476 with parameters {'max_depth': 8, 'num_leaves': 258, 'min_data_in_leaf': 21, 'bagging_fraction': 0.8833000021442096, 'bagging_freq': 10, 'feature_fraction': 0.44326798567844145, 'lambda_l1': 1.7734419425628303, 'lambda_l2': 8.481446649565262, 'min_gain_to_split': 0.19263364585511303, 'is_unbalance': False, 'num_iterations': 294}\n",
      "[2024-11-07 09:27:54,872] - [   OPTUNA   ] - 195 trials completed\n",
      "[2024-11-07 09:27:54,874] - [BEST PARAMS ] - {'objective_type': 'binary', 'boosting': 'gbdt', 'num_iterations': 294, 'max_depth': 8, 'learning_rate': 0.03, 'num_leaves': 258, 'min_data_in_leaf': 21, 'bagging_fraction': 0.8833000021442096, 'bagging_freq': 10, 'feature_fraction': 0.44326798567844145, 'early_stopping_round': 100, 'lambda_l1': 1.7734419425628303, 'lambda_l2': 8.481446649565262, 'min_gain_to_split': 0.19263364585511303, 'num_threads': 16, 'random_state': 42, 'is_unbalance': False, 'num_classes': 1, 'verbose': -1}\n",
      "[2024-11-07 09:27:54,875] - [    END     ] - Tuning LightGBMClassification\n",
      "[2024-11-07 09:27:54,877] - [   START    ] - Fitting LightGBMClassification\n",
      "[2024-11-07 09:27:54,892] - [    FIT     ] - LightGBMClassification fold 0\n",
      "[2024-11-07 09:27:56,881] - [    FIT     ] - LightGBMClassification fold 1\n",
      "[2024-11-07 09:27:59,788] - [    FIT     ] - LightGBMClassification fold 2\n",
      "[2024-11-07 09:28:04,156] - [    FIT     ] - LightGBMClassification fold 3\n",
      "[2024-11-07 09:28:09,145] - [    FIT     ] - LightGBMClassification fold 4\n",
      "[2024-11-07 09:28:14,959] - [    END     ] - Fitting LightGBMClassification\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = LightGBMClassification(n_jobs=16, time_series=True)\n",
    "model.tune(X_train, y_train, metric, timeout=60 * 60, categorical_features=cat_columns)\n",
    "oof = model.fit(X_train, y_train, categorical_features=cat_columns)\n",
    "\n",
    "print(metric(y_train, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a073f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_oofs_idx = oof[np.any(np.isnan(oof), axis=1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f8165e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095227594190041"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y_train[none_oofs_idx:], oof[none_oofs_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc0326db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lgb_8095_full_dataset_time_series\"\n",
    "MODEL_DIR = Path(f\"../../../data/models/{MODEL_NAME}\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "652cae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res[MODEL_NAME] = oof[none_oofs_idx:, 1]\n",
    "res.to_csv(MODEL_DIR / \"oof.csv\", index=False)\n",
    "joblib.dump(model, MODEL_DIR / f\"{MODEL_NAME}.joblib\")\n",
    "\n",
    "with (MODEL_DIR / \"params.yaml\").open(\"w\") as f:\n",
    "    yaml.dump(model.params, f)\n",
    "\n",
    "with (MODEL_DIR / \"score.txt\").open(\"w\") as f:\n",
    "    print(\"OOF:\", metric(y_train, oof), file=f)\n",
    "    \n",
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv(MODEL_DIR / f'{MODEL_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c20b42",
   "metadata": {},
   "source": [
    "## TEST \n",
    "**81.22112399468679**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e490c4a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3645213-67f1-4a56-8449-706616b01975",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(DATA_PATH / \"test_preproc_2.parquet\")\n",
    "test[\"target\"] = model.predict(test[cfg[\"selected_features\"] + cat_columns])[:, 1]\n",
    "test[['id', 'target']].to_csv('lgb_813.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b626f4-24d7-47cc-8e1c-8d4829422eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pd.read_csv(\"lama_utilized.csv\")\n",
    "pred_2 = pd.read_csv(\"lgmb_oe_ohe_cols_0805.csv\")\n",
    "pred_3 = pd.read_csv(\"catboost_ts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6fd1b74-1c84-47a2-9640-f9afca52a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1[\"target\"] = 0.6 * pred_1[\"target\"] + 0.2 * pred_2[\"target\"] + 0.2 * pred_3[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9a12186-27a7-43e5-bbf9-05d9894bd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1.to_csv(\"blend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1a479dff-a006-4237-9a22-9b4a9d6a52eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Open the file pointed by this path and return a file object, as\n",
       "the built-in open() function does.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/lib/python3.10/pathlib.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_DIR.open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9b1c6-0fb4-461a-9aa9-1c23e299671f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_kernel",
   "language": "python",
   "name": "base_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
